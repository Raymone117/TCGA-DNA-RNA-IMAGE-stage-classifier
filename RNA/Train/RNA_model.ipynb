{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "wm4KwJjzASvx",
        "outputId": "69a10f28-b23a-468c-a3ba-e64a8a3eab74"
      },
      "outputs": [],
      "source": [
        "# !pip install scanpy\n",
        "# !pip install flwr\n",
        "# !pip install autogluon\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"SCIPY_ARRAY_API\"] = \"1\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import anndata as ad\n",
        "import joblib\n",
        "from scipy.sparse import issparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "import scanpy as sc\n",
        "import gdown\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Config\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "\n",
        "# file_id = \"110eYMgseyD32YIS9xOMbOpJ76wnDXahR\"\n",
        "# gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output=\"TCGA_BRCA_RNA.h5ad\", quiet=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvdhOXrma8on"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd4slBRIANxm",
        "outputId": "cdb695d1-621d-4ab4-ec41-7d6e64d65df1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All patient_id(s) in test_metadata.csv are present in the .h5ad dataset.\n",
            "All test samples successfully mapped to stage labels.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/yy/s74n5fc53gv5mw5gdw5l8ch40000gn/T/ipykernel_40322/3146219170.py:51: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
            "  adata_test.obs[\"stage\"] = adata_test.obs[\"patient_id\"].map(patient_to_stage)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training and test sets saved:\n",
            "Test samples: 28 ‚Üí RNA_test.h5ad\n",
            "Train samples: 1202 ‚Üí RNA_train.h5ad\n",
            "Test label distribution:\n",
            "stage\n",
            "Stage II     14\n",
            "Stage III     7\n",
            "Stage I       6\n",
            "Stage IV      1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Paths\n",
        "adata_path = \"../Dataset/TCGA_BRCA_RNA.h5ad\"\n",
        "test_csv_path = \"../test_metadata.csv\"\n",
        "train_h5ad_path = \"RNA_train.h5ad\"\n",
        "test_h5ad_path = \"RNA_test.h5ad\"\n",
        "\n",
        "# Label mappings\n",
        "label_map = {\n",
        "    \"Stage I\": 0,\n",
        "    \"Stage II\": 1,\n",
        "    \"Stage III\": 2,\n",
        "    \"Stage IV\": 3,\n",
        "}\n",
        "stage_map = {\n",
        "    \"Stage1\": \"Stage I\",\n",
        "    \"Stage2\": \"Stage II\",\n",
        "    \"Stage3\": \"Stage III\",\n",
        "    \"Stage4\": \"Stage IV\",\n",
        "}\n",
        "\n",
        "# Load .h5ad data\n",
        "adata = sc.read_h5ad(adata_path)\n",
        "adata.obs[\"patient_id\"] = adata.obs[\"patient_id\"].astype(str)\n",
        "\n",
        "# Load test_metadata.csv and fix label format\n",
        "test_df = pd.read_csv(test_csv_path)\n",
        "test_df[\"patient_id\"] = test_df[\"patient_id\"].astype(str)\n",
        "test_df[\"label\"] = test_df[\"label\"].str.strip()\n",
        "test_df[\"stage\"] = test_df[\"label\"].map(stage_map)  # Convert e.g. \"Stage4\" ‚Üí \"Stage IV\"\n",
        "\n",
        "# üîç Check patient ID consistency\n",
        "csv_patient_ids = set(test_df[\"patient_id\"])\n",
        "adata_patient_ids = set(adata.obs[\"patient_id\"])\n",
        "missing_in_adata = csv_patient_ids - adata_patient_ids\n",
        "if missing_in_adata:\n",
        "    print(\"The following patient_id(s) exist in test_metadata.csv but were not found in .h5ad:\")\n",
        "    print(missing_in_adata)\n",
        "else:\n",
        "    print(\"All patient_id(s) in test_metadata.csv are present in the .h5ad dataset.\")\n",
        "\n",
        "# 1. Extract test set by patient ID\n",
        "test_patients = set(test_df[\"patient_id\"])\n",
        "is_test = adata.obs[\"patient_id\"].isin(test_patients)\n",
        "adata_test = adata[is_test].copy()\n",
        "\n",
        "# De-duplicate: keep only one sample per patient_id\n",
        "adata_test = adata_test[adata_test.obs.groupby(\"patient_id\").head(1).index]\n",
        "\n",
        "# Assign correct stage labels from test_metadata.csv\n",
        "patient_to_stage = dict(zip(test_df[\"patient_id\"], test_df[\"stage\"]))\n",
        "adata_test.obs[\"stage\"] = adata_test.obs[\"patient_id\"].map(patient_to_stage)\n",
        "\n",
        "# üîç Check for unmapped test samples\n",
        "unmapped = adata_test.obs[adata_test.obs[\"stage\"].isna()]\n",
        "if not unmapped.empty:\n",
        "    print(\"The following patient_id(s) were found in .h5ad but failed to map a stage label:\")\n",
        "    print(unmapped[\"patient_id\"].tolist())\n",
        "else:\n",
        "    print(\"All test samples successfully mapped to stage labels.\")\n",
        "\n",
        "# 2. The rest are used as training set\n",
        "adata_train = adata[~is_test].copy()\n",
        "\n",
        "# Save output files\n",
        "adata_train.write(train_h5ad_path)\n",
        "adata_test.write(test_h5ad_path)\n",
        "\n",
        "# Final summary\n",
        "print(\"Training and test sets saved:\")\n",
        "print(\"Test samples:\", adata_test.shape[0], \"‚Üí\", test_h5ad_path)\n",
        "print(\"Train samples:\", adata_train.shape[0], \"‚Üí\", train_h5ad_path)\n",
        "print(\"Test label distribution:\")\n",
        "print(adata_test.obs[\"stage\"].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Gl2MGBGbC61"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:110: UserWarning: Features [17916 18434 19255 20000 20704 21144 22796 22865 23559 23594 25051 25096\n",
            " 25475 25494 25613 25876 25943 26696 27209 27544 27847 28210 30227 30553\n",
            " 31799 32852 33003 33969 34230 40615 42909 43522 45975 46464 46819 47370\n",
            " 47517 49278 49295 49614 49621 49733 50585 52248 52416 52832 53689 53724\n",
            " 54163 54475 55028 55904] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        }
      ],
      "source": [
        "# File paths\n",
        "scaler_path = \"RNA_scaler.pkl\"\n",
        "selector_path = \"RNA_selector_kbest.pkl\"\n",
        "autogluon_model_path = \"autogluon_rna_model\"\n",
        "\n",
        "# 1. Load data\n",
        "adata = ad.read_h5ad(train_h5ad_path)\n",
        "X = adata.X.toarray() if issparse(adata.X) else adata.X\n",
        "y_raw = adata.obs[\"stage\"].values\n",
        "label_map = {\"Stage I\": 0, \"Stage II\": 1, \"Stage III\": 2, \"Stage IV\": 3}\n",
        "label_names = list(label_map.keys())\n",
        "y = np.array([label_map.get(s, 3) for s in y_raw])  # Default to Stage IV if unknown\n",
        "\n",
        "# 2. Sample-level cleaning (Z-score)\n",
        "expr_sum = X.sum(axis=1)\n",
        "z_scores = (expr_sum - np.mean(expr_sum)) / np.std(expr_sum)\n",
        "mask = np.abs(z_scores) < 3\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# 3. Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# 4. Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "joblib.dump(scaler, scaler_path)\n",
        "\n",
        "# 5. SelectKBest Feature Selection\n",
        "selector = SelectKBest(score_func=f_classif, k=1000)\n",
        "X_train_sel = selector.fit_transform(X_train_scaled, y_train)\n",
        "X_val_sel = selector.transform(X_val_scaled)\n",
        "joblib.dump(selector, selector_path)\n",
        "\n",
        "# 6. SMOTE Over-sampling\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train_sel, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pQcd1G_IGGDu",
        "outputId": "a31acb58-9f9b-41f6-cdc9-4af7d1f353f3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"autogluon_rna_model\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.4.0\n",
            "Python Version:     3.12.2\n",
            "Operating System:   Darwin\n",
            "Platform Machine:   arm64\n",
            "Platform Version:   Darwin Kernel Version 24.6.0: Mon Jul 14 11:29:54 PDT 2025; root:xnu-11417.140.69~1/RELEASE_ARM64_T8122\n",
            "CPU Count:          8\n",
            "Memory Avail:       4.07 GB / 16.00 GB (25.5%)\n",
            "Disk Space Avail:   131.25 GB / 460.43 GB (28.5%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "Setting dynamic_stacking from 'auto' to False. Reason: Skip dynamic_stacking when use_bag_holdout is enabled. (use_bag_holdout=True)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "Beginning AutoGluon training ... Time limit = 1800s\n",
            "AutoGluon will save models to \"/Users/xin/Desktop/DATA5703/RNA/Train/autogluon_rna_model\"\n",
            "Train Data Rows:    2204\n",
            "Train Data Columns: 1000\n",
            "Tuning Data Rows:    241\n",
            "Tuning Data Columns: 1000\n",
            "Label Column:       stage\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 4\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    4176.53 MB\n",
            "\tTrain Data (Original)  Memory Usage: 18.65 MB (0.4% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 1000 | ['0', '1', '2', '3', '4', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 1000 | ['0', '1', '2', '3', '4', ...]\n",
            "\t0.7s = Fit runtime\n",
            "\t1000 features in original data used to generate 1000 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 18.65 MB (0.5% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.77s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'GBM': [{'ag_args_fit': {'hyperparameter_tune_kwargs': 'auto'}}],\n",
            "\t'CAT': [{'ag_args_fit': {'hyperparameter_tune_kwargs': 'auto'}}],\n",
            "\t'XGB': [{'ag_args_fit': {'hyperparameter_tune_kwargs': 'auto'}}],\n",
            "\t'RF': [{'ag_args_fit': {'hyperparameter_tune_kwargs': 'auto'}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 4 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1199.19s of the 1799.23s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=8.71%)\n",
            "\t0.7094\t = Validation score   (f1_weighted)\n",
            "\t100.96s\t = Training   runtime\n",
            "\t0.43s\t = Validation runtime\n",
            "Fitting model: RandomForest_BAG_L1 ... Training model for up to 1094.00s of the 1694.04s of remaining time.\n",
            "\t0.5261\t = Validation score   (f1_weighted)\n",
            "\t1.77s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1091.80s of the 1691.85s of remaining time.\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 29.18% memory usage per fold, 58.35%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=29.18%)\n",
            "\t0.7007\t = Validation score   (f1_weighted)\n",
            "\t877.86s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ... Training model for up to 211.97s of the 812.01s of remaining time.\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 13.78% memory usage per fold, 55.13%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=13.78%)\n",
            "\t0.7138\t = Validation score   (f1_weighted)\n",
            "\t110.75s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 698.49s of remaining time.\n",
            "\tEnsemble Weights: {'XGBoost_BAG_L1': 1.0}\n",
            "\t0.7138\t = Validation score   (f1_weighted)\n",
            "\t0.08s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 4 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 698.40s of the 698.39s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=7.11%)\n",
            "\t0.5528\t = Validation score   (f1_weighted)\n",
            "\t84.02s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: RandomForest_BAG_L2 ... Training model for up to 611.21s of the 611.20s of remaining time.\n",
            "\t0.6619\t = Validation score   (f1_weighted)\n",
            "\t1.68s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ... Training model for up to 609.09s of the 609.08s of remaining time.\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 30.64% memory usage per fold, 61.28%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=30.64%)\n",
            "\t0.583\t = Validation score   (f1_weighted)\n",
            "\t491.83s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L2 ... Training model for up to 115.20s of the 115.19s of remaining time.\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 13.12% memory usage per fold, 52.46%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=13.12%)\n",
            "\t0.5832\t = Validation score   (f1_weighted)\n",
            "\t79.66s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 32.72s of remaining time.\n",
            "\tEnsemble Weights: {'XGBoost_BAG_L1': 0.4, 'RandomForest_BAG_L2': 0.4, 'LightGBM_BAG_L1': 0.2}\n",
            "\t0.7214\t = Validation score   (f1_weighted)\n",
            "\t0.07s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 1767.37s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 303.5 rows/s (241 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/xin/Desktop/DATA5703/RNA/Train/autogluon_rna_model\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x30b521ac0>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 7. Prepare for AutoGluon\n",
        "train_df = pd.DataFrame(X_resampled)\n",
        "train_df[\"stage\"] = y_resampled\n",
        "val_df = pd.DataFrame(X_val_sel)\n",
        "val_df[\"stage\"] = y_val\n",
        "\n",
        "train_data = TabularDataset(train_df)\n",
        "val_data = TabularDataset(val_df)\n",
        "\n",
        "# 8. AutoGluon Training with GPU models and more time\n",
        "predictor = TabularPredictor(\n",
        "    label=\"stage\",\n",
        "    path=autogluon_model_path,\n",
        "    eval_metric=\"f1_weighted\",\n",
        "    problem_type=\"multiclass\"\n",
        ")\n",
        "predictor.fit(\n",
        "    train_data=train_data,\n",
        "    # tuning_data=val_data,\n",
        "    use_bag_holdout=True,\n",
        "    # num_bag_folds=5,\n",
        "    # num_stack_levels=1,\n",
        "    time_limit=1800,\n",
        "    presets=\"best_quality\",\n",
        "    hyperparameters={\n",
        "        \"GBM\": {\"ag_args_fit\": {\"hyperparameter_tune_kwargs\": \"auto\"}},\n",
        "        \"CAT\": {\"ag_args_fit\": {\"hyperparameter_tune_kwargs\": \"auto\"}},\n",
        "        \"XGB\": {\"ag_args_fit\": {\"hyperparameter_tune_kwargs\": \"auto\"}},\n",
        "        \"RF\":  {\"ag_args_fit\": {\"hyperparameter_tune_kwargs\": \"auto\"}}\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31cSR1gXcIJm",
        "outputId": "5b9fbf7c-0182-4e64-cfd8-42b4a4ac0b85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Stage I       0.65      1.00      0.79        39\n",
            "    Stage II       0.83      0.79      0.81       139\n",
            "   Stage III       0.60      0.54      0.57        54\n",
            "    Stage IV       0.00      0.00      0.00         9\n",
            "\n",
            "    accuracy                           0.74       241\n",
            "   macro avg       0.52      0.58      0.54       241\n",
            "weighted avg       0.72      0.74      0.72       241\n",
            "\n",
            "Confusion Matrix:\n",
            "           Stage I  Stage II  Stage III  Stage IV\n",
            "Stage I         39         0          0         0\n",
            "Stage II        14       110         15         0\n",
            "Stage III        6        19         29         0\n",
            "Stage IV         1         4          4         0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        }
      ],
      "source": [
        "# 9. Evaluation\n",
        "val_preds = predictor.predict(val_data.drop(columns=[\"stage\"]))\n",
        "print(\"Validation Classification Report:\")\n",
        "print(classification_report(val_data[\"stage\"], val_preds, target_names=label_names))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(pd.DataFrame(confusion_matrix(val_data[\"stage\"], val_preds), index=label_names, columns=label_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JfYjw0YnWAFy",
        "outputId": "a4c521b2-2b8d-41ce-eb18-a2fc944aefc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                 model  score_val  eval_metric  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0  WeightedEnsemble_L3   0.721409  f1_weighted       0.794191  1093.090344                0.001003           0.074579            3       True         10\n",
            "1       XGBoost_BAG_L1   0.713832  f1_weighted       0.166761   110.754014                0.166761         110.754014            1       True          4\n",
            "2  WeightedEnsemble_L2   0.713832  f1_weighted       0.167915   110.835135                0.001154           0.081121            2       True          5\n",
            "3      LightGBM_BAG_L1   0.709395  f1_weighted       0.430442   100.958566                0.430442         100.958566            1       True          1\n",
            "4      CatBoost_BAG_L1   0.700685  f1_weighted       0.135326   877.857084                0.135326         877.857084            1       True          3\n",
            "5  RandomForest_BAG_L2   0.661935  f1_weighted       0.793188  1093.015765                0.024108           1.676851            2       True          7\n",
            "6       XGBoost_BAG_L2   0.583226  f1_weighted       0.943481  1171.001023                0.174401          79.662109            2       True          9\n",
            "7      CatBoost_BAG_L2   0.582978  f1_weighted       0.853316  1583.169962                0.084236         491.831047            2       True          8\n",
            "8      LightGBM_BAG_L2   0.552795  f1_weighted       0.862698  1175.356346                0.093618          84.017432            2       True          6\n",
            "9  RandomForest_BAG_L1   0.526147  f1_weighted       0.036551     1.769250                0.036551           1.769250            1       True          2\n",
            "Number of models trained: 10\n",
            "Types of models trained:\n",
            "{'StackerEnsembleModel_LGB', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_XGBoost', 'WeightedEnsembleModel', 'StackerEnsembleModel_RF'}\n",
            "Bagging used: True  (with 8 folds)\n",
            "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('float', []) : 1000 | ['0', '1', '2', '3', '4', ...]\n",
            "Plot summary of models saved to file: /Users/xin/Desktop/DATA5703/RNA/Train/autogluon_rna_model/SummaryOfModels.html\n",
            "*** End of fit() summary ***\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'model_types': {'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
              "  'RandomForest_BAG_L1': 'StackerEnsembleModel_RF',\n",
              "  'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
              "  'XGBoost_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
              "  'WeightedEnsemble_L2': 'WeightedEnsembleModel',\n",
              "  'LightGBM_BAG_L2': 'StackerEnsembleModel_LGB',\n",
              "  'RandomForest_BAG_L2': 'StackerEnsembleModel_RF',\n",
              "  'CatBoost_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
              "  'XGBoost_BAG_L2': 'StackerEnsembleModel_XGBoost',\n",
              "  'WeightedEnsemble_L3': 'WeightedEnsembleModel'},\n",
              " 'model_performance': {'LightGBM_BAG_L1': 0.7093947031998783,\n",
              "  'RandomForest_BAG_L1': 0.5261471983368422,\n",
              "  'CatBoost_BAG_L1': 0.7006854228665891,\n",
              "  'XGBoost_BAG_L1': 0.7138316614185216,\n",
              "  'WeightedEnsemble_L2': 0.7138316614185216,\n",
              "  'LightGBM_BAG_L2': 0.5527952114353698,\n",
              "  'RandomForest_BAG_L2': 0.6619347255861778,\n",
              "  'CatBoost_BAG_L2': 0.5829775430046195,\n",
              "  'XGBoost_BAG_L2': 0.5832256471053151,\n",
              "  'WeightedEnsemble_L3': 0.7214092351387934},\n",
              " 'model_best': 'WeightedEnsemble_L3',\n",
              " 'model_paths': {'LightGBM_BAG_L1': ['LightGBM_BAG_L1'],\n",
              "  'RandomForest_BAG_L1': ['RandomForest_BAG_L1'],\n",
              "  'CatBoost_BAG_L1': ['CatBoost_BAG_L1'],\n",
              "  'XGBoost_BAG_L1': ['XGBoost_BAG_L1'],\n",
              "  'WeightedEnsemble_L2': ['WeightedEnsemble_L2'],\n",
              "  'LightGBM_BAG_L2': ['LightGBM_BAG_L2'],\n",
              "  'RandomForest_BAG_L2': ['RandomForest_BAG_L2'],\n",
              "  'CatBoost_BAG_L2': ['CatBoost_BAG_L2'],\n",
              "  'XGBoost_BAG_L2': ['XGBoost_BAG_L2'],\n",
              "  'WeightedEnsemble_L3': ['WeightedEnsemble_L3']},\n",
              " 'model_fit_times': {'LightGBM_BAG_L1': 100.95856595039368,\n",
              "  'RandomForest_BAG_L1': 1.7692501544952393,\n",
              "  'CatBoost_BAG_L1': 877.8570840358734,\n",
              "  'XGBoost_BAG_L1': 110.75401425361633,\n",
              "  'WeightedEnsemble_L2': 0.08112120628356934,\n",
              "  'LightGBM_BAG_L2': 84.01743173599243,\n",
              "  'RandomForest_BAG_L2': 1.6768507957458496,\n",
              "  'CatBoost_BAG_L2': 491.83104729652405,\n",
              "  'XGBoost_BAG_L2': 79.66210889816284,\n",
              "  'WeightedEnsemble_L3': 0.07457900047302246},\n",
              " 'model_pred_times': {'LightGBM_BAG_L1': 0.43044209480285645,\n",
              "  'RandomForest_BAG_L1': 0.03655076026916504,\n",
              "  'CatBoost_BAG_L1': 0.13532590866088867,\n",
              "  'XGBoost_BAG_L1': 0.16676115989685059,\n",
              "  'WeightedEnsemble_L2': 0.001153707504272461,\n",
              "  'LightGBM_BAG_L2': 0.09361791610717773,\n",
              "  'RandomForest_BAG_L2': 0.024107933044433594,\n",
              "  'CatBoost_BAG_L2': 0.08423614501953125,\n",
              "  'XGBoost_BAG_L2': 0.17440104484558105,\n",
              "  'WeightedEnsemble_L3': 0.0010027885437011719},\n",
              " 'num_bag_folds': 8,\n",
              " 'max_stack_level': 3,\n",
              " 'num_classes': 4,\n",
              " 'model_hyperparams': {'LightGBM_BAG_L1': {'use_orig_features': True,\n",
              "   'valid_stacker': True,\n",
              "   'max_base_models': 0,\n",
              "   'max_base_models_per_type': 'auto',\n",
              "   'save_bag_folds': True,\n",
              "   'stratify': 'auto',\n",
              "   'bin': 'auto',\n",
              "   'n_bins': None},\n",
              "  'RandomForest_BAG_L1': {'use_orig_features': True,\n",
              "   'valid_stacker': True,\n",
              "   'max_base_models': 0,\n",
              "   'max_base_models_per_type': 'auto',\n",
              "   'save_bag_folds': True,\n",
              "   'stratify': 'auto',\n",
              "   'bin': 'auto',\n",
              "   'n_bins': None,\n",
              "   'use_child_oof': True},\n",
              "  'CatBoost_BAG_L1': {'use_orig_features': True,\n",
              "   'valid_stacker': True,\n",
              "   'max_base_models': 0,\n",
              "   'max_base_models_per_type': 'auto',\n",
              "   'save_bag_folds': True,\n",
              "   'stratify': 'auto',\n",
              "   'bin': 'auto',\n",
              "   'n_bins': None},\n",
              "  'XGBoost_BAG_L1': {'use_orig_features': True,\n",
              "   'valid_stacker': True,\n",
              "   'max_base_models': 0,\n",
              "   'max_base_models_per_type': 'auto',\n",
              "   'save_bag_folds': True,\n",
              "   'stratify': 'auto',\n",
              "   'bin': 'auto',\n",
              "   'n_bins': None},\n",
              "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
              "   'valid_stacker': True,\n",
              "   'max_base_models': 0,\n",
              "   'max_base_models_per_type': 'auto',\n",
              "   'save_bag_folds': True,\n",
              "   'stratify': 'auto',\n",
              "   'bin': 'auto',\n",
              "   'n_bins': None},\n",
              "  'LightGBM_BAG_L2': {'use_orig_features': True,\n",
              "   'valid_stacker': True,\n",
              "   'max_base_models': 0,\n",
              "   'max_base_models_per_type': 'auto',\n",
              "   'save_bag_folds': True,\n",
              "   'stratify': 'auto',\n",
              "   'bin': 'auto',\n",
              "   'n_bins': None},\n",
              "  'RandomForest_BAG_L2': {'use_orig_features': True,\n",
              "   'valid_stacker': True,\n",
              "   'max_base_models': 0,\n",
              "   'max_base_models_per_type': 'auto',\n",
              "   'save_bag_folds': True,\n",
              "   'stratify': 'auto',\n",
              "   'bin': 'auto',\n",
              "   'n_bins': None,\n",
              "   'use_child_oof': True},\n",
              "  'CatBoost_BAG_L2': {'use_orig_features': True,\n",
              "   'valid_stacker': True,\n",
              "   'max_base_models': 0,\n",
              "   'max_base_models_per_type': 'auto',\n",
              "   'save_bag_folds': True,\n",
              "   'stratify': 'auto',\n",
              "   'bin': 'auto',\n",
              "   'n_bins': None},\n",
              "  'XGBoost_BAG_L2': {'use_orig_features': True,\n",
              "   'valid_stacker': True,\n",
              "   'max_base_models': 0,\n",
              "   'max_base_models_per_type': 'auto',\n",
              "   'save_bag_folds': True,\n",
              "   'stratify': 'auto',\n",
              "   'bin': 'auto',\n",
              "   'n_bins': None},\n",
              "  'WeightedEnsemble_L3': {'use_orig_features': False,\n",
              "   'valid_stacker': True,\n",
              "   'max_base_models': 0,\n",
              "   'max_base_models_per_type': 'auto',\n",
              "   'save_bag_folds': True,\n",
              "   'stratify': 'auto',\n",
              "   'bin': 'auto',\n",
              "   'n_bins': None}},\n",
              " 'leaderboard':                  model  score_val  eval_metric  pred_time_val     fit_time  \\\n",
              " 0  WeightedEnsemble_L3   0.721409  f1_weighted       0.794191  1093.090344   \n",
              " 1       XGBoost_BAG_L1   0.713832  f1_weighted       0.166761   110.754014   \n",
              " 2  WeightedEnsemble_L2   0.713832  f1_weighted       0.167915   110.835135   \n",
              " 3      LightGBM_BAG_L1   0.709395  f1_weighted       0.430442   100.958566   \n",
              " 4      CatBoost_BAG_L1   0.700685  f1_weighted       0.135326   877.857084   \n",
              " 5  RandomForest_BAG_L2   0.661935  f1_weighted       0.793188  1093.015765   \n",
              " 6       XGBoost_BAG_L2   0.583226  f1_weighted       0.943481  1171.001023   \n",
              " 7      CatBoost_BAG_L2   0.582978  f1_weighted       0.853316  1583.169962   \n",
              " 8      LightGBM_BAG_L2   0.552795  f1_weighted       0.862698  1175.356346   \n",
              " 9  RandomForest_BAG_L1   0.526147  f1_weighted       0.036551     1.769250   \n",
              " \n",
              "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              " 0                0.001003           0.074579            3       True   \n",
              " 1                0.166761         110.754014            1       True   \n",
              " 2                0.001154           0.081121            2       True   \n",
              " 3                0.430442         100.958566            1       True   \n",
              " 4                0.135326         877.857084            1       True   \n",
              " 5                0.024108           1.676851            2       True   \n",
              " 6                0.174401          79.662109            2       True   \n",
              " 7                0.084236         491.831047            2       True   \n",
              " 8                0.093618          84.017432            2       True   \n",
              " 9                0.036551           1.769250            1       True   \n",
              " \n",
              "    fit_order  \n",
              " 0         10  \n",
              " 1          4  \n",
              " 2          5  \n",
              " 3          1  \n",
              " 4          3  \n",
              " 5          7  \n",
              " 6          9  \n",
              " 7          8  \n",
              " 8          6  \n",
              " 9          2  }"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.fit_summary()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
