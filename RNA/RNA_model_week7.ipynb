{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "7UIvIdMQWCaq"
      },
      "id": "7UIvIdMQWCaq"
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "file_id = \"1cPmNRjDZDevMK5vzXK7M12kwhFfpcjsb\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output=\"TCGA_BRCA_RNA.h5ad\", quiet=False)\n",
        "\n",
        "\n",
        "# https://drive.google.com/file/d/1roKItvj-FOjnGBQsert9ANMI8mbDeBwn/view?usp=sharing\n",
        "file_id = \"1roKItvj-FOjnGBQsert9ANMI8mbDeBwn\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output=\"TCGA_BRCA_RNA_HiSeqV2.h5ad\", quiet=False)\n",
        "\n",
        "\n",
        "!pip install scanpy\n",
        "# !pip install tabpfn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TYzzDCLyua3p",
        "outputId": "7961ea3c-0705-438d-e2ab-f000f3e1a85f"
      },
      "id": "TYzzDCLyua3p",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1cPmNRjDZDevMK5vzXK7M12kwhFfpcjsb\n",
            "From (redirected): https://drive.google.com/uc?id=1cPmNRjDZDevMK5vzXK7M12kwhFfpcjsb&confirm=t&uuid=04624bbf-8831-46ed-a7ac-b42460c5e8a2\n",
            "To: /content/TCGA_BRCA_RNA.h5ad\n",
            "100%|██████████| 575M/575M [00:11<00:00, 50.6MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1roKItvj-FOjnGBQsert9ANMI8mbDeBwn\n",
            "From (redirected): https://drive.google.com/uc?id=1roKItvj-FOjnGBQsert9ANMI8mbDeBwn&confirm=t&uuid=d570343e-5b30-488c-b02e-948a417d6564\n",
            "To: /content/TCGA_BRCA_RNA_HiSeqV2.h5ad\n",
            "100%|██████████| 218M/218M [00:01<00:00, 110MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scanpy\n",
            "  Downloading scanpy-1.11.4-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting anndata>=0.8 (from scanpy)\n",
            "  Downloading anndata-0.12.2-py3-none-any.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: h5py>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from scanpy) (3.14.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from scanpy) (1.5.2)\n",
            "Collecting legacy-api-wrap>=1.4.1 (from scanpy)\n",
            "  Downloading legacy_api_wrap-1.4.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.5 in /usr/local/lib/python3.12/dist-packages (from scanpy) (3.10.0)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.12/dist-packages (from scanpy) (8.4.0)\n",
            "Requirement already satisfied: networkx>=2.7.1 in /usr/local/lib/python3.12/dist-packages (from scanpy) (3.5)\n",
            "Requirement already satisfied: numba>=0.57.1 in /usr/local/lib/python3.12/dist-packages (from scanpy) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.24.1 in /usr/local/lib/python3.12/dist-packages (from scanpy) (2.0.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from scanpy) (25.0)\n",
            "Requirement already satisfied: pandas>=1.5.3 in /usr/local/lib/python3.12/dist-packages (from scanpy) (2.2.2)\n",
            "Requirement already satisfied: patsy!=1.0.0 in /usr/local/lib/python3.12/dist-packages (from scanpy) (1.0.1)\n",
            "Requirement already satisfied: pynndescent>=0.5.13 in /usr/local/lib/python3.12/dist-packages (from scanpy) (0.5.13)\n",
            "Requirement already satisfied: scikit-learn>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from scanpy) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from scanpy) (1.16.1)\n",
            "Requirement already satisfied: seaborn>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from scanpy) (0.13.2)\n",
            "Collecting session-info2 (from scanpy)\n",
            "  Downloading session_info2-0.2.2-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: statsmodels>=0.14.5 in /usr/local/lib/python3.12/dist-packages (from scanpy) (0.14.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from scanpy) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from scanpy) (4.15.0)\n",
            "Requirement already satisfied: umap-learn>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from scanpy) (0.5.9.post2)\n",
            "Collecting array-api-compat>=1.7.1 (from anndata>=0.8->scanpy)\n",
            "  Downloading array_api_compat-1.12.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting zarr!=3.0.*,>=2.18.7 (from anndata>=0.8->scanpy)\n",
            "  Downloading zarr-3.1.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy) (2.9.0.post0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.57.1->scanpy) (0.43.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.3->scanpy) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.3->scanpy) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.3->scanpy) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.5->scanpy) (1.17.0)\n",
            "Collecting donfig>=0.8 (from zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy)\n",
            "  Downloading donfig-0.8.1.post1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting numcodecs>=0.14 (from numcodecs[crc32c]>=0.14->zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy)\n",
            "  Downloading numcodecs-0.16.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from donfig>=0.8->zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy) (6.0.2)\n",
            "Collecting crc32c>=2.7 (from numcodecs[crc32c]>=0.14->zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy)\n",
            "  Downloading crc32c-2.7.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Downloading scanpy-1.11.4-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anndata-0.12.2-py3-none-any.whl (169 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.9/169.9 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading legacy_api_wrap-1.4.1-py3-none-any.whl (10.0 kB)\n",
            "Downloading session_info2-0.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading array_api_compat-1.12.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.2/58.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zarr-3.1.2-py3-none-any.whl (261 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.0/261.0 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading donfig-0.8.1.post1-py3-none-any.whl (21 kB)\n",
            "Downloading numcodecs-0.16.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m115.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading crc32c-2.7.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: session-info2, numcodecs, legacy-api-wrap, donfig, crc32c, array-api-compat, zarr, anndata, scanpy\n",
            "Successfully installed anndata-0.12.2 array-api-compat-1.12.0 crc32c-2.7.1 donfig-0.8.1.post1 legacy-api-wrap-1.4.1 numcodecs-0.16.2 scanpy-1.11.4 session-info2-0.2.2 zarr-3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1552660c",
      "metadata": {
        "id": "1552660c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# # ========== 配置 ==========\n",
        "# H5AD_PATH = \"/content/TCGA_BRCA_RNA.h5ad\"\n",
        "# H5AD_PATH = \"/content/TCGA_BRCA_RNA_HiSeqV2.h5ad\"\n",
        "\n",
        "# ========= Step 0: 固定随机种子 ==========\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "import random\n",
        "random.seed(SEED)\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "\n",
        "os.environ[\"SCIPY_ARRAY_API\"] = \"1\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0195d85",
      "metadata": {
        "id": "c0195d85"
      },
      "source": [
        "## Lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scanpy as sc\n",
        "import anndata as ad\n",
        "import warnings\n",
        "import lightgbm as lgb\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# ========= Step 0: 固定随机种子 ==========\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "\n",
        "# ========= Step 1: 读取 h5ad ==========\n",
        "\n",
        "H5AD_PATH = \"/content/TCGA_BRCA_RNA.h5ad\"\n",
        "adata = sc.read_h5ad(H5AD_PATH)\n",
        "adata.var_names_make_unique()\n",
        "adata = adata[adata.obs[\"stage\"].astype(str) != \"Unknown\"].copy()\n",
        "\n",
        "\n",
        "# ========= Step 2: 标签处理 ==========\n",
        "labels = adata.obs[\"stage\"].astype(str)\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(labels)\n",
        "# X = adata.X\n",
        "from scipy.sparse import issparse\n",
        "if issparse(adata.X):\n",
        "    X = adata.X.toarray()\n",
        "else:\n",
        "    X = adata.X\n",
        "\n",
        "class_names = label_encoder.classes_\n",
        "stage_iv_index = label_encoder.transform(['Stage IV'])[0]\n",
        "\n",
        "# ========= Step 3: 划分训练集和测试集 ==========\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=SEED\n",
        ")\n",
        "\n",
        "# ========= Step 4: SMOTE 数据增强 ==========\n",
        "sm = SMOTE(random_state=SEED)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "# ========= Step 5: 手动复制 Stage IV 样本 ==========\n",
        "iv_mask = y_train_res == stage_iv_index\n",
        "X_iv = X_train_res[iv_mask]\n",
        "y_iv = y_train_res[iv_mask]\n",
        "\n",
        "N = 3  # 复制次数\n",
        "X_train_res = np.vstack([X_train_res] + [X_iv] * N)\n",
        "y_train_res = np.concatenate([y_train_res] + [y_iv] * N)\n",
        "\n",
        "# ========= Step 6: 特征选择 ==========\n",
        "selector = SelectKBest(score_func=mutual_info_classif, k=500)\n",
        "X_train_sel = selector.fit_transform(X_train_res, y_train_res)\n",
        "X_test_sel = selector.transform(X_test)\n",
        "\n",
        "# ========= Step 7: 权重设置 ==========\n",
        "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train_res), y=y_train_res)\n",
        "class_weights[stage_iv_index] *= 10  # 强化 Stage IV\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# 可选 sample_weight（可注释）\n",
        "sample_weight = np.ones(len(y_train_res))\n",
        "sample_weight[y_train_res == stage_iv_index] *= 5\n",
        "\n",
        "# ========= Step 8: LightGBM 训练 ==========\n",
        "lgbm = LGBMClassifier(\n",
        "    objective=\"multiclass\",\n",
        "    num_class=len(class_names),\n",
        "    class_weight=class_weight_dict,\n",
        "    learning_rate=0.01,\n",
        "    n_estimators=1000,\n",
        "    min_data_in_leaf=50,\n",
        "    min_child_weight=10,\n",
        "    max_depth=4,\n",
        "    num_leaves=7,\n",
        "    reg_alpha=1.0,\n",
        "    reg_lambda=1.0,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    feature_fraction=0.8,\n",
        "    bagging_fraction=0.8,\n",
        "    bagging_freq=1,\n",
        "    boosting_type=\"gbdt\",\n",
        "    random_state=SEED,\n",
        "    deterministic=True,\n",
        "    n_jobs=1\n",
        ")\n",
        "\n",
        "lgbm.fit(\n",
        "    X_train_sel, y_train_res,\n",
        "    sample_weight=sample_weight,\n",
        "    eval_set=[(X_test_sel, y_test)],\n",
        "    eval_metric=\"multi_logloss\",\n",
        "    callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
        ")\n"
      ],
      "metadata": {
        "id": "6qiF-WJuWIM8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1b5f4385-0d5b-400c-dddd-93c3fe109220"
      },
      "id": "6qiF-WJuWIM8",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.8 will be ignored. Current value: bagging_fraction=0.8\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.8 will be ignored. Current value: bagging_fraction=0.8\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022447 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 127500\n",
            "[LightGBM] [Info] Number of data points in the train set: 3941, number of used features: 500\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.8 will be ignored. Current value: bagging_fraction=0.8\n",
            "[LightGBM] [Info] Start training from score -3.970292\n",
            "[LightGBM] [Info] Start training from score -3.970292\n",
            "[LightGBM] [Info] Start training from score -3.970292\n",
            "[LightGBM] [Info] Start training from score -0.058269\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Early stopping, best iteration is:\n",
            "[940]\tvalid_0's multi_logloss: 1.0997\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(bagging_fraction=0.8, bagging_freq=1,\n",
              "               class_weight={0: np.float64(1.75), 1: np.float64(1.75),\n",
              "                             2: np.float64(1.75), 3: np.float64(4.375)},\n",
              "               colsample_bytree=0.8, deterministic=True, feature_fraction=0.8,\n",
              "               learning_rate=0.01, max_depth=4, min_child_weight=10,\n",
              "               min_data_in_leaf=50, n_estimators=1000, n_jobs=1, num_class=4,\n",
              "               num_leaves=7, objective='multiclass', random_state=42,\n",
              "               reg_alpha=1.0, reg_lambda=1.0, subsample=0.8)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(bagging_fraction=0.8, bagging_freq=1,\n",
              "               class_weight={0: np.float64(1.75), 1: np.float64(1.75),\n",
              "                             2: np.float64(1.75), 3: np.float64(4.375)},\n",
              "               colsample_bytree=0.8, deterministic=True, feature_fraction=0.8,\n",
              "               learning_rate=0.01, max_depth=4, min_child_weight=10,\n",
              "               min_data_in_leaf=50, n_estimators=1000, n_jobs=1, num_class=4,\n",
              "               num_leaves=7, objective=&#x27;multiclass&#x27;, random_state=42,\n",
              "               reg_alpha=1.0, reg_lambda=1.0, subsample=0.8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(bagging_fraction=0.8, bagging_freq=1,\n",
              "               class_weight={0: np.float64(1.75), 1: np.float64(1.75),\n",
              "                             2: np.float64(1.75), 3: np.float64(4.375)},\n",
              "               colsample_bytree=0.8, deterministic=True, feature_fraction=0.8,\n",
              "               learning_rate=0.01, max_depth=4, min_child_weight=10,\n",
              "               min_data_in_leaf=50, n_estimators=1000, n_jobs=1, num_class=4,\n",
              "               num_leaves=7, objective=&#x27;multiclass&#x27;, random_state=42,\n",
              "               reg_alpha=1.0, reg_lambda=1.0, subsample=0.8)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ========= Step 9: Soft Labeling 阈值调整 ==========\n",
        "y_proba = lgbm.predict_proba(X_test_sel)\n",
        "# soft_threshold = 0.3\n",
        "y_pred_raw = lgbm.predict(X_test_sel)\n",
        "# y_pred_soft = np.copy(y_pred_raw)\n",
        "# y_pred_soft[y_proba[:, stage_iv_index] > soft_threshold] = stage_iv_index\n",
        "\n",
        "# ========= Step 10: 评估函数 ==========\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def evaluate(pred, y_true, name):\n",
        "    acc = accuracy_score(y_true, pred)\n",
        "    macro_f1 = f1_score(y_true, pred, average=\"macro\", zero_division=0)\n",
        "\n",
        "    # macro_f1 = f1_score(y_true, pred, average=\"macro\")\n",
        "    print(f\"\\n LightGBM Macro F1-score: {macro_f1:.4f} ({name})\")\n",
        "    print(classification_report(y_true, pred, target_names=class_names, zero_division=0))\n",
        "\n",
        "    print(f\"\\n Macro F1-score: {macro_f1:.4f}, Accuracy: {acc:.4f}\")\n",
        "\n",
        "    # 混淆矩阵\n",
        "    cm = confusion_matrix(y_true, pred)\n",
        "    print(\" LightGBM Confusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "# evaluate(lgbm.predict(X_train_sel), y_train_res, \"Train\")\n",
        "print(\"LightGBM model result\")\n",
        "evaluate(y_pred_raw, y_test, \"Test (Raw)\")\n",
        "\n",
        "# # ========= Step 11: 打印 Stage IV 概率 ==========\n",
        "# print(\"🧪 Stage IV 预测概率（前5条）:\")\n",
        "# print(y_proba[:5, stage_iv_index])\n",
        "\n",
        "\n",
        "from itertools import product\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# 所有候选阈值（你可以自定义更大搜索空间）\n",
        "stage_iv_range = [0.02, 0.05, 0.15, 0.20,0.45, 0.5]\n",
        "stage_iii_range = [0.30, 0.35, 0.40,0.45, 0.5,0.55, 0.6]\n",
        "stage_i_range   = [0.30, 0.35, 0.4, 0.5]\n",
        "stage_ii_range  = [ 0.4, 0.5, 0.6, 0.7, 0.8]\n",
        "\n",
        "results = []\n",
        "\n",
        "class2index = {cls: i for i, cls in enumerate(class_names)}\n",
        "stage_iv_idx = class2index[\"Stage IV\"]\n",
        "stage_i_idx = class2index[\"Stage I\"]\n",
        "\n",
        "# 遍历所有组合\n",
        "for th_iv, th_iii, th_i, th_ii in product(stage_iv_range, stage_iii_range, stage_i_range, stage_ii_range):\n",
        "\n",
        "    # 多类别 Soft Label Override\n",
        "    y_pred = np.copy(y_pred_raw)\n",
        "    for i in range(len(y_pred)):\n",
        "        if y_proba[i][class2index[\"Stage IV\"]] > th_iv:\n",
        "            y_pred[i] = class2index[\"Stage IV\"]\n",
        "        elif y_proba[i][class2index[\"Stage III\"]] > th_iii:\n",
        "            y_pred[i] = class2index[\"Stage III\"]\n",
        "        elif y_proba[i][class2index[\"Stage I\"]] > th_i:\n",
        "            y_pred[i] = class2index[\"Stage I\"]\n",
        "        elif y_proba[i][class2index[\"Stage II\"]] > th_ii:\n",
        "            y_pred[i] = class2index[\"Stage II\"]\n",
        "        # 否则保留原始预测\n",
        "\n",
        "    # 评估指标\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        y_test, y_pred, average=None, zero_division=0\n",
        "    )\n",
        "    macro_f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
        "\n",
        "    results.append({\n",
        "        \"Stage IV Thresh\": th_iv,\n",
        "        \"Stage III Thresh\": th_iii,\n",
        "        \"Stage II Thresh\": th_ii,\n",
        "        \"Stage I Thresh\": th_i,\n",
        "        \"Macro F1\": macro_f1,\n",
        "        \"Stage IV Recall\": recall[stage_iv_idx],\n",
        "        \"Stage I Precision\": precision[stage_i_idx],\n",
        "    })\n",
        "\n",
        "# 转成 DataFrame 排序\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values(\"Macro F1\", ascending=False)\n",
        "\n",
        "# # 显示 Top 10\n",
        "# from IPython.display import display\n",
        "# display(results_df.head(10))\n",
        "\n",
        "\n",
        "\n",
        "# ===== 1. 提取最优结果 =====\n",
        "best = results_df.iloc[0]\n",
        "th_iv = best[\"Stage IV Thresh\"]\n",
        "th_iii = best[\"Stage III Thresh\"]\n",
        "th_ii = best[\"Stage II Thresh\"]\n",
        "th_i = best[\"Stage I Thresh\"]\n",
        "\n",
        "# print(\"Best soft threshould:\")\n",
        "# print(best[[\"Stage IV Thresh\", \"Stage III Thresh\", \"Stage II Thresh\", \"Stage I Thresh\"]])\n",
        "\n",
        "# ===== 2. 使用最佳阈值重新预测 =====\n",
        "# y_pred_best = np.copy(y_pred_raw)\n",
        "# for i in range(len(y_pred_best)):\n",
        "#     if y_proba[i][class2index[\"Stage IV\"]] > th_iv:\n",
        "#         y_pred_best[i] = class2index[\"Stage IV\"]\n",
        "#     elif y_proba[i][class2index[\"Stage III\"]] > th_iii:\n",
        "#         y_pred_best[i] = class2index[\"Stage III\"]\n",
        "#     elif y_proba[i][class2index[\"Stage I\"]] > th_i:\n",
        "#         y_pred_best[i] = class2index[\"Stage I\"]\n",
        "#     elif y_proba[i][class2index[\"Stage II\"]] > th_ii:\n",
        "#         y_pred_best[i] = class2index[\"Stage II\"]\n",
        "#     # 否则保留原始预测\n",
        "\n",
        "\n",
        "# # ===== 3. 打印评估指标 =====\n",
        "# print(\"\\n LightGBM Classification Report (Best Thresholds):\")\n",
        "# print(classification_report(y_test, y_pred_best, target_names=class_names, zero_division=0))\n",
        "\n",
        "# macro_f1 = f1_score(y_test, y_pred_best, average=\"macro\")\n",
        "# acc = accuracy_score(y_test, y_pred_best)\n",
        "# print(f\" Macro F1-score: {macro_f1:.4f}, Accuracy: {acc:.4f}\")\n",
        "\n",
        "# # ===== 4. 混淆矩阵可视化 =====\n",
        "# cm = confusion_matrix(y_test, y_pred_best)\n",
        "# df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "# print(\" LightGBM Confusion Matrix:\")\n",
        "# print(df_cm)\n",
        "\n",
        "\n",
        "\n",
        "# ===== 使用最佳阈值做 Dynamic Override 预测 =====\n",
        "y_pred_best = []\n",
        "for i in range(len(y_proba)):\n",
        "    candidate_classes = []\n",
        "\n",
        "    for cls in class2index:\n",
        "        class_idx = class2index[cls]\n",
        "        prob = y_proba[i][class_idx]\n",
        "        thresh = best[f\"{cls} Thresh\"]\n",
        "        if prob > thresh:\n",
        "            candidate_classes.append((cls, prob))\n",
        "\n",
        "    if candidate_classes:\n",
        "        # 选择超过阈值中 softmax 概率最大的类别\n",
        "        selected_cls = max(candidate_classes, key=lambda x: x[1])[0]\n",
        "        y_pred_best.append(class2index[selected_cls])\n",
        "    else:\n",
        "        # fallback: 使用原始预测\n",
        "        y_pred_best.append(y_pred_raw[i])\n",
        "\n",
        "# 打印评估指标\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
        "\n",
        "print(\"\\nLightGBM Classification Report (Best Soft Thresholds):\")\n",
        "print(classification_report(y_test, y_pred_best, target_names=class_names, zero_division=0))\n",
        "\n",
        "macro_f1 = f1_score(y_test, y_pred_best, average=\"macro\")\n",
        "acc = accuracy_score(y_test, y_pred_best)\n",
        "print(f\"Macro F1-score: {macro_f1:.4f}, Accuracy: {acc:.4f}\")\n",
        "\n",
        "# 混淆矩阵\n",
        "cm = confusion_matrix(y_test, y_pred_best)\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "print(\"LightGBM Confusion Matrix(Best Soft Thresholds):\")\n",
        "print(df_cm)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apL77XWEPSbj",
        "outputId": "2bbdd61d-b232-4604-9b15-a0e259060bb4"
      },
      "id": "apL77XWEPSbj",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.8 will be ignored. Current value: bagging_fraction=0.8\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.8 will be ignored. Current value: bagging_fraction=0.8\n",
            "LightGBM model result\n",
            "\n",
            " LightGBM Macro F1-score: 0.3823 (Test (Raw))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Stage I       0.32      0.30      0.31        40\n",
            "    Stage II       0.65      0.66      0.66       142\n",
            "   Stage III       0.36      0.36      0.36        56\n",
            "    Stage IV       0.17      0.25      0.20         4\n",
            "\n",
            "    accuracy                           0.52       242\n",
            "   macro avg       0.38      0.39      0.38       242\n",
            "weighted avg       0.52      0.52      0.52       242\n",
            "\n",
            "\n",
            " Macro F1-score: 0.3823, Accuracy: 0.5248\n",
            " LightGBM Confusion Matrix:\n",
            "[[12 21  7  0]\n",
            " [18 94 27  3]\n",
            " [ 7 27 20  2]\n",
            " [ 0  2  1  1]]\n",
            "\n",
            "LightGBM Classification Report (Best Soft Thresholds):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Stage I       0.40      0.30      0.34        40\n",
            "    Stage II       0.66      0.65      0.66       142\n",
            "   Stage III       0.35      0.41      0.38        56\n",
            "    Stage IV       0.17      0.25      0.20         4\n",
            "\n",
            "    accuracy                           0.53       242\n",
            "   macro avg       0.40      0.40      0.40       242\n",
            "weighted avg       0.54      0.53      0.53       242\n",
            "\n",
            "Macro F1-score: 0.3951, Accuracy: 0.5331\n",
            "LightGBM Confusion Matrix(Best Soft Thresholds):\n",
            "           Stage I  Stage II  Stage III  Stage IV\n",
            "Stage I         12        20          8         0\n",
            "Stage II        13        93         33         3\n",
            "Stage III        5        26         23         2\n",
            "Stage IV         0         2          1         1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP"
      ],
      "metadata": {
        "id": "yqRrt99seUyh"
      },
      "id": "yqRrt99seUyh"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scanpy as sc\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# ===== 固定随机种子 =====\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "# ===== 参数 =====\n",
        "BATCH_SIZE = 16\n",
        "LR = 1e-3\n",
        "NUM_EPOCHS = 20\n",
        "HIDDEN1 = 1024\n",
        "HIDDEN2 = 256\n",
        "DROPOUT_RATE = 0.5\n",
        "MODEL_SAVE_PATH = \"./mlp_best.pt\"\n",
        "\n",
        "# ===== 读取数据 =====\n",
        "# H5AD_PATH = \"/content/TCGA_BRCA_RNA.h5ad\"\n",
        "H5AD_PATH = \"/content/TCGA_BRCA_RNA_HiSeqV2.h5ad\"\n",
        "adata = sc.read_h5ad(H5AD_PATH)\n",
        "adata.var_names_make_unique()\n",
        "\n",
        "# ===== 只保留合法标签 =====\n",
        "valid_stages = [\"Stage I\", \"Stage II\", \"Stage III\", \"Stage IV\"]\n",
        "adata = adata[adata.obs[\"stage\"].isin(valid_stages)].copy()\n",
        "\n",
        "# ===== 特征矩阵 & 标签 =====\n",
        "import scipy.sparse\n",
        "X = adata.X.toarray() if scipy.sparse.issparse(adata.X) else np.array(adata.X)\n",
        "labels = adata.obs[\"stage\"].astype(str).values\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(labels)  # 0~3\n",
        "\n",
        "INPUT_DIM = X.shape[1]\n",
        "NUM_CLASSES = len(le.classes_)\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"Classes:\", le.classes_)\n",
        "\n",
        "# ===== 划分训练 / 测试集 =====\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=SEED\n",
        ")\n",
        "\n",
        "# ===== 类别权重 =====\n",
        "class_weights = compute_class_weight(\"balanced\", classes=np.unique(y_train), y=y_train)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)\n",
        "print(\"Class weights:\", class_weights.cpu().numpy())\n",
        "\n",
        "# ===== 自定义 Dataset =====\n",
        "class RNAStageDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "    def __len__(self): return len(self.y)\n",
        "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
        "\n",
        "train_loader = DataLoader(RNAStageDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(RNAStageDataset(X_test, y_test), batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# ===== 定义 MLP 模型 =====\n",
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden1, hidden2, num_classes, dropout_rate=0.5):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden1)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden2)\n",
        "        self.out = nn.Linear(hidden2, num_classes)\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x); x = self.bn1(x); x = self.relu(x); x = self.dropout(x)\n",
        "        x = self.fc2(x); x = self.bn2(x); x = self.relu(x); x = self.dropout(x)\n",
        "        return self.out(x)\n",
        "\n",
        "model = MLPClassifier(INPUT_DIM, HIDDEN1, HIDDEN2, NUM_CLASSES, DROPOUT_RATE).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-4)\n",
        "\n",
        "# ===== 训练循环 =====\n",
        "best_f1 = 0.0\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    model.train(); total_loss = 0.0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        batch_X, batch_y = batch_X.to(DEVICE), batch_y.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(batch_X)\n",
        "        loss = criterion(logits, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * batch_X.size(0)\n",
        "    avg_loss = total_loss / len(train_loader.dataset)\n",
        "\n",
        "    # ===== 验证阶段 =====\n",
        "    model.eval(); preds, truths = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y in test_loader:\n",
        "            batch_X = batch_X.to(DEVICE)\n",
        "            logits = model(batch_X)\n",
        "            preds_batch = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "            preds.extend(preds_batch)\n",
        "            truths.extend(batch_y.numpy())\n",
        "\n",
        "    acc = accuracy_score(truths, preds)\n",
        "    f1 = f1_score(truths, preds, average=\"macro\", zero_division=0)\n",
        "    print(f\"Epoch {epoch}/{NUM_EPOCHS} - Loss: {avg_loss:.4f} | Acc: {acc:.4f} | Macro F1: {f1:.4f}\")\n",
        "\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "        print(\"✅ New best model saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUiY2aOACJ1Q",
        "outputId": "40d7f711-63d0-4bdf-aef5-4217aa4e2940"
      },
      "id": "RUiY2aOACJ1Q",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "X shape: (1216, 17170)\n",
            "Classes: ['Stage I' 'Stage II' 'Stage III' 'Stage IV']\n",
            "Class weights: [1.5283018  0.43862817 1.0995475  6.394737  ]\n",
            "Epoch 1/20 - Loss: 1.5409 | Acc: 0.3607 | Macro F1: 0.2438\n",
            "✅ New best model saved!\n",
            "Epoch 2/20 - Loss: 1.3647 | Acc: 0.4016 | Macro F1: 0.2717\n",
            "✅ New best model saved!\n",
            "Epoch 3/20 - Loss: 1.2299 | Acc: 0.3607 | Macro F1: 0.2618\n",
            "Epoch 4/20 - Loss: 1.0772 | Acc: 0.3279 | Macro F1: 0.2457\n",
            "Epoch 5/20 - Loss: 0.9521 | Acc: 0.2541 | Macro F1: 0.2252\n",
            "Epoch 6/20 - Loss: 0.7901 | Acc: 0.3689 | Macro F1: 0.2181\n",
            "Epoch 7/20 - Loss: 0.7031 | Acc: 0.5697 | Macro F1: 0.2406\n",
            "Epoch 8/20 - Loss: 0.6448 | Acc: 0.1967 | Macro F1: 0.1288\n",
            "Epoch 9/20 - Loss: 0.6144 | Acc: 0.2418 | Macro F1: 0.1708\n",
            "Epoch 10/20 - Loss: 0.4855 | Acc: 0.2377 | Macro F1: 0.2271\n",
            "Epoch 11/20 - Loss: 0.4846 | Acc: 0.5697 | Macro F1: 0.2476\n",
            "Epoch 12/20 - Loss: 0.4077 | Acc: 0.2869 | Macro F1: 0.1981\n",
            "Epoch 13/20 - Loss: 0.4071 | Acc: 0.2787 | Macro F1: 0.2359\n",
            "Epoch 14/20 - Loss: 0.3549 | Acc: 0.4918 | Macro F1: 0.3068\n",
            "✅ New best model saved!\n",
            "Epoch 15/20 - Loss: 0.3274 | Acc: 0.5164 | Macro F1: 0.3564\n",
            "✅ New best model saved!\n",
            "Epoch 16/20 - Loss: 0.3522 | Acc: 0.5615 | Macro F1: 0.2030\n",
            "Epoch 17/20 - Loss: 0.3336 | Acc: 0.5328 | Macro F1: 0.2572\n",
            "Epoch 18/20 - Loss: 0.3054 | Acc: 0.3811 | Macro F1: 0.3257\n",
            "Epoch 19/20 - Loss: 0.3192 | Acc: 0.2582 | Macro F1: 0.2157\n",
            "Epoch 20/20 - Loss: 0.2798 | Acc: 0.2992 | Macro F1: 0.2271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"MLP model result\")\n",
        "# ====== ✅ 测试阶段：Raw + Soft Threshold ======\n",
        "model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "model.eval()\n",
        "\n",
        "soft_preds, raw_preds, truths = [], [], []\n",
        "proba_all = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_X, batch_y in test_loader:\n",
        "        batch_X = batch_X.to(DEVICE)\n",
        "        logits = model(batch_X)\n",
        "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
        "        preds = np.argmax(probs, axis=1)\n",
        "\n",
        "        raw_preds.extend(preds)\n",
        "        truths.extend(batch_y.numpy())\n",
        "        proba_all.extend(probs)\n",
        "\n",
        "# numpy 化\n",
        "y_test = np.array(truths)\n",
        "y_pred_raw = np.array(raw_preds)\n",
        "y_proba = np.array(proba_all)\n",
        "\n",
        "# ========= 原始预测评估 =========\n",
        "print(\"\\n[Raw Prediction] Test Results:\")\n",
        "\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_raw, target_names=le.classes_, zero_division=0))\n",
        "\n",
        "# print(\"Accuracy:\", accuracy_score(y_test, y_pred_raw))\n",
        "macro_f1 = f1_score(y_test, y_pred_raw, average=\"macro\")\n",
        "acc = accuracy_score(y_test, y_pred_raw)\n",
        "print(f\"Macro F1-score: {macro_f1:.4f}, Accuracy: {acc:.4f}\")\n",
        "\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_raw))\n",
        "\n",
        "\n",
        "# ========= soft threshold 搜索 + 最优组合预测 =========\n",
        "from itertools import product\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "stage_i_range   = [0.2, 0.3, 0.4, 0.5]\n",
        "stage_ii_range  = [0.4, 0.5, 0.6, 0.7]\n",
        "stage_iii_range = [0.2, 0.3, 0.4, 0.5]\n",
        "stage_iv_range  = [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
        "\n",
        "results = []\n",
        "class2index = {cls: i for i, cls in enumerate(le.classes_)}\n",
        "stage_iv_idx = class2index[\"Stage IV\"]\n",
        "stage_i_idx = class2index[\"Stage I\"]\n",
        "\n",
        "for th_i, th_ii, th_iii, th_iv in product(stage_i_range, stage_ii_range, stage_iii_range, stage_iv_range):\n",
        "    thresholds = {\n",
        "        \"Stage I\": th_i,\n",
        "        \"Stage II\": th_ii,\n",
        "        \"Stage III\": th_iii,\n",
        "        \"Stage IV\": th_iv\n",
        "    }\n",
        "\n",
        "    y_pred = np.copy(y_pred_raw)\n",
        "    for i in range(len(y_pred)):\n",
        "        if y_proba[i][class2index[\"Stage IV\"]] > thresholds[\"Stage IV\"]:\n",
        "            y_pred[i] = class2index[\"Stage IV\"]\n",
        "        elif y_proba[i][class2index[\"Stage III\"]] > thresholds[\"Stage III\"]:\n",
        "            y_pred[i] = class2index[\"Stage III\"]\n",
        "        elif y_proba[i][class2index[\"Stage I\"]] > thresholds[\"Stage I\"]:\n",
        "            y_pred[i] = class2index[\"Stage I\"]\n",
        "        elif y_proba[i][class2index[\"Stage II\"]] > thresholds[\"Stage II\"]:\n",
        "            y_pred[i] = class2index[\"Stage II\"]\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None, zero_division=0)\n",
        "    macro_f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
        "\n",
        "    results.append({\n",
        "        \"Stage I Thresh\": th_i,\n",
        "        \"Stage II Thresh\": th_ii,\n",
        "        \"Stage III Thresh\": th_iii,\n",
        "        \"Stage IV Thresh\": th_iv,\n",
        "        \"Macro F1\": macro_f1,\n",
        "        \"Stage IV Recall\": recall[stage_iv_idx],\n",
        "        \"Stage I Precision\": precision[stage_i_idx],\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"y_pred\": y_pred\n",
        "    })\n",
        "\n",
        "# ========= 结果展示 =========\n",
        "results_df = pd.DataFrame(results).sort_values(\"Macro F1\", ascending=False)\n",
        "\n",
        "# # 展示前10\n",
        "# from IPython.display import display\n",
        "# display(results_df.head(10))\n",
        "\n",
        "# ========= 使用最佳组合评估 =========\n",
        "best_result = results_df.iloc[0]\n",
        "best_pred = best_result[\"y_pred\"]\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, best_pred, target_names=le.classes_, zero_division=0))\n",
        "\n",
        "# print(\"Accuracy:\", accuracy_score(y_test, best_pred))\n",
        "macro_f1 = f1_score(y_test, best_pred, average=\"macro\")\n",
        "acc = accuracy_score(y_test, best_pred)\n",
        "print(f\"Macro F1-score: {macro_f1:.4f}, Accuracy: {acc:.4f}\")\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, best_pred))\n",
        "\n",
        "# ========= 可视化混淆矩阵 =========\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "cm = confusion_matrix(y_test, best_pred)\n",
        "df_cm = pd.DataFrame(cm, index=le.classes_, columns=le.classes_)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title(\"MLP Confusion Matrix (Best Soft Thresholds)\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NFuv0aZ_DwLb",
        "outputId": "29ac55c2-6cb9-400e-cc22-77baaa63998b"
      },
      "id": "NFuv0aZ_DwLb",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP model result\n",
            "\n",
            "[Raw Prediction] Test Results:\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Stage I       0.27      0.28      0.27        40\n",
            "    Stage II       0.65      0.68      0.66       139\n",
            "   Stage III       0.40      0.36      0.38        55\n",
            "    Stage IV       0.12      0.10      0.11        10\n",
            "\n",
            "    accuracy                           0.52       244\n",
            "   macro avg       0.36      0.35      0.36       244\n",
            "weighted avg       0.51      0.52      0.51       244\n",
            "\n",
            "Macro F1-score: 0.3564, Accuracy: 0.5164\n",
            "Confusion Matrix:\n",
            "[[11 22  7  0]\n",
            " [23 94 20  2]\n",
            " [ 7 23 20  5]\n",
            " [ 0  6  3  1]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Stage I       0.30      0.28      0.29        40\n",
            "    Stage II       0.67      0.68      0.67       139\n",
            "   Stage III       0.43      0.36      0.40        55\n",
            "    Stage IV       0.15      0.30      0.20        10\n",
            "\n",
            "    accuracy                           0.52       244\n",
            "   macro avg       0.39      0.40      0.39       244\n",
            "weighted avg       0.53      0.52      0.53       244\n",
            "\n",
            "Macro F1-score: 0.3883, Accuracy: 0.5246\n",
            "Confusion Matrix:\n",
            "[[11 21  6  2]\n",
            " [19 94 19  7]\n",
            " [ 7 20 20  8]\n",
            " [ 0  6  1  3]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3jzqmod0FTdc"
      },
      "id": "3jzqmod0FTdc",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}