{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "wm4KwJjzASvx",
        "outputId": "69a10f28-b23a-468c-a3ba-e64a8a3eab74"
      },
      "outputs": [],
      "source": [
        "# !pip install scanpy\n",
        "# !pip install flwr\n",
        "# !pip install autogluon\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvdhOXrma8on"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "TwiNiQvoAMBp",
        "outputId": "f2fdd30e-c4e9-4c60-cf6d-23b6ce894c65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=110eYMgseyD32YIS9xOMbOpJ76wnDXahR\n",
            "From (redirected): https://drive.google.com/uc?id=110eYMgseyD32YIS9xOMbOpJ76wnDXahR&confirm=t&uuid=282f912a-0aaa-41fa-9658-f3457e79f71c\n",
            "To: /Users/xin/Desktop/DATA5703/Git/TCGA-DNA-RNA-IMAGE-stage-classifier/RNA/Week11/TCGA_BRCA_RNA_with_TinX.h5ad\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 574M/574M [01:26<00:00, 6.63MB/s] \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'TCGA_BRCA_RNA_with_TinX.h5ad'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"SCIPY_ARRAY_API\"] = \"1\"\n",
        "\n",
        "import gdown\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import anndata as ad\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from scipy.sparse import issparse\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import lightgbm as lgb\n",
        "import joblib\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "# Config\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "\n",
        "file_id = \"110eYMgseyD32YIS9xOMbOpJ76wnDXahR\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output=\"TCGA_BRCA_RNA_with_TinX.h5ad\", quiet=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd4slBRIANxm",
        "outputId": "cdb695d1-621d-4ab4-ec41-7d6e64d65df1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All patient_id(s) in test_metadata.csv are present in the .h5ad dataset.\n",
            "All test samples successfully mapped to stage labels.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/yy/s74n5fc53gv5mw5gdw5l8ch40000gn/T/ipykernel_85757/3291985456.py:54: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
            "  adata_test.obs[\"stage\"] = adata_test.obs[\"patient_id\"].map(patient_to_stage)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training and test sets saved:\n",
            "Test samples: 28 â†’ RNA_test.h5ad\n",
            "Train samples: 1202 â†’ RNA_train.h5ad\n",
            "Test label distribution:\n",
            "stage\n",
            "Stage II     14\n",
            "Stage III     7\n",
            "Stage I       6\n",
            "Stage IV      1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import scanpy as sc\n",
        "import pandas as pd\n",
        "\n",
        "# === Paths ===\n",
        "adata_path = \"TCGA_BRCA_RNA_with_TinX.h5ad\"\n",
        "test_csv_path = \"test_metadata_THENEWEST - 28.csv\"\n",
        "train_h5ad_path = \"RNA_train.h5ad\"\n",
        "test_h5ad_path = \"RNA_test.h5ad\"\n",
        "\n",
        "# === Label mappings ===\n",
        "label_map = {\n",
        "    \"Stage I\": 0,\n",
        "    \"Stage II\": 1,\n",
        "    \"Stage III\": 2,\n",
        "    \"Stage IV\": 3,\n",
        "}\n",
        "stage_map = {\n",
        "    \"Stage1\": \"Stage I\",\n",
        "    \"Stage2\": \"Stage II\",\n",
        "    \"Stage3\": \"Stage III\",\n",
        "    \"Stage4\": \"Stage IV\",\n",
        "}\n",
        "\n",
        "# === Load .h5ad data ===\n",
        "adata = sc.read_h5ad(adata_path)\n",
        "adata.obs[\"patient_id\"] = adata.obs[\"patient_id\"].astype(str)\n",
        "\n",
        "# === Load test_metadata.csv and fix label format ===\n",
        "test_df = pd.read_csv(test_csv_path)\n",
        "test_df[\"patient_id\"] = test_df[\"patient_id\"].astype(str)\n",
        "test_df[\"label\"] = test_df[\"label\"].str.strip()\n",
        "test_df[\"stage\"] = test_df[\"label\"].map(stage_map)  # Convert e.g. \"Stage4\" â†’ \"Stage IV\"\n",
        "\n",
        "# === ðŸ” Check patient ID consistency ===\n",
        "csv_patient_ids = set(test_df[\"patient_id\"])\n",
        "adata_patient_ids = set(adata.obs[\"patient_id\"])\n",
        "missing_in_adata = csv_patient_ids - adata_patient_ids\n",
        "if missing_in_adata:\n",
        "    print(\"The following patient_id(s) exist in test_metadata.csv but were not found in .h5ad:\")\n",
        "    print(missing_in_adata)\n",
        "else:\n",
        "    print(\"All patient_id(s) in test_metadata.csv are present in the .h5ad dataset.\")\n",
        "\n",
        "# === 1. Extract test set by patient ID ===\n",
        "test_patients = set(test_df[\"patient_id\"])\n",
        "is_test = adata.obs[\"patient_id\"].isin(test_patients)\n",
        "adata_test = adata[is_test].copy()\n",
        "\n",
        "# De-duplicate: keep only one sample per patient_id\n",
        "adata_test = adata_test[adata_test.obs.groupby(\"patient_id\").head(1).index]\n",
        "\n",
        "# Assign correct stage labels from test_metadata.csv\n",
        "patient_to_stage = dict(zip(test_df[\"patient_id\"], test_df[\"stage\"]))\n",
        "adata_test.obs[\"stage\"] = adata_test.obs[\"patient_id\"].map(patient_to_stage)\n",
        "\n",
        "# === ðŸ” Check for unmapped test samples ===\n",
        "unmapped = adata_test.obs[adata_test.obs[\"stage\"].isna()]\n",
        "if not unmapped.empty:\n",
        "    print(\"The following patient_id(s) were found in .h5ad but failed to map a stage label:\")\n",
        "    print(unmapped[\"patient_id\"].tolist())\n",
        "else:\n",
        "    print(\"All test samples successfully mapped to stage labels.\")\n",
        "\n",
        "# === 2. The rest are used as training set ===\n",
        "adata_train = adata[~is_test].copy()\n",
        "\n",
        "# === Save output files ===\n",
        "adata_train.write(train_h5ad_path)\n",
        "adata_test.write(test_h5ad_path)\n",
        "\n",
        "# === Final summary ===\n",
        "print(\"Training and test sets saved:\")\n",
        "print(\"Test samples:\", adata_test.shape[0], \"â†’\", test_h5ad_path)\n",
        "print(\"Train samples:\", adata_train.shape[0], \"â†’\", train_h5ad_path)\n",
        "print(\"Test label distribution:\")\n",
        "print(adata_test.obs[\"stage\"].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Gl2MGBGbC61"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pQcd1G_IGGDu",
        "outputId": "a31acb58-9f9b-41f6-cdc9-4af7d1f353f3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:110: UserWarning: Features [17916 18434 19255 20000 20704 21144 22796 22865 23559 23594 25051 25096\n",
            " 25475 25494 25613 25876 25943 26696 27209 27544 27847 28210 30227 30553\n",
            " 31799 32852 33003 33969 34230 40615 42909 43522 45975 46464 46819 47370\n",
            " 47517 49278 49295 49614 49621 49733 50585 52248 52416 52832 53689 53724\n",
            " 54163 54475 55028 55904] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.4.0\n",
            "Python Version:     3.12.2\n",
            "Operating System:   Darwin\n",
            "Platform Machine:   arm64\n",
            "Platform Version:   Darwin Kernel Version 24.6.0: Mon Jul 14 11:29:54 PDT 2025; root:xnu-11417.140.69~1/RELEASE_ARM64_T8122\n",
            "CPU Count:          8\n",
            "Memory Avail:       3.29 GB / 16.00 GB (20.6%)\n",
            "Disk Space Avail:   122.69 GB / 460.43 GB (26.6%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "Setting dynamic_stacking from 'auto' to False. Reason: Skip dynamic_stacking when use_bag_holdout is enabled. (use_bag_holdout=True)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "Beginning AutoGluon training ... Time limit = 1800s\n",
            "AutoGluon will save models to \"/Users/xin/Desktop/DATA5703/Git/TCGA-DNA-RNA-IMAGE-stage-classifier/RNA/Week11/autogluon_rna_model\"\n",
            "Train Data Rows:    2204\n",
            "Train Data Columns: 1000\n",
            "Tuning Data Rows:    241\n",
            "Tuning Data Columns: 1000\n",
            "Label Column:       stage\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 4\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    3337.20 MB\n",
            "\tTrain Data (Original)  Memory Usage: 18.65 MB (0.6% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 1000 | ['0', '1', '2', '3', '4', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 1000 | ['0', '1', '2', '3', '4', ...]\n",
            "\t0.8s = Fit runtime\n",
            "\t1000 features in original data used to generate 1000 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 18.65 MB (0.6% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.85s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'GBM': [{'ag_args_fit': {'hyperparameter_tune_kwargs': 'auto'}}],\n",
            "\t'CAT': [{'ag_args_fit': {'hyperparameter_tune_kwargs': 'auto'}}],\n",
            "\t'XGB': [{'ag_args_fit': {'hyperparameter_tune_kwargs': 'auto'}}],\n",
            "\t'RF': [{'ag_args_fit': {'hyperparameter_tune_kwargs': 'auto'}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 4 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1199.13s of the 1799.15s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=9.57%)\n",
            "\t0.7094\t = Validation score   (f1_weighted)\n",
            "\t76.67s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: RandomForest_BAG_L1 ... Training model for up to 1118.35s of the 1718.37s of remaining time.\n",
            "\t0.5261\t = Validation score   (f1_weighted)\n",
            "\t1.55s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1116.42s of the 1716.44s of remaining time.\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 30.17% memory usage per fold, 60.35%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=30.17%)\n",
            "\t0.7007\t = Validation score   (f1_weighted)\n",
            "\t897.82s\t = Training   runtime\n",
            "\t0.33s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ... Training model for up to 216.36s of the 816.38s of remaining time.\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 14.74% memory usage per fold, 58.98%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=14.74%)\n",
            "\t0.7138\t = Validation score   (f1_weighted)\n",
            "\t113.83s\t = Training   runtime\n",
            "\t0.18s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 699.77s of remaining time.\n",
            "\tEnsemble Weights: {'XGBoost_BAG_L1': 1.0}\n",
            "\t0.7138\t = Validation score   (f1_weighted)\n",
            "\t0.08s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 4 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 699.68s of the 699.67s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=8.20%)\n",
            "\t0.5746\t = Validation score   (f1_weighted)\n",
            "\t84.59s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: RandomForest_BAG_L2 ... Training model for up to 611.93s of the 611.91s of remaining time.\n",
            "\t0.6647\t = Validation score   (f1_weighted)\n",
            "\t1.66s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ... Training model for up to 609.84s of the 609.82s of remaining time.\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 32.69% memory usage per fold, 65.38%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=32.69%)\n",
            "\t0.5861\t = Validation score   (f1_weighted)\n",
            "\t492.32s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L2 ... Training model for up to 115.42s of the 115.41s of remaining time.\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 13.92% memory usage per fold, 55.66%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=13.92%)\n",
            "\t0.6046\t = Validation score   (f1_weighted)\n",
            "\t74.02s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 38.60s of remaining time.\n",
            "\tEnsemble Weights: {'RandomForest_BAG_L2': 0.458, 'XGBoost_BAG_L1': 0.333, 'LightGBM_BAG_L1': 0.208}\n",
            "\t0.7215\t = Validation score   (f1_weighted)\n",
            "\t0.08s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 1761.5s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 366.6 rows/s (241 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/xin/Desktop/DATA5703/Git/TCGA-DNA-RNA-IMAGE-stage-classifier/RNA/Week11/autogluon_rna_model\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x31917ff50>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import anndata as ad\n",
        "import joblib\n",
        "from scipy.sparse import issparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "\n",
        "# === File paths ===\n",
        "scaler_path = \"RNA_scaler.pkl\"\n",
        "selector_path = \"RNA_selector_kbest.pkl\"\n",
        "autogluon_model_path = \"autogluon_rna_model\"\n",
        "\n",
        "# === 1. Load data ===\n",
        "adata = ad.read_h5ad(train_h5ad_path)\n",
        "X = adata.X.toarray() if issparse(adata.X) else adata.X\n",
        "y_raw = adata.obs[\"stage\"].values\n",
        "label_map = {\"Stage I\": 0, \"Stage II\": 1, \"Stage III\": 2, \"Stage IV\": 3}\n",
        "label_names = list(label_map.keys())\n",
        "y = np.array([label_map.get(s, 3) for s in y_raw])  # Default to Stage IV if unknown\n",
        "\n",
        "# === 2. Sample-level cleaning ===\n",
        "expr_sum = X.sum(axis=1)\n",
        "z_scores = (expr_sum - np.mean(expr_sum)) / np.std(expr_sum)\n",
        "mask = np.abs(z_scores) < 3\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# === 3. Train-validation split ===\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# === 4. Scaling ===\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "joblib.dump(scaler, scaler_path)\n",
        "\n",
        "# === 5. SelectKBest Feature Selection ===\n",
        "selector = SelectKBest(score_func=f_classif, k=1000)\n",
        "X_train_sel = selector.fit_transform(X_train_scaled, y_train)\n",
        "X_val_sel = selector.transform(X_val_scaled)\n",
        "joblib.dump(selector, selector_path)\n",
        "\n",
        "# === 6. SMOTE Over-sampling ===\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train_sel, y_train)\n",
        "\n",
        "# === 7. Prepare for AutoGluon ===\n",
        "train_df = pd.DataFrame(X_resampled)\n",
        "train_df[\"stage\"] = y_resampled\n",
        "val_df = pd.DataFrame(X_val_sel)\n",
        "val_df[\"stage\"] = y_val\n",
        "\n",
        "train_data = TabularDataset(train_df)\n",
        "val_data = TabularDataset(val_df)\n",
        "\n",
        "# === 8. AutoGluon Training with GPU models and more time ===\n",
        "predictor = TabularPredictor(\n",
        "    label=\"stage\",\n",
        "    path=autogluon_model_path,\n",
        "    eval_metric=\"f1_weighted\",\n",
        "    problem_type=\"multiclass\"\n",
        ")\n",
        "predictor.fit(\n",
        "    train_data=train_data,\n",
        "    tuning_data=val_data,\n",
        "    use_bag_holdout=True,\n",
        "    # num_bag_folds=5,\n",
        "    # num_stack_levels=1,\n",
        "    time_limit=1800,\n",
        "    presets=\"best_quality\",\n",
        "    hyperparameters={\n",
        "        \"GBM\": {\"ag_args_fit\": {\"hyperparameter_tune_kwargs\": \"auto\"}},\n",
        "        \"CAT\": {\"ag_args_fit\": {\"hyperparameter_tune_kwargs\": \"auto\"}},\n",
        "        \"XGB\": {\"ag_args_fit\": {\"hyperparameter_tune_kwargs\": \"auto\"}},\n",
        "        \"RF\":  {\"ag_args_fit\": {\"hyperparameter_tune_kwargs\": \"auto\"}}\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31cSR1gXcIJm",
        "outputId": "5b9fbf7c-0182-4e64-cfd8-42b4a4ac0b85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Stage I       0.66      1.00      0.80        39\n",
            "    Stage II       0.83      0.79      0.81       139\n",
            "   Stage III       0.59      0.54      0.56        54\n",
            "    Stage IV       0.00      0.00      0.00         9\n",
            "\n",
            "    accuracy                           0.74       241\n",
            "   macro avg       0.52      0.58      0.54       241\n",
            "weighted avg       0.72      0.74      0.72       241\n",
            "\n",
            "Confusion Matrix:\n",
            "           Stage I  Stage II  Stage III  Stage IV\n",
            "Stage I         39         0          0         0\n",
            "Stage II        13       110         16         0\n",
            "Stage III        6        19         29         0\n",
            "Stage IV         1         4          4         0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        }
      ],
      "source": [
        "# === 9. Evaluation ===\n",
        "val_preds = predictor.predict(val_data.drop(columns=[\"stage\"]))\n",
        "print(\"Validation Classification Report:\")\n",
        "print(classification_report(val_data[\"stage\"], val_preds, target_names=label_names))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(pd.DataFrame(confusion_matrix(val_data[\"stage\"], val_preds), index=label_names, columns=label_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "collapsed": true,
        "id": "iN6MrztfV8_p",
        "outputId": "237ad54f-5425-4c5b-e1fd-6edb14a410d3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_test</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_test</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_test_marginal</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WeightedEnsemble_L3</td>\n",
              "      <td>0.721473</td>\n",
              "      <td>0.721473</td>\n",
              "      <td>f1_weighted</td>\n",
              "      <td>0.448609</td>\n",
              "      <td>0.657370</td>\n",
              "      <td>1091.608685</td>\n",
              "      <td>0.001092</td>\n",
              "      <td>0.001050</td>\n",
              "      <td>0.080143</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XGBoost_BAG_L1</td>\n",
              "      <td>0.713832</td>\n",
              "      <td>0.713832</td>\n",
              "      <td>f1_weighted</td>\n",
              "      <td>0.157080</td>\n",
              "      <td>0.175822</td>\n",
              "      <td>113.830715</td>\n",
              "      <td>0.157080</td>\n",
              "      <td>0.175822</td>\n",
              "      <td>113.830715</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>0.713832</td>\n",
              "      <td>0.713832</td>\n",
              "      <td>f1_weighted</td>\n",
              "      <td>0.158607</td>\n",
              "      <td>0.177003</td>\n",
              "      <td>113.911689</td>\n",
              "      <td>0.001527</td>\n",
              "      <td>0.001181</td>\n",
              "      <td>0.080974</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LightGBM_BAG_L1</td>\n",
              "      <td>0.709395</td>\n",
              "      <td>0.709395</td>\n",
              "      <td>f1_weighted</td>\n",
              "      <td>0.137733</td>\n",
              "      <td>0.091315</td>\n",
              "      <td>76.668195</td>\n",
              "      <td>0.137733</td>\n",
              "      <td>0.091315</td>\n",
              "      <td>76.668195</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CatBoost_BAG_L1</td>\n",
              "      <td>0.700685</td>\n",
              "      <td>0.700685</td>\n",
              "      <td>f1_weighted</td>\n",
              "      <td>0.078468</td>\n",
              "      <td>0.329234</td>\n",
              "      <td>897.823853</td>\n",
              "      <td>0.078468</td>\n",
              "      <td>0.329234</td>\n",
              "      <td>897.823853</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RandomForest_BAG_L2</td>\n",
              "      <td>0.664678</td>\n",
              "      <td>0.664678</td>\n",
              "      <td>f1_weighted</td>\n",
              "      <td>0.447517</td>\n",
              "      <td>0.656320</td>\n",
              "      <td>1091.528543</td>\n",
              "      <td>0.037576</td>\n",
              "      <td>0.025215</td>\n",
              "      <td>1.655122</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>XGBoost_BAG_L2</td>\n",
              "      <td>0.604620</td>\n",
              "      <td>0.604620</td>\n",
              "      <td>f1_weighted</td>\n",
              "      <td>0.556244</td>\n",
              "      <td>0.788320</td>\n",
              "      <td>1163.895713</td>\n",
              "      <td>0.146303</td>\n",
              "      <td>0.157215</td>\n",
              "      <td>74.022292</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>CatBoost_BAG_L2</td>\n",
              "      <td>0.586102</td>\n",
              "      <td>0.586102</td>\n",
              "      <td>f1_weighted</td>\n",
              "      <td>0.511169</td>\n",
              "      <td>0.712035</td>\n",
              "      <td>1582.191760</td>\n",
              "      <td>0.101228</td>\n",
              "      <td>0.080930</td>\n",
              "      <td>492.318339</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LightGBM_BAG_L2</td>\n",
              "      <td>0.574568</td>\n",
              "      <td>0.574568</td>\n",
              "      <td>f1_weighted</td>\n",
              "      <td>0.490648</td>\n",
              "      <td>0.717419</td>\n",
              "      <td>1174.462964</td>\n",
              "      <td>0.080707</td>\n",
              "      <td>0.086315</td>\n",
              "      <td>84.589543</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RandomForest_BAG_L1</td>\n",
              "      <td>0.526147</td>\n",
              "      <td>0.526147</td>\n",
              "      <td>f1_weighted</td>\n",
              "      <td>0.036660</td>\n",
              "      <td>0.034733</td>\n",
              "      <td>1.550658</td>\n",
              "      <td>0.036660</td>\n",
              "      <td>0.034733</td>\n",
              "      <td>1.550658</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 model  score_test  score_val  eval_metric  pred_time_test  \\\n",
              "0  WeightedEnsemble_L3    0.721473   0.721473  f1_weighted        0.448609   \n",
              "1       XGBoost_BAG_L1    0.713832   0.713832  f1_weighted        0.157080   \n",
              "2  WeightedEnsemble_L2    0.713832   0.713832  f1_weighted        0.158607   \n",
              "3      LightGBM_BAG_L1    0.709395   0.709395  f1_weighted        0.137733   \n",
              "4      CatBoost_BAG_L1    0.700685   0.700685  f1_weighted        0.078468   \n",
              "5  RandomForest_BAG_L2    0.664678   0.664678  f1_weighted        0.447517   \n",
              "6       XGBoost_BAG_L2    0.604620   0.604620  f1_weighted        0.556244   \n",
              "7      CatBoost_BAG_L2    0.586102   0.586102  f1_weighted        0.511169   \n",
              "8      LightGBM_BAG_L2    0.574568   0.574568  f1_weighted        0.490648   \n",
              "9  RandomForest_BAG_L1    0.526147   0.526147  f1_weighted        0.036660   \n",
              "\n",
              "   pred_time_val     fit_time  pred_time_test_marginal  \\\n",
              "0       0.657370  1091.608685                 0.001092   \n",
              "1       0.175822   113.830715                 0.157080   \n",
              "2       0.177003   113.911689                 0.001527   \n",
              "3       0.091315    76.668195                 0.137733   \n",
              "4       0.329234   897.823853                 0.078468   \n",
              "5       0.656320  1091.528543                 0.037576   \n",
              "6       0.788320  1163.895713                 0.146303   \n",
              "7       0.712035  1582.191760                 0.101228   \n",
              "8       0.717419  1174.462964                 0.080707   \n",
              "9       0.034733     1.550658                 0.036660   \n",
              "\n",
              "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              "0                0.001050           0.080143            3       True   \n",
              "1                0.175822         113.830715            1       True   \n",
              "2                0.001181           0.080974            2       True   \n",
              "3                0.091315          76.668195            1       True   \n",
              "4                0.329234         897.823853            1       True   \n",
              "5                0.025215           1.655122            2       True   \n",
              "6                0.157215          74.022292            2       True   \n",
              "7                0.080930         492.318339            2       True   \n",
              "8                0.086315          84.589543            2       True   \n",
              "9                0.034733           1.550658            1       True   \n",
              "\n",
              "   fit_order  \n",
              "0         10  \n",
              "1          4  \n",
              "2          5  \n",
              "3          1  \n",
              "4          3  \n",
              "5          7  \n",
              "6          9  \n",
              "7          8  \n",
              "8          6  \n",
              "9          2  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.leaderboard(val_data, silent=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JfYjw0YnWAFy",
        "outputId": "a4c521b2-2b8d-41ce-eb18-a2fc944aefc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                 model  score_val  eval_metric  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0  WeightedEnsemble_L3   0.721473  f1_weighted       0.657370  1091.608685                0.001050           0.080143            3       True         10\n",
            "1       XGBoost_BAG_L1   0.713832  f1_weighted       0.175822   113.830715                0.175822         113.830715            1       True          4\n",
            "2  WeightedEnsemble_L2   0.713832  f1_weighted       0.177003   113.911689                0.001181           0.080974            2       True          5\n",
            "3      LightGBM_BAG_L1   0.709395  f1_weighted       0.091315    76.668195                0.091315          76.668195            1       True          1\n",
            "4      CatBoost_BAG_L1   0.700685  f1_weighted       0.329234   897.823853                0.329234         897.823853            1       True          3\n",
            "5  RandomForest_BAG_L2   0.664678  f1_weighted       0.656320  1091.528543                0.025215           1.655122            2       True          7\n",
            "6       XGBoost_BAG_L2   0.604620  f1_weighted       0.788320  1163.895713                0.157215          74.022292            2       True          9\n",
            "7      CatBoost_BAG_L2   0.586102  f1_weighted       0.712035  1582.191760                0.080930         492.318339            2       True          8\n",
            "8      LightGBM_BAG_L2   0.574568  f1_weighted       0.717419  1174.462964                0.086315          84.589543            2       True          6\n",
            "9  RandomForest_BAG_L1   0.526147  f1_weighted       0.034733     1.550658                0.034733           1.550658            1       True          2\n",
            "Number of models trained: 10\n",
            "Types of models trained:\n",
            "{'StackerEnsembleModel_LGB', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_CatBoost', 'WeightedEnsembleModel'}\n",
            "Bagging used: True  (with 8 folds)\n",
            "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('float', []) : 1000 | ['0', '1', '2', '3', '4', ...]\n",
            "Plot summary of models saved to file: /Users/xin/Desktop/DATA5703/Git/TCGA-DNA-RNA-IMAGE-stage-classifier/RNA/Week11/autogluon_rna_model/SummaryOfModels.html\n",
            "*** End of fit() summary ***\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'model_types': {'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
              "  'RandomForest_BAG_L1': 'StackerEnsembleModel_RF',\n",
              "  'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
              "  'XGBoost_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
              "  'WeightedEnsemble_L2': 'WeightedEnsembleModel',\n",
              "  'LightGBM_BAG_L2': 'StackerEnsembleModel_LGB',\n",
              "  'RandomForest_BAG_L2': 'StackerEnsembleModel_RF',\n",
              "  'CatBoost_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
              "  'XGBoost_BAG_L2': 'StackerEnsembleModel_XGBoost',\n",
              "  'WeightedEnsemble_L3': 'WeightedEnsembleModel'},\n",
              " 'model_performance': {'LightGBM_BAG_L1': 0.7093947031998783,\n",
              "  'RandomForest_BAG_L1': 0.5261471983368422,\n",
              "  'CatBoost_BAG_L1': 0.7006854228665891,\n",
              "  'XGBoost_BAG_L1': 0.7138316614185216,\n",
              "  'WeightedEnsemble_L2': 0.7138316614185216,\n",
              "  'LightGBM_BAG_L2': 0.5745684279509564,\n",
              "  'RandomForest_BAG_L2': 0.6646779596012864,\n",
              "  'CatBoost_BAG_L2': 0.5861021964295893,\n",
              "  'XGBoost_BAG_L2': 0.6046196226392491,\n",
              "  'WeightedEnsemble_L3': 0.7214732527180796},\n",
              " 'model_best': 'WeightedEnsemble_L3',\n",
              " 'model_paths': {'LightGBM_BAG_L1': ['LightGBM_BAG_L1'],\n",
              "  'RandomForest_BAG_L1': ['RandomForest_BAG_L1'],\n",
              "  'CatBoost_BAG_L1': ['CatBoost_BAG_L1'],\n",
              "  'XGBoost_BAG_L1': ['XGBoost_BAG_L1'],\n",
              "  'WeightedEnsemble_L2': ['WeightedEnsemble_L2'],\n",
              "  'LightGBM_BAG_L2': ['LightGBM_BAG_L2'],\n",
              "  'RandomForest_BAG_L2': ['RandomForest_BAG_L2'],\n",
              "  'CatBoost_BAG_L2': ['CatBoost_BAG_L2'],\n",
              "  'XGBoost_BAG_L2': ['XGBoost_BAG_L2'],\n",
              "  'WeightedEnsemble_L3': ['WeightedEnsemble_L3']},\n",
              " 'model_fit_times': {'LightGBM_BAG_L1': 76.66819500923157,\n",
              "  'RandomForest_BAG_L1': 1.5506579875946045,\n",
              "  'CatBoost_BAG_L1': 897.8238527774811,\n",
              "  'XGBoost_BAG_L1': 113.83071494102478,\n",
              "  'WeightedEnsemble_L2': 0.08097410202026367,\n",
              "  'LightGBM_BAG_L2': 84.58954286575317,\n",
              "  'RandomForest_BAG_L2': 1.6551220417022705,\n",
              "  'CatBoost_BAG_L2': 492.3183391094208,\n",
              "  'XGBoost_BAG_L2': 74.02229189872742,\n",
              "  'WeightedEnsemble_L3': 0.08014273643493652},\n",
              " 'model_pred_times': {'LightGBM_BAG_L1': 0.09131503105163574,\n",
              "  'RandomForest_BAG_L1': 0.03473305702209473,\n",
              "  'CatBoost_BAG_L1': 0.32923412322998047,\n",
              "  'XGBoost_BAG_L1': 0.17582225799560547,\n",
              "  'WeightedEnsemble_L2': 0.0011811256408691406,\n",
              "  'LightGBM_BAG_L2': 0.08631491661071777,\n",
              "  'RandomForest_BAG_L2': 0.02521514892578125,\n",
              "  'CatBoost_BAG_L2': 0.08093023300170898,\n",
              "  'XGBoost_BAG_L2': 0.15721511840820312,\n",
              "  'WeightedEnsemble_L3': 0.0010499954223632812},\n",
              " 'num_bag_folds': 8,\n",
              " 'max_stack_level': 3,\n",
              " 'num_classes': 4,\n",
              " 'model_hyperparams': {'LightGBM_BAG_L1': {'use_orig_features': True,\n",
              "   'valid_stacker': True,\n",
              "   'max_base_models': 0,\n",
              "   'max_base_models_per_type': 'auto',\n",
              "   'save_bag_folds': True,\n",
              "   'stratify': 'auto',\n",
              "   'bin': 'auto',\n",
              "   'n_bins': None},\n",
              "  'RandomForest_BAG_L1': {'use_orig_features': True,\n",
              "   'valid_stacker': True,\n",
              "   'max_base_models': 0,\n",
              "   'max_base_models_per_type': 'auto',\n",
              "   'save_bag_folds': True,\n",
              "   'stratify': 'auto',\n",
              "   'bin': 'auto',\n",
              "   'n_bins': None,\n",
              "   'use_child_oof': True},\n",
              "  'CatBoost_BAG_L1': {'use_orig_features': True,\n",
              "   'valid_stacker': True,\n",
              "   'max_base_models': 0,\n",
              "   'max_base_models_per_type': 'auto',\n",
              "   'save_bag_folds': True,\n",
              "   'stratify': 'auto',\n",
              "   'bin': 'auto',\n",
              "   'n_bins': None},\n",
              "  'XGBoost_BAG_L1': {'use_orig_features': True,\n",
              "   'valid_stacker': True,\n",
              "   'max_base_models': 0,\n",
              "   'max_base_models_per_type': 'auto',\n",
              "   'save_bag_folds': True,\n",
              "   'stratify': 'auto',\n",
              "   'bin': 'auto',\n",
              "   'n_bins': None},\n",
              "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
              "   'valid_stacker': True,\n",
              "   'max_base_models': 0,\n",
              "   'max_base_models_per_type': 'auto',\n",
              "   'save_bag_folds': True,\n",
              "   'stratify': 'auto',\n",
              "   'bin': 'auto',\n",
              "   'n_bins': None},\n",
              "  'LightGBM_BAG_L2': {'use_orig_features': True,\n",
              "   'valid_stacker': True,\n",
              "   'max_base_models': 0,\n",
              "   'max_base_models_per_type': 'auto',\n",
              "   'save_bag_folds': True,\n",
              "   'stratify': 'auto',\n",
              "   'bin': 'auto',\n",
              "   'n_bins': None},\n",
              "  'RandomForest_BAG_L2': {'use_orig_features': True,\n",
              "   'valid_stacker': True,\n",
              "   'max_base_models': 0,\n",
              "   'max_base_models_per_type': 'auto',\n",
              "   'save_bag_folds': True,\n",
              "   'stratify': 'auto',\n",
              "   'bin': 'auto',\n",
              "   'n_bins': None,\n",
              "   'use_child_oof': True},\n",
              "  'CatBoost_BAG_L2': {'use_orig_features': True,\n",
              "   'valid_stacker': True,\n",
              "   'max_base_models': 0,\n",
              "   'max_base_models_per_type': 'auto',\n",
              "   'save_bag_folds': True,\n",
              "   'stratify': 'auto',\n",
              "   'bin': 'auto',\n",
              "   'n_bins': None},\n",
              "  'XGBoost_BAG_L2': {'use_orig_features': True,\n",
              "   'valid_stacker': True,\n",
              "   'max_base_models': 0,\n",
              "   'max_base_models_per_type': 'auto',\n",
              "   'save_bag_folds': True,\n",
              "   'stratify': 'auto',\n",
              "   'bin': 'auto',\n",
              "   'n_bins': None},\n",
              "  'WeightedEnsemble_L3': {'use_orig_features': False,\n",
              "   'valid_stacker': True,\n",
              "   'max_base_models': 0,\n",
              "   'max_base_models_per_type': 'auto',\n",
              "   'save_bag_folds': True,\n",
              "   'stratify': 'auto',\n",
              "   'bin': 'auto',\n",
              "   'n_bins': None}},\n",
              " 'leaderboard':                  model  score_val  eval_metric  pred_time_val     fit_time  \\\n",
              " 0  WeightedEnsemble_L3   0.721473  f1_weighted       0.657370  1091.608685   \n",
              " 1       XGBoost_BAG_L1   0.713832  f1_weighted       0.175822   113.830715   \n",
              " 2  WeightedEnsemble_L2   0.713832  f1_weighted       0.177003   113.911689   \n",
              " 3      LightGBM_BAG_L1   0.709395  f1_weighted       0.091315    76.668195   \n",
              " 4      CatBoost_BAG_L1   0.700685  f1_weighted       0.329234   897.823853   \n",
              " 5  RandomForest_BAG_L2   0.664678  f1_weighted       0.656320  1091.528543   \n",
              " 6       XGBoost_BAG_L2   0.604620  f1_weighted       0.788320  1163.895713   \n",
              " 7      CatBoost_BAG_L2   0.586102  f1_weighted       0.712035  1582.191760   \n",
              " 8      LightGBM_BAG_L2   0.574568  f1_weighted       0.717419  1174.462964   \n",
              " 9  RandomForest_BAG_L1   0.526147  f1_weighted       0.034733     1.550658   \n",
              " \n",
              "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              " 0                0.001050           0.080143            3       True   \n",
              " 1                0.175822         113.830715            1       True   \n",
              " 2                0.001181           0.080974            2       True   \n",
              " 3                0.091315          76.668195            1       True   \n",
              " 4                0.329234         897.823853            1       True   \n",
              " 5                0.025215           1.655122            2       True   \n",
              " 6                0.157215          74.022292            2       True   \n",
              " 7                0.080930         492.318339            2       True   \n",
              " 8                0.086315          84.589543            2       True   \n",
              " 9                0.034733           1.550658            1       True   \n",
              " \n",
              "    fit_order  \n",
              " 0         10  \n",
              " 1          4  \n",
              " 2          5  \n",
              " 3          1  \n",
              " 4          3  \n",
              " 5          7  \n",
              " 6          9  \n",
              " 7          8  \n",
              " 8          6  \n",
              " 9          2  }"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.fit_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crKbdU05bG-c"
      },
      "source": [
        "## Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIBZB4S3CmoY",
        "outputId": "d0759f4e-ab93-450c-e924-5cefcea13c8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server_RNA_test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Stage I       0.57      0.67      0.62         6\n",
            "    Stage II       0.71      0.71      0.71        14\n",
            "   Stage III       0.71      0.71      0.71         7\n",
            "    Stage IV       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.68        28\n",
            "   macro avg       0.50      0.52      0.51        28\n",
            "weighted avg       0.66      0.68      0.67        28\n",
            "\n",
            "Server_RNA_test Confusion Matrix:\n",
            "           Stage I  Stage II  Stage III  Stage IV\n",
            "Stage I          4         2          0         0\n",
            "Stage II         3        10          1         0\n",
            "Stage III        0         2          5         0\n",
            "Stage IV         0         0          1         0\n",
            "\n",
            "28 predictions have been generated.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import anndata as ad\n",
        "import joblib\n",
        "import json\n",
        "from scipy.sparse import issparse\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import flwr as fl\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "# ===== Parameter Settings =====\n",
        "test_h5ad_path   = \"RNA_test.h5ad\"\n",
        "scaler_path = \"RNA_scaler.pkl\"\n",
        "selector_path = \"RNA_selector_kbest.pkl\"\n",
        "autogluon_model_path = \"autogluon_rna_model\"\n",
        "\n",
        "SERVER_ADDRESS   = \"192.168.0.6:8080\"\n",
        "MODALITY         = \"RNA\"\n",
        "WEIGHT           = 0.3\n",
        "\n",
        "label_map = {\"Stage I\": 0, \"Stage II\": 1, \"Stage III\": 2, \"Stage IV\": 3}\n",
        "label_names = list(label_map.keys())\n",
        "int_to_stage = {v: k for k, v in label_map.items()}\n",
        "\n",
        "class RNAClient(fl.client.NumPyClient):\n",
        "    def __init__(self, test_h5ad_path, scaler_path, selector_path, model_path, modality, weight):\n",
        "        self.modality = modality\n",
        "        self.weight = weight\n",
        "        self.rows = []\n",
        "        self._load_and_predict(test_h5ad_path, scaler_path, selector_path, model_path)\n",
        "\n",
        "    def _load_and_predict(self, h5ad_path, scaler_path, selector_path, model_path):\n",
        "        # === 1. Load test data ===\n",
        "        adata = ad.read_h5ad(h5ad_path)\n",
        "        X = adata.X.toarray() if issparse(adata.X) else adata.X\n",
        "        y_raw = adata.obs[\"stage\"].values\n",
        "        pids = adata.obs[\"patient_id\"].astype(str).values\n",
        "        y_true = np.array([label_map.get(s, 3) for s in y_raw])\n",
        "\n",
        "         # === 2. Load scaler & selector ===\n",
        "        scaler = joblib.load(scaler_path)\n",
        "        selector = joblib.load(selector_path)\n",
        "\n",
        "        X_scaled = scaler.transform(X)\n",
        "        X_selected = selector.transform(X_scaled)\n",
        "\n",
        "        # === 3. Wrap as DataFrame for AutoGluon ===\n",
        "        df = pd.DataFrame(X_selected)\n",
        "\n",
        "        # === 4. Load AutoGluon model and predict ===\n",
        "        predictor = TabularPredictor.load(model_path)\n",
        "\n",
        "        y_pred = predictor.predict(df)\n",
        "        y_prob = predictor.predict_proba(df)\n",
        "\n",
        "        # AutoGluon returns string labels (\"0\", \"1\", ...) â†’ map to int\n",
        "        y_pred_int = y_pred.astype(int).values\n",
        "\n",
        "        print(\"Server_RNA_test Classification Report:\")\n",
        "        print(classification_report(y_true, y_pred_int, target_names=label_names))\n",
        "        print(\"Server_RNA_test Confusion Matrix:\")\n",
        "        print(pd.DataFrame(confusion_matrix(y_true, y_pred_int), index=label_names, columns=label_names))\n",
        "\n",
        "        # === 5. Format to JSON ===\n",
        "        for i, probs in enumerate(y_prob.values):\n",
        "            self.rows.append({\n",
        "                \"patient_id\": pids[i],\n",
        "                \"probs\": probs.tolist(),\n",
        "                \"modality\": self.modality,\n",
        "                \"weight\": self.weight\n",
        "            })\n",
        "\n",
        "        print(f\"\\n{len(self.rows)} predictions have been generated.\")\n",
        "\n",
        "    def get_parameters(self, config): return []\n",
        "    def fit(self, parameters, config): return [], 0, {}\n",
        "    def evaluate(self, parameters, config):\n",
        "        task = config.get(\"task\", \"\")\n",
        "        metrics = {}\n",
        "        if task == \"predict\":\n",
        "            print(f\"\\nðŸ“¤ RNA client uploads {len(self.rows)} predictions.\")\n",
        "            metrics = {\n",
        "                \"preds_json\": json.dumps(self.rows).encode(\"utf-8\")\n",
        "            }\n",
        "        return 0.0, len(self.rows), metrics\n",
        "\n",
        "# ===== Start client =====\n",
        "client = RNAClient(test_h5ad_path, scaler_path, selector_path, autogluon_model_path, MODALITY, WEIGHT)\n",
        "\n",
        "# fl.client.start_numpy_client(server_address=SERVER_ADDRESS, client=client)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
