{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZGVTYzqouea",
        "outputId": "ed91139b-0021-415e-d4ce-e3e12c402e53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scanpy\n",
            "  Downloading scanpy-1.11.4-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting anndata>=0.8 (from scanpy)\n",
            "  Downloading anndata-0.12.2-py3-none-any.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: h5py>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from scanpy) (3.14.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from scanpy) (1.5.2)\n",
            "Collecting legacy-api-wrap>=1.4.1 (from scanpy)\n",
            "  Downloading legacy_api_wrap-1.4.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.5 in /usr/local/lib/python3.12/dist-packages (from scanpy) (3.10.0)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.12/dist-packages (from scanpy) (8.4.0)\n",
            "Requirement already satisfied: networkx>=2.7.1 in /usr/local/lib/python3.12/dist-packages (from scanpy) (3.5)\n",
            "Requirement already satisfied: numba>=0.57.1 in /usr/local/lib/python3.12/dist-packages (from scanpy) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.24.1 in /usr/local/lib/python3.12/dist-packages (from scanpy) (2.0.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from scanpy) (25.0)\n",
            "Requirement already satisfied: pandas>=1.5.3 in /usr/local/lib/python3.12/dist-packages (from scanpy) (2.2.2)\n",
            "Requirement already satisfied: patsy!=1.0.0 in /usr/local/lib/python3.12/dist-packages (from scanpy) (1.0.1)\n",
            "Requirement already satisfied: pynndescent>=0.5.13 in /usr/local/lib/python3.12/dist-packages (from scanpy) (0.5.13)\n",
            "Requirement already satisfied: scikit-learn>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from scanpy) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from scanpy) (1.16.1)\n",
            "Requirement already satisfied: seaborn>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from scanpy) (0.13.2)\n",
            "Collecting session-info2 (from scanpy)\n",
            "  Downloading session_info2-0.2.2-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: statsmodels>=0.14.5 in /usr/local/lib/python3.12/dist-packages (from scanpy) (0.14.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from scanpy) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from scanpy) (4.15.0)\n",
            "Requirement already satisfied: umap-learn>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from scanpy) (0.5.9.post2)\n",
            "Collecting array-api-compat>=1.7.1 (from anndata>=0.8->scanpy)\n",
            "  Downloading array_api_compat-1.12.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting zarr!=3.0.*,>=2.18.7 (from anndata>=0.8->scanpy)\n",
            "  Downloading zarr-3.1.3-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy) (2.9.0.post0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.57.1->scanpy) (0.43.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.3->scanpy) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.3->scanpy) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.3->scanpy) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.5->scanpy) (1.17.0)\n",
            "Collecting donfig>=0.8 (from zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy)\n",
            "  Downloading donfig-0.8.1.post1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting numcodecs>=0.14 (from numcodecs[crc32c]>=0.14->zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy)\n",
            "  Downloading numcodecs-0.16.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from donfig>=0.8->zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy) (6.0.2)\n",
            "Collecting crc32c>=2.7 (from numcodecs[crc32c]>=0.14->zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy)\n",
            "  Downloading crc32c-2.7.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Downloading scanpy-1.11.4-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anndata-0.12.2-py3-none-any.whl (169 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.9/169.9 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading legacy_api_wrap-1.4.1-py3-none-any.whl (10.0 kB)\n",
            "Downloading session_info2-0.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading array_api_compat-1.12.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.2/58.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zarr-3.1.3-py3-none-any.whl (276 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.4/276.4 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading donfig-0.8.1.post1-py3-none-any.whl (21 kB)\n",
            "Downloading numcodecs-0.16.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading crc32c-2.7.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: session-info2, numcodecs, legacy-api-wrap, donfig, crc32c, array-api-compat, zarr, anndata, scanpy\n",
            "Successfully installed anndata-0.12.2 array-api-compat-1.12.0 crc32c-2.7.1 donfig-0.8.1.post1 legacy-api-wrap-1.4.1 numcodecs-0.16.3 scanpy-1.11.4 session-info2-0.2.2 zarr-3.1.3\n"
          ]
        }
      ],
      "source": [
        "!pip install scanpy\n",
        "\n",
        "import gdown\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scanpy as sc\n",
        "import scipy.sparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.feature_selection import SelectKBest, f_classif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "zxlor9QZo0Lg",
        "outputId": "f6833bbc-ddce-45dd-d991-0313b63cd490"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1hjpD4dIdVZGsOsdvYVrBskpCTGLNXjMN\n",
            "From (redirected): https://drive.google.com/uc?id=1hjpD4dIdVZGsOsdvYVrBskpCTGLNXjMN&confirm=t&uuid=11ac1972-b503-4d3c-a472-585dabb3a955\n",
            "To: /content/TCGA_BRCA_RNA_HiSeqV2.h5ad\n",
            "100%|██████████| 258M/258M [00:01<00:00, 156MB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'TCGA_BRCA_RNA_HiSeqV2.h5ad'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download dataset\n",
        "file_id = \"1hjpD4dIdVZGsOsdvYVrBskpCTGLNXjMN\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output=\"TCGA_BRCA_RNA_HiSeqV2.h5ad\", quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7rmYvVxo3vU",
        "outputId": "64fb186b-8c6d-4c1e-b0c6-70a003a8e962"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Config\n",
        "os.environ[\"SCIPY_ARRAY_API\"] = \"1\"\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", DEVICE)\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "\n",
        "H5AD_PATH = \"/content/TCGA_BRCA_RNA_HiSeqV2.h5ad\"\n",
        "\n",
        "# ===== 参数 =====\n",
        "BATCH_SIZE = 16\n",
        "LR = 1e-3\n",
        "NUM_EPOCHS = 20\n",
        "HIDDEN1 = 1024\n",
        "HIDDEN2 = 256\n",
        "DROPOUT_RATE = 0.5\n",
        "MODEL_SAVE_PATH = \"./mlp_best.pt\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7C9bJFPo8gU",
        "outputId": "a66787e9-27f6-477a-b977-4fdffe623327"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (1216, 1000)\n",
            "Classes: ['Stage I' 'Stage II' 'Stage III' 'Stage IV']\n",
            "Class weights: [1.5283018  0.43862817 1.0995475  6.394737  ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [  144   283   284   297   321   365   565   732   824   825   839  1077\n",
            "  1100  1188  1255  1256  1259  1338  1363  1367  1399  1425  1430  1461\n",
            "  1619  1655  1743  1766  1891  1993  1994  2003  2031  2032  2224  2225\n",
            "  2231  2236  2248  2476  2691  2693  2698  2699  2733  2889  2903  3039\n",
            "  3048  3049  3076  3079  3273  3284  3288  3425  3463  3895  3994  4036\n",
            "  4050  4051  4052  4135  4933  5009  5033  5242  5299  5371  5418  5439\n",
            "  5606  5607  5609  5648  5755  6030  6049  6051  6118  6125  6147  6323\n",
            "  6324  6825  6852  6855  6856  7207  7218  7357  7403  7420  7421  7440\n",
            "  7602  7800  7857  7858  8000  8025  8107  8565  9029  9200  9305  9485\n",
            "  9621  9625  9666  9755 10262 10315 10458 10464 10502 10527 10528 10585\n",
            " 10605 10608 10668 10690 10958 10959 10962 10963 10964 10965 10966 10996\n",
            " 10999 11124 11125 11192 11372 11776 11905 12140 12144 12231 12585 12593\n",
            " 12628 12680 12709 12752 12820 12822 12829 13030 13032 13108 13189 13236\n",
            " 13297 13303 13304 13307 13322 13472 13608 13629 13667 13668 13746 13862\n",
            " 13866 13882 13905 13908 13909 13911 13912 13918 13963 13989 13996 13997\n",
            " 14006 14029 14149 14490 14607 14618 14639 14765 15189 15192 15202 15205\n",
            " 15209 15237 15259 15304 15328 15350 15460 15481 15538 15654 15887 15916\n",
            " 15938 15940 16160 16198 16241 16315 16324 16539 16585 16614 16615 16617\n",
            " 16618 16623 16658 16688 16774 16898 16906 16914 16980 17079 17127 17193\n",
            " 17210 17220 17402 17406 17410 17411 17412 17502 17679 17751 17921 17979\n",
            " 18118 18195 18224 18225 18486 18822 18882 18884 18902 18960 19154 19160\n",
            " 19257 19315 19330 19373 19446 19451 19478 19788 19805 19827 19902 19961\n",
            " 20018 20059 20112 20116 20120 20152 20238 20244 20245 20246 20316 20319\n",
            " 20327 20410] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        }
      ],
      "source": [
        "# ===== 读取数据 =====\n",
        "adata = sc.read_h5ad(H5AD_PATH)\n",
        "adata.var_names_make_unique()\n",
        "\n",
        "# ===== 只保留合法标签 =====\n",
        "valid_stages = [\"Stage I\", \"Stage II\", \"Stage III\", \"Stage IV\"]\n",
        "adata = adata[adata.obs[\"stage\"].isin(valid_stages)].copy()\n",
        "\n",
        "# ===== 特征矩阵 & 标签 =====\n",
        "import scipy.sparse\n",
        "X = adata.X.toarray() if scipy.sparse.issparse(adata.X) else np.array(adata.X)\n",
        "labels = adata.obs[\"stage\"].astype(str).values\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(labels)  # 0~3\n",
        "\n",
        "selector = SelectKBest(score_func=f_classif, k=1000)\n",
        "X_rna_selected = selector.fit_transform(X, y)\n",
        "X = X_rna_selected\n",
        "\n",
        "INPUT_DIM = X.shape[1]\n",
        "NUM_CLASSES = len(le.classes_)\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"Classes:\", le.classes_)\n",
        "\n",
        "sample_indices = np.arange(len(X))  # 或者 adata.obs_names.to_numpy()\n",
        "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
        "    X, y, sample_indices, test_size=0.2, stratify=y, random_state=SEED\n",
        ")\n",
        "\n",
        "# ===== 类别权重 =====\n",
        "class_weights = compute_class_weight(\"balanced\", classes=np.unique(y_train), y=y_train)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)\n",
        "print(\"Class weights:\", class_weights.cpu().numpy())\n",
        "\n",
        "# ===== 自定义 Dataset =====\n",
        "class RNAStageDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "    def __len__(self): return len(self.y)\n",
        "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
        "\n",
        "train_loader = DataLoader(RNAStageDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(RNAStageDataset(X_test, y_test), batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# ===== 定义 MLP 模型 =====\n",
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden1, hidden2, num_classes, dropout_rate=0.5):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden1)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden2)\n",
        "        self.out = nn.Linear(hidden2, num_classes)\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x); x = self.bn1(x); x = self.relu(x); x = self.dropout(x)\n",
        "        x = self.fc2(x); x = self.bn2(x); x = self.relu(x); x = self.dropout(x)\n",
        "        return self.out(x)\n",
        "\n",
        "model = MLPClassifier(INPUT_DIM, HIDDEN1, HIDDEN2, NUM_CLASSES, DROPOUT_RATE).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKposizMqVI-",
        "outputId": "cf856159-216b-4f87-8f30-bf29b8aa446f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20 - Loss: 1.4935 | Acc: 0.3770 | Macro F1: 0.2517\n",
            "✅ New best model saved!\n",
            "Epoch 2/20 - Loss: 1.3448 | Acc: 0.3525 | Macro F1: 0.3034\n",
            "✅ New best model saved!\n",
            "Epoch 3/20 - Loss: 1.2240 | Acc: 0.4631 | Macro F1: 0.3189\n",
            "✅ New best model saved!\n",
            "Epoch 4/20 - Loss: 1.0791 | Acc: 0.2951 | Macro F1: 0.2410\n",
            "Epoch 5/20 - Loss: 1.0181 | Acc: 0.4508 | Macro F1: 0.4013\n",
            "✅ New best model saved!\n",
            "Epoch 6/20 - Loss: 0.8815 | Acc: 0.4057 | Macro F1: 0.3582\n",
            "Epoch 7/20 - Loss: 0.7686 | Acc: 0.4344 | Macro F1: 0.3443\n",
            "Epoch 8/20 - Loss: 0.7527 | Acc: 0.1680 | Macro F1: 0.1808\n",
            "Epoch 9/20 - Loss: 0.6938 | Acc: 0.4016 | Macro F1: 0.3590\n",
            "Epoch 10/20 - Loss: 0.6115 | Acc: 0.3320 | Macro F1: 0.2643\n",
            "Epoch 11/20 - Loss: 0.6036 | Acc: 0.3525 | Macro F1: 0.2749\n",
            "Epoch 12/20 - Loss: 0.5665 | Acc: 0.5082 | Macro F1: 0.3286\n",
            "Epoch 13/20 - Loss: 0.5624 | Acc: 0.4467 | Macro F1: 0.3180\n",
            "Epoch 14/20 - Loss: 0.6076 | Acc: 0.3279 | Macro F1: 0.2966\n",
            "Epoch 15/20 - Loss: 0.4878 | Acc: 0.4672 | Macro F1: 0.2784\n",
            "Epoch 16/20 - Loss: 0.4594 | Acc: 0.5861 | Macro F1: 0.4448\n",
            "✅ New best model saved!\n",
            "Epoch 17/20 - Loss: 0.4538 | Acc: 0.5615 | Macro F1: 0.4247\n",
            "Epoch 18/20 - Loss: 0.4237 | Acc: 0.4713 | Macro F1: 0.3955\n",
            "Epoch 19/20 - Loss: 0.3907 | Acc: 0.4877 | Macro F1: 0.3013\n",
            "Epoch 20/20 - Loss: 0.4076 | Acc: 0.3811 | Macro F1: 0.2885\n"
          ]
        }
      ],
      "source": [
        "# ===== 训练循环 =====\n",
        "best_f1 = 0.0\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    model.train(); total_loss = 0.0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        batch_X, batch_y = batch_X.to(DEVICE), batch_y.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(batch_X)\n",
        "        loss = criterion(logits, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * batch_X.size(0)\n",
        "    avg_loss = total_loss / len(train_loader.dataset)\n",
        "\n",
        "    # ===== 验证阶段 =====\n",
        "    model.eval(); preds, truths = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y in test_loader:\n",
        "            batch_X = batch_X.to(DEVICE)\n",
        "            logits = model(batch_X)\n",
        "            preds_batch = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "            preds.extend(preds_batch)\n",
        "            truths.extend(batch_y.numpy())\n",
        "\n",
        "    acc = accuracy_score(truths, preds)\n",
        "    f1 = f1_score(truths, preds, average=\"macro\", zero_division=0)\n",
        "    print(f\"Epoch {epoch}/{NUM_EPOCHS} - Loss: {avg_loss:.4f} | Acc: {acc:.4f} | Macro F1: {f1:.4f}\")\n",
        "\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "        print(\"✅ New best model saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA7IJl1Yp7t1",
        "outputId": "8251db7e-1a65-4de1-9d55-eb0f251c93c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP Classification Report(Raw data):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Stage I       0.33      0.17      0.23        40\n",
            "    Stage II       0.62      0.84      0.71       139\n",
            "   Stage III       0.56      0.27      0.37        55\n",
            "    Stage IV       0.57      0.40      0.47        10\n",
            "\n",
            "    accuracy                           0.59       244\n",
            "   macro avg       0.52      0.42      0.44       244\n",
            "weighted avg       0.56      0.59      0.55       244\n",
            "\n",
            "MLP Macro F1-score: 0.4448, Accuracy: 0.5861\n",
            "MLP Confusion Matrix(Raw data):\n",
            "[[  7  31   2   0]\n",
            " [ 12 117   9   1]\n",
            " [  2  36  15   2]\n",
            " [  0   5   1   4]]\n"
          ]
        }
      ],
      "source": [
        "# ====== ✅ 测试阶段：Raw + Soft Threshold ======\n",
        "model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "model.eval()\n",
        "\n",
        "soft_preds, raw_preds, truths = [], [], []\n",
        "proba_all = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_X, batch_y in test_loader:\n",
        "        batch_X = batch_X.to(DEVICE)\n",
        "        logits = model(batch_X)\n",
        "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
        "        preds = np.argmax(probs, axis=1)\n",
        "\n",
        "        raw_preds.extend(preds)\n",
        "        truths.extend(batch_y.numpy())\n",
        "        proba_all.extend(probs)\n",
        "\n",
        "# numpy 化\n",
        "y_test = np.array(truths)\n",
        "y_pred_raw = np.array(raw_preds)\n",
        "y_proba = np.array(proba_all)\n",
        "\n",
        "# ========= 测试数据集评估 =========\n",
        "print(\"MLP Classification Report(Raw data):\")\n",
        "print(classification_report(y_test, y_pred_raw, target_names=le.classes_, zero_division=0))\n",
        "\n",
        "macro_f1 = f1_score(y_test, y_pred_raw, average=\"macro\")\n",
        "acc = accuracy_score(y_test, y_pred_raw)\n",
        "print(f\"MLP Macro F1-score: {macro_f1:.4f}, Accuracy: {acc:.4f}\")\n",
        "\n",
        "\n",
        "print(\"MLP Confusion Matrix(Raw data):\")\n",
        "print(confusion_matrix(y_test, y_pred_raw))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMm62AmMqKuy",
        "outputId": "4e416164-1466-432b-bd23-7777d1654a48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'patient_id': 'TCGA-B6-A0IB', 'probs': [0.0027299015782773495, 0.2252773642539978, 0.08863842487335205, 0.683354377746582], 'modality': 'RNA', 'weight': 1.0}, {'patient_id': 'TCGA-BH-A0BG', 'probs': [0.26045361161231995, 0.7311237454414368, 0.0012419125996530056, 0.007180718705058098], 'modality': 'RNA', 'weight': 1.0}]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# 保存测试集对应 patient id（需提前划分 sample_indices）\n",
        "test_patient_ids = adata.obs.iloc[idx_test][\"patient_id\"].values\n",
        "\n",
        "output_data = []\n",
        "for i, probs in enumerate(y_proba):\n",
        "    output_data.append({\n",
        "        \"patient_id\": test_patient_ids[i],\n",
        "        \"probs\": probs.tolist(),\n",
        "        \"modality\": \"RNA\",\n",
        "        \"weight\": 1.0\n",
        "    })\n",
        "\n",
        "print(output_data[:2])  # 打印前两个样本查看格式\n",
        "\n",
        "output_path = \"./RNA_test_results.json\"\n",
        "with open(output_path, \"w\") as f:\n",
        "    json.dump(output_data, f, indent=4)\n",
        "\n",
        "print(f\"✅ JSON 文件已保存到: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baG2ZHHBrmXY",
        "outputId": "7fa68a62-9984-4ac0-aa20-16029e474b5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'patient_id': 'TCGA-JL-A3YW', 'probs': [0.0027299015782773495, 0.2252773642539978, 0.08863842487335205, 0.683354377746582], 'pred_label': 'Stage IV', 'modality': 'RNA', 'weight': 1.0}, {'patient_id': 'TCGA-AC-A3YI', 'probs': [0.26045361161231995, 0.7311237454414368, 0.0012419125996530056, 0.007180718705058098], 'pred_label': 'Stage II', 'modality': 'RNA', 'weight': 1.0}]\n",
            "✅ JSON 保存成功：./rna_test_predictions.json\n"
          ]
        }
      ],
      "source": [
        "# import json\n",
        "\n",
        "# # ========== 加载已训练模型 ==========\n",
        "# model = MLPClassifier(INPUT_DIM, HIDDEN1, HIDDEN2, NUM_CLASSES, DROPOUT_RATE).to(DEVICE)\n",
        "# model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "# model.eval()\n",
        "\n",
        "# # ========== 推理测试集 ==========\n",
        "# raw_preds, truths, proba_all = [], [], []\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     for batch_X, batch_y in test_loader:\n",
        "#         batch_X = batch_X.to(DEVICE)\n",
        "#         logits = model(batch_X)\n",
        "#         probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
        "#         preds = np.argmax(probs, axis=1)\n",
        "\n",
        "#         raw_preds.extend(preds)\n",
        "#         truths.extend(batch_y.numpy())\n",
        "#         proba_all.extend(probs)\n",
        "\n",
        "# y_test = np.array(truths)\n",
        "# y_proba = np.array(proba_all)\n",
        "# y_pred_raw = np.array(raw_preds)\n",
        "\n",
        "# # ========== soft threshold 后处理 ==========\n",
        "# from itertools import product\n",
        "# from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# stage_i_range   = [0.4, 0.5, 0.6]\n",
        "# stage_ii_range  = [0.5, 0.6, 0.7]\n",
        "# stage_iii_range = [0.4, 0.5, 0.6]\n",
        "# stage_iv_range  = [0.2, 0.3, 0.4]\n",
        "\n",
        "# results = []\n",
        "# class2index = {cls: i for i, cls in enumerate(le.classes_)}\n",
        "\n",
        "# for th_i, th_ii, th_iii, th_iv in product(stage_i_range, stage_ii_range, stage_iii_range, stage_iv_range):\n",
        "#     thresholds = {\n",
        "#         \"Stage I\": th_i,\n",
        "#         \"Stage II\": th_ii,\n",
        "#         \"Stage III\": th_iii,\n",
        "#         \"Stage IV\": th_iv\n",
        "#     }\n",
        "\n",
        "#     y_pred = np.copy(y_pred_raw)\n",
        "#     for i in range(len(y_pred)):\n",
        "#         if y_proba[i][class2index[\"Stage IV\"]] > thresholds[\"Stage IV\"]:\n",
        "#             y_pred[i] = class2index[\"Stage IV\"]\n",
        "#         elif y_proba[i][class2index[\"Stage III\"]] > thresholds[\"Stage III\"]:\n",
        "#             y_pred[i] = class2index[\"Stage III\"]\n",
        "#         elif y_proba[i][class2index[\"Stage I\"]] > thresholds[\"Stage I\"]:\n",
        "#             y_pred[i] = class2index[\"Stage I\"]\n",
        "#         elif y_proba[i][class2index[\"Stage II\"]] > thresholds[\"Stage II\"]:\n",
        "#             y_pred[i] = class2index[\"Stage II\"]\n",
        "\n",
        "#     macro_f1 = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
        "#     results.append({\n",
        "#         \"Macro F1\": macro_f1,\n",
        "#         \"th_i\": th_i, \"th_ii\": th_ii, \"th_iii\": th_iii, \"th_iv\": th_iv,\n",
        "#         \"y_pred\": y_pred\n",
        "#     })\n",
        "\n",
        "# best_result = sorted(results, key=lambda x: x[\"Macro F1\"], reverse=True)[0]\n",
        "# best_pred = best_result[\"y_pred\"]\n",
        "\n",
        "# # ========== 提取测试集的 patient_id ==========\n",
        "# test_indices = X_test.shape[0]\n",
        "# patient_ids = adata.obs[\"patient_id\"].values\n",
        "# test_patient_ids = adata.obs.iloc[-test_indices:][\"patient_id\"].values  # 最后 N 个为 test set\n",
        "\n",
        "# # ========== 生成 JSON 输出 ==========\n",
        "# output_data = []\n",
        "# for i in range(len(test_patient_ids)):\n",
        "#     output_data.append({\n",
        "#         \"patient_id\": test_patient_ids[i],\n",
        "#         \"probs\": y_proba[i].tolist(),\n",
        "#         \"pred_label\": le.inverse_transform([best_pred[i]])[0],\n",
        "#         \"modality\": \"RNA\",\n",
        "#         \"weight\": 1.0\n",
        "#     })\n",
        "\n",
        "# print(output_data[:2])\n",
        "# # 保存 JSON\n",
        "# json_output_path = \"./rna_test_predictions.json\"\n",
        "# with open(json_output_path, \"w\") as f:\n",
        "#     json.dump(output_data, f, indent=2)\n",
        "\n",
        "# print(f\"✅ JSON 保存成功：{json_output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VaNygitkrn9i"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
