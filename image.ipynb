{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "653810b4-92b4-4adc-823b-d79dea705e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_27036\\422187617.py:29: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes (from folder names): ['Stage 1', 'Stage 2', 'Stage 3', 'Stage 4']\n",
      "Train class counts: {0: 1985, 1: 3574, 2: 4006, 3: 11849}\n",
      "Class weights: [1.8030756711959839, 1.0014283657073975, 0.8934361338615417, 0.30205968022346497]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_27036\\422187617.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/25] Train 0.6228/0.7945 | Val 2.7167/0.3996 | 115.7s\n",
      "  ↳ Saved best to best_stage_resnet18.pth\n",
      "[02/25] Train 0.3914/0.8770 | Val 0.7689/0.7984 | 81.8s\n",
      "  ↳ Saved best to best_stage_resnet18.pth\n",
      "[03/25] Train 0.3156/0.9012 | Val 0.4831/0.8489 | 82.2s\n",
      "  ↳ Saved best to best_stage_resnet18.pth\n",
      "[04/25] Train 0.2585/0.9197 | Val 7.9083/0.3249 | 81.6s\n",
      "[05/25] Train 0.2339/0.9324 | Val 0.6318/0.7848 | 83.2s\n",
      "[06/25] Train 0.2020/0.9395 | Val 11.4751/0.2916 | 81.9s\n",
      "[07/25] Train 0.2027/0.9412 | Val 0.3790/0.8976 | 81.6s\n",
      "  ↳ Saved best to best_stage_resnet18.pth\n",
      "[08/25] Train 0.1987/0.9406 | Val 0.7999/0.7988 | 82.4s\n",
      "[09/25] Train 0.1820/0.9472 | Val 0.1763/0.9432 | 83.4s\n",
      "  ↳ Saved best to best_stage_resnet18.pth\n",
      "[10/25] Train 0.1707/0.9503 | Val 0.0838/0.9733 | 86.4s\n",
      "  ↳ Saved best to best_stage_resnet18.pth\n",
      "[11/25] Train 0.1539/0.9548 | Val 4.7823/0.4257 | 83.6s\n",
      "[12/25] Train 0.1440/0.9571 | Val 0.2175/0.9215 | 81.3s\n",
      "[13/25] Train 0.1412/0.9595 | Val 7.4541/0.3688 | 82.0s\n",
      "[14/25] Train 0.1365/0.9600 | Val 0.3289/0.8946 | 80.8s\n",
      "[15/25] Train 0.1455/0.9581 | Val 0.6244/0.7712 | 82.5s\n",
      "Early stopping.\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[ 345    0    6  145]\n",
      " [  11  789    3   90]\n",
      " [ 136   42  750   74]\n",
      " [ 717    1    0 2244]]\n",
      "\n",
      "Per-class metrics:\n",
      " Stage 1 | P: 0.285  R: 0.696  F1: 0.405\n",
      " Stage 2 | P: 0.948  R: 0.884  F1: 0.915\n",
      " Stage 3 | P: 0.988  R: 0.749  F1: 0.852\n",
      " Stage 4 | P: 0.879  R: 0.758  F1: 0.814\n",
      "\n",
      "Macro-F1: 0.746\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# train_cnn_from_single_root.py\n",
    "import os, math, time, random\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "# ========== 0) 基本配置 ==========\n",
    "DATA_ROOT = r\"F:\\5703Dataset\\image\"   # 你的根目录：里面有 Stage 1 / Stage 2 / Stage 3 / Stage 4\n",
    "SAVE_PATH = \"best_stage_resnet18.pth\"\n",
    "\n",
    "VAL_RATIO   = 0.2\n",
    "BATCH_SIZE  = 64\n",
    "EPOCHS      = 25\n",
    "LR          = 1e-3\n",
    "WEIGHT_DECAY= 1e-4\n",
    "PATIENCE    = 5\n",
    "IMG_SIZE    = 224\n",
    "NUM_WORKERS = 4\n",
    "USE_PRETRAINED = False  # 有网/有缓存可改 True\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "\n",
    "# ========== 1) 数据与分层划分 ==========\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(0.15,0.15,0.15,0.02),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "full_ds = datasets.ImageFolder(DATA_ROOT, transform=None)  # 先不加变换，划分时不需要\n",
    "classes = full_ds.classes  # 文件夹名顺序\n",
    "print(\"Classes (from folder names):\", classes)  # 例如 ['Stage 1','Stage 2','Stage 3','Stage 4']\n",
    "\n",
    "# 取每个样本的标签\n",
    "targets = full_ds.targets  # list[int]\n",
    "indices_per_class = {}\n",
    "for idx, y in enumerate(targets):\n",
    "    indices_per_class.setdefault(y, []).append(idx)\n",
    "\n",
    "# 按类别分层切分\n",
    "train_indices, val_indices = [], []\n",
    "import math\n",
    "for y, idxs in indices_per_class.items():\n",
    "    n = len(idxs)\n",
    "    n_val = max(1, int(round(n * VAL_RATIO)))\n",
    "    random.Random(SEED).shuffle(idxs)\n",
    "    val_indices.extend(idxs[:n_val])\n",
    "    train_indices.extend(idxs[n_val:])\n",
    "\n",
    "# 创建带变换的数据集\n",
    "train_ds = datasets.ImageFolder(DATA_ROOT, transform=train_tfms)\n",
    "val_ds   = datasets.ImageFolder(DATA_ROOT, transform=val_tfms)\n",
    "\n",
    "train_subset = Subset(train_ds, train_indices)\n",
    "val_subset   = Subset(val_ds,   val_indices)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader   = DataLoader(val_subset,   batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "# 类别计数（用于加权）\n",
    "train_counts = Counter([full_ds.targets[i] for i in train_indices])\n",
    "num_classes  = len(classes)\n",
    "counts_tensor = torch.tensor([train_counts.get(c,0) for c in range(num_classes)], dtype=torch.float)\n",
    "class_weights = (counts_tensor.sum() / (counts_tensor + 1e-9))\n",
    "class_weights = class_weights / class_weights.mean()\n",
    "print(\"Train class counts:\", dict(train_counts))\n",
    "print(\"Class weights:\", class_weights.tolist())\n",
    "\n",
    "# ========== 2) 模型 ==========\n",
    "def build_model(nc=num_classes, pretrained=USE_PRETRAINED):\n",
    "    if pretrained:\n",
    "        weights = models.ResNet18_Weights.DEFAULT\n",
    "        model = models.resnet18(weights=weights)\n",
    "    else:\n",
    "        model = models.resnet18(weights=None)\n",
    "    in_feat = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_feat, nc)\n",
    "    return model\n",
    "\n",
    "model = build_model().to(device)\n",
    "\n",
    "# ========== 3) 训练配置 ==========\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "best_val = math.inf\n",
    "no_improve = 0\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    total_loss, total_correct, total_num = 0.0, 0, 0\n",
    "    cm = torch.zeros(num_classes, num_classes, dtype=torch.long)\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "        if train:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        total_correct += (preds == labels).sum().item()\n",
    "        total_num += labels.size(0)\n",
    "\n",
    "        for t, p in zip(labels.view(-1), preds.view(-1)):\n",
    "            cm[t.long(), p.long()] += 1\n",
    "\n",
    "    return total_loss / max(total_num,1), total_correct / max(total_num,1), cm\n",
    "\n",
    "# ========== 4) 训练循环 ==========\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    t0 = time.time()\n",
    "    tr_loss, tr_acc, _ = run_epoch(train_loader, train=True)\n",
    "    val_loss, val_acc, val_cm = run_epoch(val_loader, train=False)\n",
    "    print(f\"[{epoch:02d}/{EPOCHS}] Train {tr_loss:.4f}/{tr_acc:.4f} | Val {val_loss:.4f}/{val_acc:.4f} | {time.time()-t0:.1f}s\")\n",
    "    if val_loss < best_val - 1e-4:\n",
    "        best_val = val_loss\n",
    "        no_improve = 0\n",
    "        torch.save({\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"classes\": classes,  # 保存原文件夹类名\n",
    "            \"args\": {\"img_size\": IMG_SIZE, \"mean\":[0.485,0.456,0.406], \"std\":[0.229,0.224,0.225]}\n",
    "        }, SAVE_PATH)\n",
    "        print(f\"  ↳ Saved best to {SAVE_PATH}\")\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= PATIENCE:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "# ========== 5) 评估 ==========\n",
    "print(\"\\nConfusion Matrix (rows=true, cols=pred):\")\n",
    "print(val_cm.cpu().numpy())\n",
    "\n",
    "eps = 1e-12\n",
    "tp = val_cm.diag().float()\n",
    "pred_pos = val_cm.sum(dim=0).float()\n",
    "true_pos = val_cm.sum(dim=1).float()\n",
    "precision = tp / (pred_pos + eps)\n",
    "recall    = tp / (true_pos + eps)\n",
    "f1        = 2 * precision * recall / (precision + recall + eps)\n",
    "\n",
    "print(\"\\nPer-class metrics:\")\n",
    "for i, cname in enumerate(classes):\n",
    "    print(f\"{cname:>8s} | P: {precision[i]:.3f}  R: {recall[i]:.3f}  F1: {f1[i]:.3f}\")\n",
    "print(f\"\\nMacro-F1: {f1.mean().item():.3f}\")\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0659b954-52f7-4712-a198-744f99964997",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
