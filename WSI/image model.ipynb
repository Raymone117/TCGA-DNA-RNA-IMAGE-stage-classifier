{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T18:03:13.001648Z",
     "start_time": "2025-09-28T17:45:30.421619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openslide\n",
    "from skimage import color, filters, morphology, measure, exposure\n",
    "from skimage.color import hed_from_rgb\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "# ===== ✅ 设置随机种子（全局可复现）=====\n",
    "SEED = 0\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ===== 根目录 =====\n",
    "ROOT = r\"D:\\total\"\n",
    "REQUIRE_MPP = True\n",
    "\n",
    "# ===== CNN 特征提取器 =====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "resnet.fc = nn.Identity()\n",
    "resnet = resnet.to(device).eval()\n",
    "\n",
    "transform_cnn = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def extract_cnn_feature(img):\n",
    "    if isinstance(img, np.ndarray):\n",
    "        img = Image.fromarray(img)\n",
    "    elif isinstance(img, torch.Tensor):\n",
    "        img = T.ToPILImage()(img)\n",
    "    if getattr(img, \"mode\", None) != \"RGB\":\n",
    "        img = img.convert(\"RGB\")\n",
    "    x = transform_cnn(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        feat = resnet(x).cpu().numpy().flatten()\n",
    "    return feat  # [512]\n",
    "\n",
    "# ---------- Top-K 病灶裁剪 + 池化 ----------\n",
    "def extract_topk_crops(pil_img, nuc_mask, k=3, pad_ratio=0.12, out_size=224):\n",
    "    lab = measure.label(nuc_mask)\n",
    "    props = sorted(measure.regionprops(lab), key=lambda p: p.area, reverse=True)\n",
    "    W, H = pil_img.width, pil_img.height\n",
    "    crops = []\n",
    "    for p in props[:k]:\n",
    "        ymin, xmin, ymax, xmax = p.bbox\n",
    "        h, w = ymax - ymin, xmax - xmin\n",
    "        if h <= 0 or w <= 0: continue\n",
    "        px = int(pad_ratio * w); py = int(pad_ratio * h)\n",
    "        xmin = max(xmin - px, 0); xmax = min(xmax + px, W)\n",
    "        ymin = max(ymin - py, 0); ymax = min(ymax + py, H)\n",
    "        crops.append(pil_img.crop((xmin, ymin, xmax, ymax)).resize((out_size, out_size)))\n",
    "    if not crops:\n",
    "        crops = [pil_img.resize((out_size, out_size))]\n",
    "    return crops\n",
    "\n",
    "def cnn_features_pooled(crops):\n",
    "    feats = [extract_cnn_feature(im) for im in crops]  # [k,512]\n",
    "    F = np.stack(feats, 0)\n",
    "    return np.concatenate([F.mean(0), F.max(0)], 0)  # [1024]\n",
    "# ------------------------------------------\n",
    "\n",
    "def read_thumbnail_and_geometry(svs_path, min_dim=3000):\n",
    "    slide = openslide.OpenSlide(svs_path)\n",
    "    W0, H0 = slide.dimensions\n",
    "    scale = max(W0, H0) / float(min_dim)\n",
    "    new_w, new_h = int(W0/scale), int(H0/scale)\n",
    "    img = slide.get_thumbnail((new_w, new_h))\n",
    "    mpp_x = slide.properties.get(\"openslide.mpp-x\", None)\n",
    "    mpp_y = slide.properties.get(\"openslide.mpp-y\", None)\n",
    "    slide.close()\n",
    "    mpp_x = float(mpp_x) if mpp_x not in (None, \"\") else None\n",
    "    mpp_y = float(mpp_y) if mpp_y not in (None, \"\") else None\n",
    "    return np.asarray(img), scale, mpp_x, mpp_y\n",
    "\n",
    "def tissue_mask(rgb):\n",
    "    hsv = color.rgb2hsv(rgb); v = hsv[..., 2]\n",
    "    thr = filters.threshold_otsu(v)\n",
    "    mask = v < thr * 0.98\n",
    "    mask = morphology.remove_small_holes(mask, 256)\n",
    "    mask = morphology.remove_small_objects(mask, 256)\n",
    "    return mask\n",
    "\n",
    "def he_nuclei_mask(rgb, tissue):\n",
    "    rgbf = np.clip(rgb/255.0, 0, 1)\n",
    "    hed = color.separate_stains(rgbf, hed_from_rgb)\n",
    "    H = hed[..., 0]\n",
    "    H = exposure.rescale_intensity(\n",
    "        H, in_range=(np.percentile(H[tissue], 2), np.percentile(H[tissue], 98)))\n",
    "    thr = filters.threshold_otsu(H[tissue])\n",
    "    nuc = np.zeros_like(H, dtype=bool)\n",
    "    nuc[tissue] = H[tissue] > thr\n",
    "    nuc = morphology.remove_small_objects(nuc.astype(bool), 64)\n",
    "    nuc = morphology.binary_opening(nuc, morphology.disk(2))\n",
    "    return nuc, H\n",
    "\n",
    "def wsi_features(svs_path):\n",
    "    rgb, scale, mpp_x, mpp_y = read_thumbnail_and_geometry(svs_path)\n",
    "    has_mpp = (mpp_x is not None) and (mpp_y is not None) and (mpp_x > 0) and (mpp_y > 0)\n",
    "    if REQUIRE_MPP and not has_mpp:\n",
    "        return None\n",
    "    mask = tissue_mask(rgb)\n",
    "    if mask.sum() < 5000:\n",
    "        return None\n",
    "    nuc, H = he_nuclei_mask(rgb, mask)\n",
    "\n",
    "    # —— 手工统计\n",
    "    tissue_px_thumb = int(mask.sum())\n",
    "    tumor_px_thumb  = int(nuc.sum())\n",
    "    lab = measure.label(nuc)\n",
    "    props = measure.regionprops(lab)\n",
    "    areas  = np.array([p.area for p in props], dtype=np.float32) if props else np.array([])\n",
    "    perims = np.array([p.perimeter for p in props], dtype=np.float32) if props else np.array([])\n",
    "    cc_count = len(props)\n",
    "    largest_cc_px = int(areas.max()) if cc_count else 0\n",
    "\n",
    "    tumor_frac = tumor_px_thumb / max(tissue_px_thumb, 1)\n",
    "    largest_cc_frac = largest_cc_px / max(tissue_px_thumb, 1)\n",
    "    small_thresh = 0.001 * tissue_px_thumb\n",
    "    cc_small = int((areas < small_thresh).sum()) if cc_count else 0\n",
    "    cc_small_frac = cc_small / max(cc_count, 1)\n",
    "    frag_ratio = float(perims.sum() / (areas.sum() + 1e-6)) if cc_count else 0.0\n",
    "\n",
    "    feats = dict(\n",
    "        tumor_frac=tumor_frac,\n",
    "        largest_cc_frac=largest_cc_frac,\n",
    "        cc_count=cc_count,\n",
    "        cc_small_frac=cc_small_frac,\n",
    "        frag_ratio=frag_ratio,\n",
    "    )\n",
    "\n",
    "    # —— CNN：Top-K 裁剪 + 池化（K=3）\n",
    "    pil_img = Image.fromarray(rgb)\n",
    "    crops = extract_topk_crops(pil_img, nuc_mask=nuc, k=3, pad_ratio=0.12)\n",
    "    cnn_feat = cnn_features_pooled(crops)  # [1024]\n",
    "\n",
    "    return feats, cnn_feat\n",
    "\n",
    "def collect_rows(root):\n",
    "    rows = []\n",
    "    for stage in [1,2,3,4]:\n",
    "        for split in [\"train\",\"val\",\"test\"]:   # ★ 加入 val\n",
    "            d = Path(root) / f\"stage {stage} {split}\"\n",
    "            if not d.exists(): \n",
    "                continue\n",
    "            label = stage - 1  # 四分类：stage1→0, stage2→1, stage3→2, stage4→3\n",
    "            for p in list(d.glob(\"*.svs\")) + list(d.glob(\"*.tif\")):\n",
    "                res = wsi_features(str(p))\n",
    "                if res is None: \n",
    "                    continue\n",
    "                feats, cnn_feat = res\n",
    "                row = dict(path=str(p), label=label, split=split)\n",
    "                row.update(feats)\n",
    "                for i, v in enumerate(cnn_feat):\n",
    "                    row[f\"cnn_{i}\"] = v\n",
    "                rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ===== 主程序 =====\n",
    "if __name__ == \"__main__\":\n",
    "    df = collect_rows(ROOT)\n",
    "    print(\"Feature rows:\", df.shape)\n",
    "\n",
    "    # 按 split 打印类别分布\n",
    "    for sp in [\"train\",\"val\",\"test\"]:\n",
    "        if sp in df[\"split\"].unique():\n",
    "            print(f\"\\nClass distribution in {sp}:\")\n",
    "            print(df[df.split==sp][\"label\"].value_counts().sort_index())\n",
    "\n",
    "    df.to_csv(\"wsi_stage_features_topk_4class_split.csv\", index=False)\n",
    "\n",
    "    train_df = df[df.split==\"train\"].copy()\n",
    "    val_df   = df[df.split==\"val\"].copy()\n",
    "    test_df  = df[df.split==\"test\"].copy()\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c.startswith(\"cnn_\")] + [\n",
    "        \"tumor_frac\",\"largest_cc_frac\",\"cc_count\",\"cc_small_frac\",\"frag_ratio\"\n",
    "    ]\n",
    "\n",
    "    Xtr, ytr = train_df[feature_cols].values, train_df[\"label\"].values\n",
    "    Xval, yval = val_df[feature_cols].values, val_df[\"label\"].values\n",
    "    Xte, yte = test_df[feature_cols].values, test_df[\"label\"].values\n",
    "\n",
    "    # ===== 类不平衡权重（只根据训练集计算） =====\n",
    "    counts = train_df[\"label\"].value_counts()\n",
    "    n_classes = 4\n",
    "    class_weight_map = {c: len(train_df) / (n_classes * counts[c]) for c in counts.index}\n",
    "\n",
    "    custom_multipliers = {3: 2.5}  # stage4 提升权重\n",
    "    for k, mult in custom_multipliers.items():\n",
    "        if k in class_weight_map:\n",
    "            class_weight_map[k] *= mult\n",
    "\n",
    "    weights = train_df[\"label\"].map(class_weight_map).values\n",
    "\n",
    "    # ===== 模型训练（用训练集 + 验证集监控） =====\n",
    "    clf = HistGradientBoostingClassifier(\n",
    "        max_depth=6, learning_rate=0.06, max_iter=600,\n",
    "        l2_regularization=1.0, min_samples_leaf=20, random_state=SEED\n",
    "    )\n",
    "    clf.fit(Xtr, ytr, sample_weight=weights)\n",
    "\n",
    "    # 验证集效果\n",
    "    yval_pr = clf.predict(Xval)\n",
    "    print(\"\\nValidation performance:\")\n",
    "    print(confusion_matrix(yval, yval_pr, labels=[0,1,2,3]))\n",
    "    print(classification_report(yval, yval_pr, labels=[0,1,2,3],\n",
    "          target_names=[\"stage1\",\"stage2\",\"stage3\",\"stage4\"], digits=4))\n",
    "    \n",
    "    # ===== 保存验证集预测结果 =====\n",
    "    val_df[\"y_true\"] = yval\n",
    "    val_df[\"y_pred\"] = yval_pr\n",
    "    val_df.to_csv(\"val_preds.csv\", index=False)\n",
    "    print(\"\\n✅ val predictions will be saved in val_preds.csv\")"
   ],
   "id": "beb4bf31d64e6d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature rows: (190, 1032)\n",
      "\n",
      "Class distribution in train:\n",
      "label\n",
      "0    46\n",
      "1    41\n",
      "2    52\n",
      "3     9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution in val:\n",
      "label\n",
      "0    6\n",
      "1    6\n",
      "2    6\n",
      "3    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution in test:\n",
      "label\n",
      "0    12\n",
      "1     6\n",
      "2     4\n",
      "3     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation performance:\n",
      "[[3 1 2 0]\n",
      " [0 6 0 0]\n",
      " [2 1 3 0]\n",
      " [1 0 0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stage1     0.5000    0.5000    0.5000         6\n",
      "      stage2     0.7500    1.0000    0.8571         6\n",
      "      stage3     0.6000    0.5000    0.5455         6\n",
      "      stage4     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.6316        19\n",
      "   macro avg     0.4625    0.5000    0.4756        19\n",
      "weighted avg     0.5842    0.6316    0.6008        19\n",
      "\n",
      "\n",
      "✅ val predictions will be saved in val_preds.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zxy01\\PycharmProjects\\pythonProject6\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\zxy01\\PycharmProjects\\pythonProject6\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\zxy01\\PycharmProjects\\pythonProject6\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T18:03:13.737385Z",
     "start_time": "2025-09-28T18:03:13.112710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "import torch\n",
    "\n",
    "joblib.dump(clf, \"new_stage_classifier_gbdt.pkl\")"
   ],
   "id": "947f6fb3fc411b06",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new_stage_classifier_gbdt.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
