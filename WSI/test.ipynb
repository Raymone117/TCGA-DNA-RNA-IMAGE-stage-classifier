{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T09:29:12.847475Z",
     "start_time": "2025-09-21T09:29:11.689935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import flwr as fl\n",
    "\n",
    "# ===== 参数设置 =====\n",
    "SERVER       = \"127.0.0.1:8080\"\n",
    "FEATURES_CSV = \"wsi_stage_features_topk_4class.csv\"   # 包含所有病人特征的文件\n",
    "MODEL_PATH   = \"stage_classifier_gbdt.pkl\"            # 你训练好的模型\n",
    "MODALITY     = \"WSI\"\n",
    "N_CLASSES    = 4\n",
    "WEIGHT       = 1.0\n",
    "\n",
    "# ===== 自动获取 test 病人列表（从 .svs 文件名中提取）=====\n",
    "TEST_IMG_DIR = r\"C:\\Users\\mxjli\\Desktop\\svs\"\n",
    "test_pids = [\n",
    "    \"-\".join(os.path.splitext(f)[0].split(\"-\")[:3])\n",
    "    for f in os.listdir(TEST_IMG_DIR)\n",
    "    if f.endswith(\".svs\")\n",
    "]\n",
    "print(f\"[INFO] Found {len(test_pids)} test patients.\")\n",
    "\n",
    "# ===== 读取特征 CSV 和模型 =====\n",
    "df = pd.read_csv(FEATURES_CSV)\n",
    "model = joblib.load(MODEL_PATH)\n",
    "\n",
    "# ===== 提取特征列（所有 cnn_ 开头 + 其他人工特征）=====\n",
    "feature_cols = [c for c in df.columns if c.startswith(\"cnn_\")] + [\n",
    "    \"tumor_frac\", \"largest_cc_frac\", \"cc_count\", \"cc_small_frac\", \"frag_ratio\"\n",
    "]\n",
    "\n",
    "# ===== 提取测试数据（根据 patient_id 匹配）=====\n",
    "df[\"pid\"] = df[\"path\"].apply(lambda x: \"-\".join(Path(x).stem.split(\"-\")[:3]))\n",
    "df_test = df[df[\"pid\"].isin(test_pids)].copy()\n",
    "x_test = df_test[feature_cols].values\n",
    "pid_list = df_test[\"pid\"].tolist()\n",
    "print(f\"[INFO] Matched {len(pid_list)} patients with features.\")\n",
    "\n",
    "# ===== 构造联邦客户端：输出 softmax =====\n",
    "class SoftmaxClient(fl.client.NumPyClient):\n",
    "    def __init__(self, pids, features, model, modality, weight, n_classes):\n",
    "        self.pids = pids\n",
    "        self.x = features\n",
    "        self.model = model\n",
    "        self.modality = modality\n",
    "        self.weight_for_fusion = float(weight)\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return []\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        return [], 0, {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        task = config.get(\"task\", \"\")\n",
    "        metrics = {}\n",
    "\n",
    "        if task == \"predict\":\n",
    "            rows = []\n",
    "            probs_all = self.model.predict_proba(self.x)\n",
    "            print(f\"[INFO] Predicting for {len(self.pids)} patients...\")\n",
    "\n",
    "            for pid, probs in zip(self.pids, probs_all):\n",
    "                probs = np.clip(probs.astype(float), 1e-9, 1.0)\n",
    "                probs = probs / probs.sum()\n",
    "                row = {\n",
    "                    \"patient_id\": pid,\n",
    "                    \"probs\": probs.tolist(),\n",
    "                    \"modality\": self.modality,\n",
    "                    \"weight\": self.weight_for_fusion\n",
    "                }\n",
    "                print(f\"[PREDICT] {row}\")  # ✅ 正确：现在 row 有定义\n",
    "                rows.append(row)\n",
    "\n",
    "            metrics = {\"preds_json\": json.dumps(rows).encode(\"utf-8\")}\n",
    "            print(f\"[INFO] Finished prediction. Sent {len(rows)} results to server.\")\n",
    "\n",
    "        return 0.0, len(self.pids), metrics"
   ],
   "id": "3c631446ae7651e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found 10 test patients.\n",
      "[INFO] Matched 15 patients with features.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T09:29:14.173901Z",
     "start_time": "2025-09-21T09:29:12.855323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===== 启动联邦客户端 =====\n",
    "client = SoftmaxClient(pid_list, x_test, model, MODALITY, WEIGHT, N_CLASSES)\n",
    "fl.client.start_numpy_client(server_address=SERVER, client=client)"
   ],
   "id": "4f32f5e9718ba22f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[93mWARNING \u001B[0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. \n",
      "\tInstead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: \n",
      "\tflwr.client.start_client(\n",
      "\t\tserver_address='<IP>:<PORT>',\n",
      "\t\tclient=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object\n",
      "\t)\n",
      "\tUsing `start_numpy_client()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001B[93mWARNING \u001B[0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.\n",
      "\tInstead, use the `flower-supernode` CLI command to start a SuperNode as shown below:\n",
      "\n",
      "\t\t$ flower-supernode --insecure --superlink='<IP>:<PORT>'\n",
      "\n",
      "\tTo view all available options, run:\n",
      "\n",
      "\t\t$ flower-supernode --help\n",
      "\n",
      "\tUsing `start_client()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      Received: get_parameters message 4bea411f-973f-476b-8ff0-cb266277e933\n",
      "\u001B[92mINFO \u001B[0m:      Sent reply\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      Received: evaluate message e154c388-5ea7-4775-ac5a-bc63c60960d1\n",
      "\u001B[92mINFO \u001B[0m:      Sent reply\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      Received: reconnect message 6ee84849-d31e-49f3-9eaf-bdebea17c367\n",
      "\u001B[92mINFO \u001B[0m:      Disconnect and shut down\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Predicting for 15 patients...\n",
      "[PREDICT] {'patient_id': 'TCGA-A2-A04N', 'probs': [0.9972151484835118, 0.0003964131639633967, 0.002328176831748804, 6.0261520776015666e-05], 'modality': 'WSI', 'weight': 1.0}\n",
      "[PREDICT] {'patient_id': 'TCGA-A2-A3XZ', 'probs': [0.9979167410573858, 0.0017404902285205071, 0.0002970510699389598, 4.571764415475157e-05], 'modality': 'WSI', 'weight': 1.0}\n",
      "[PREDICT] {'patient_id': 'TCGA-A7-A426', 'probs': [0.9971568989980669, 0.0008776461853605092, 0.0014414616579088231, 0.0005239931586638324], 'modality': 'WSI', 'weight': 1.0}\n",
      "[PREDICT] {'patient_id': 'TCGA-A2-A04N', 'probs': [0.9972151484835118, 0.0003964131639633967, 0.002328176831748804, 6.0261520776015666e-05], 'modality': 'WSI', 'weight': 1.0}\n",
      "[PREDICT] {'patient_id': 'TCGA-A2-A3XZ', 'probs': [0.9979167410573858, 0.0017404902285205071, 0.0002970510699389598, 4.571764415475157e-05], 'modality': 'WSI', 'weight': 1.0}\n",
      "[PREDICT] {'patient_id': 'TCGA-E2-A14U', 'probs': [0.04176103614772476, 0.3489736124857568, 0.6057829608564848, 0.003482390510033688], 'modality': 'WSI', 'weight': 1.0}\n",
      "[PREDICT] {'patient_id': 'TCGA-E2-A1II', 'probs': [0.758293168780981, 0.03554534872149252, 0.20534395698241834, 0.0008175255151082482], 'modality': 'WSI', 'weight': 1.0}\n",
      "[PREDICT] {'patient_id': 'TCGA-A8-A093', 'probs': [0.0018822900795639913, 0.9964023641221199, 0.0011121089276678758, 0.0006032368706481391], 'modality': 'WSI', 'weight': 1.0}\n",
      "[PREDICT] {'patient_id': 'TCGA-AC-A2FB', 'probs': [0.001193628211419502, 0.9960354933948833, 0.0022137068635603727, 0.000557171530136684], 'modality': 'WSI', 'weight': 1.0}\n",
      "[PREDICT] {'patient_id': 'TCGA-A8-A090', 'probs': [0.23205204069186713, 0.6153580400111546, 0.14142301199801804, 0.011166907298960256], 'modality': 'WSI', 'weight': 1.0}\n",
      "[PREDICT] {'patient_id': 'TCGA-A8-A093', 'probs': [0.0018822900795639913, 0.9964023641221199, 0.0011121089276678758, 0.0006032368706481391], 'modality': 'WSI', 'weight': 1.0}\n",
      "[PREDICT] {'patient_id': 'TCGA-AC-A2FB', 'probs': [0.001193628211419502, 0.9960354933948833, 0.0022137068635603727, 0.000557171530136684], 'modality': 'WSI', 'weight': 1.0}\n",
      "[PREDICT] {'patient_id': 'TCGA-A7-A426', 'probs': [0.9971568989980669, 0.0008776461853605092, 0.0014414616579088231, 0.0005239931586638324], 'modality': 'WSI', 'weight': 1.0}\n",
      "[PREDICT] {'patient_id': 'TCGA-A8-A09X', 'probs': [0.6179169248036256, 0.10357271231890108, 0.27625539924230247, 0.002254963635170896], 'modality': 'WSI', 'weight': 1.0}\n",
      "[PREDICT] {'patient_id': 'TCGA-PL-A8LX', 'probs': [0.013649882562635754, 0.33104090625830884, 0.3801330439147168, 0.27517616726433863], 'modality': 'WSI', 'weight': 1.0}\n",
      "[INFO] Finished prediction. Sent 15 results to server.\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
