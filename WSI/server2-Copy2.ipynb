{
 "cells": [
  {
   "cell_type": "code",
   "id": "1e29260f-c948-44b9-b97e-8df67a78b004",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T18:13:16.452655Z",
     "start_time": "2025-09-28T18:13:14.621226Z"
    }
   },
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# ---------- 工具函数 ----------\n",
    "\n",
    "def _to_numpy(x):\n",
    "    return np.asarray(x, dtype=float)\n",
    "\n",
    "# 将字符串标签映射为 0..C-1，并返回映射\n",
    "def encode_labels(y: List[Any]):\n",
    "    uniq = sorted(list({str(v) for v in y}))\n",
    "    str2id = {s: i for i, s in enumerate(uniq)}\n",
    "    y_id = np.array([str2id[str(v)] for v in y], dtype=int)\n",
    "    return y_id, str2id, {i: s for s, i in str2id.items()}\n",
    "\n",
    "# 融合 softmax\n",
    "def fuse_softmax(prob_list: List[np.ndarray], weights: List[float] | None = None) -> np.ndarray:\n",
    "    if len(prob_list) == 1:\n",
    "        return prob_list[0]\n",
    "    P = np.vstack(prob_list)\n",
    "    if weights is None:\n",
    "        w = np.ones((P.shape[0], 1))\n",
    "    else:\n",
    "        w = _to_numpy(weights).reshape(-1, 1)\n",
    "    P = (P * w).sum(axis=0) / w.sum()\n",
    "    P = np.clip(P, 1e-9, 1.0)\n",
    "    P = P / P.sum()\n",
    "    return P\n",
    "\n",
    "# ---------- 自定义策略 ----------\n",
    "\n",
    "class PredictAndFuseStrategy(fl.server.strategy.FedAvg):\n",
    "    def __init__(self, patient_ids: List[str], label_ids: np.ndarray, id2label: Dict[int, str], fusion: str = \"mean\"):\n",
    "        # 仅进行 evaluate（预测/收集 softmax），不做训练\n",
    "        super().__init__(\n",
    "            fraction_fit=0.0,\n",
    "            min_fit_clients=0,\n",
    "            fraction_evaluate=1.0,\n",
    "            min_evaluate_clients=1,\n",
    "            min_available_clients=1,\n",
    "        )\n",
    "        self.patient_ids = patient_ids\n",
    "        self.labels = label_ids\n",
    "        self.id2label = id2label\n",
    "        self.fusion = fusion\n",
    "        self.buffer: Dict[str, Dict[str, np.ndarray]] = defaultdict(dict)\n",
    "\n",
    "    # 修正签名：Flower 在启动时调用 evaluate(server_round, parameters)\n",
    "    def evaluate(self, server_round: int, parameters):\n",
    "        return None  # 不做全局模型评估\n",
    "\n",
    "    def configure_evaluate(self, server_round: int, parameters, client_manager):\n",
    "        # 广播“预测任务”给所有可用客户端\n",
    "        config = {\"task\": \"predict\", \"round\": server_round}\n",
    "        evaluate_ins = fl.server.client_proxy.EvaluateIns(parameters, config)\n",
    "        clients = list(client_manager.all().values())\n",
    "        return [(client, evaluate_ins) for client in clients]\n",
    "\n",
    "    def aggregate_evaluate(self, server_round: int, results, failures):\n",
    "        # 收集每个客户端上传的 JSON（包含 patient_id, probs, modality, 可选 weight）\n",
    "        for client_proxy, evaluate_res in results:\n",
    "            metrics = evaluate_res.metrics or {}\n",
    "            preds_blob = metrics.get(\"preds_json\", b\"\")\n",
    "            preds_json = preds_blob.decode(\"utf-8\") if isinstance(preds_blob, bytes) else preds_blob\n",
    "            if not preds_json:\n",
    "                continue\n",
    "            rows = json.loads(preds_json)\n",
    "            for r in rows:\n",
    "                pid = str(r[\"patient_id\"])  # 必须\n",
    "                probs = _to_numpy(r[\"probs\"])  # 长度 = C\n",
    "                modality = str(r.get(\"modality\", \"unknown\"))\n",
    "                self.buffer[pid][modality] = probs\n",
    "\n",
    "        # 计算当前轮能计算到的部分指标\n",
    "        y_true = self.labels\n",
    "        y_pred_single: List[int] = []\n",
    "        have_pred_flags: List[bool] = []\n",
    "\n",
    "        for pid in self.patient_ids:\n",
    "            modal_dict = self.buffer.get(pid, {})\n",
    "            if not modal_dict:\n",
    "                have_pred_flags.append(False)\n",
    "                y_pred_single.append(-1)\n",
    "                continue\n",
    "            probs_list = list(modal_dict.values())\n",
    "            fused = fuse_softmax(probs_list)\n",
    "            y_pred_single.append(int(np.argmax(fused)))\n",
    "            have_pred_flags.append(True)\n",
    "\n",
    "        idx = [i for i, ok in enumerate(have_pred_flags) if ok]\n",
    "        metrics = {}\n",
    "        if idx:\n",
    "            yt = y_true[idx]\n",
    "            yp = np.array(y_pred_single)[idx]\n",
    "            acc = float(accuracy_score(yt, yp))\n",
    "            mf1 = float(f1_score(yt, yp, average=\"macro\"))\n",
    "            metrics = {\"acc_partial\": acc, \"macro_f1_partial\": mf1, \"n_pred\": len(idx)}\n",
    "            print(f\"[Round {server_round}] acc={acc:.4f}, macro_f1={mf1:.4f}, n_pred={len(idx)}/{len(y_true)}\")\n",
    "        else:\n",
    "            print(f\"[Round {server_round}] no predictions yet.\")\n",
    "\n",
    "        return 0.0, metrics\n",
    "\n",
    "    def export_final(self, out_csv: str):\n",
    "        records = []\n",
    "        for pid in self.patient_ids:\n",
    "            modal_dict = self.buffer.get(pid, {})\n",
    "            row = {\"patient_id\": pid}\n",
    "            for m, p in modal_dict.items():\n",
    "                row[f\"probs_{m}\"] = json.dumps(p.tolist())\n",
    "                row[f\"pred_{m}\"] = int(np.argmax(p))\n",
    "            if modal_dict:\n",
    "                fused = fuse_softmax(list(modal_dict.values()))\n",
    "                row[\"probs_fused\"] = json.dumps(fused.tolist())\n",
    "                row[\"pred_fused\"] = int(np.argmax(fused))\n",
    "            records.append(row)\n",
    "        df = pd.DataFrame(records)\n",
    "        df.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "        return df\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "50ed18b1-e71f-4b12-a80b-990790773011",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T18:17:23.908398Z",
     "start_time": "2025-09-28T18:17:01.948113Z"
    }
   },
   "source": [
    "# ---------- 在 Jupyter 中使用 ----------\n",
    "\n",
    "test_csv = r\"C:\\Users\\zxy01\\Desktop\\test_metadata_new.csv\"   # 测试集 CSV 路径\n",
    "n_classes = 4                    # 类别数\n",
    "fusion = \"mean\"                  # 或 \"weighted\"\n",
    "export_csv = \"predictions_fused.csv\"\n",
    "rounds = 1\n",
    "\n",
    "meta = pd.read_csv(test_csv)\n",
    "assert \"patient_id\" in meta.columns and \"label\" in meta.columns\n",
    "pids = meta[\"patient_id\"].astype(str).tolist()\n",
    "y_raw = meta[\"label\"].tolist()\n",
    "y_id, str2id, id2str = encode_labels(y_raw)\n",
    "\n",
    "strategy = PredictAndFuseStrategy(patient_ids=pids, label_ids=y_id, id2label=id2str, fusion=fusion)\n",
    "\n",
    "fl.server.start_server(\n",
    "    server_address=\"0.0.0.0:8080\",\n",
    "    config=fl.server.ServerConfig(num_rounds=rounds),\n",
    "    strategy=strategy,\n",
    ")\n",
    "\n",
    "final_df = strategy.export_final(export_csv)\n",
    "print(\"Final predictions saved to:\", export_csv)\n",
    "final_df.head()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[93mWARNING \u001B[0m:   DEPRECATED FEATURE: flwr.server.start_server() is deprecated.\n",
      "\tInstead, use the `flower-superlink` CLI command to start a SuperLink as shown below:\n",
      "\n",
      "\t\t$ flower-superlink --insecure\n",
      "\n",
      "\tTo view usage and all available options, run:\n",
      "\n",
      "\t\t$ flower-superlink --help\n",
      "\n",
      "\tUsing `start_server()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001B[92mINFO \u001B[0m:      Starting Flower server, config: num_rounds=1, no round_timeout\n",
      "\u001B[92mINFO \u001B[0m:      Flower ECE: gRPC server running (1 rounds), SSL is disabled\n",
      "\u001B[92mINFO \u001B[0m:      [INIT]\n",
      "\u001B[92mINFO \u001B[0m:      Requesting initial parameters from one random client\n",
      "\u001B[92mINFO \u001B[0m:      Received initial parameters from one random client\n",
      "\u001B[92mINFO \u001B[0m:      Starting evaluation of initial global parameters\n",
      "\u001B[92mINFO \u001B[0m:      Evaluation returned no results (`None`)\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [ROUND 1]\n",
      "\u001B[92mINFO \u001B[0m:      configure_fit: no clients selected, cancel\n",
      "\u001B[92mINFO \u001B[0m:      configure_evaluate: strategy sampled 1 clients (out of 1)\n",
      "\u001B[92mINFO \u001B[0m:      aggregate_evaluate: received 1 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [SUMMARY]\n",
      "\u001B[92mINFO \u001B[0m:      Run finished 1 round(s) in 1.53s\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (loss, distributed):\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 1: 0.0\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001B[92mINFO \u001B[0m:      \t{'acc_partial': [(1, 0.55)],\n",
      "\u001B[92mINFO \u001B[0m:      \t 'macro_f1_partial': [(1, 0.4018665158371041)],\n",
      "\u001B[92mINFO \u001B[0m:      \t 'n_pred': [(1, 20)]}\n",
      "\u001B[92mINFO \u001B[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 1] acc=0.5500, macro_f1=0.4019, n_pred=20/20\n",
      "Final predictions saved to: predictions_fused.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     patient_id                                          probs_WSI  pred_WSI  \\\n",
       "0  TCGA-A2-A3XZ  [0.996105920569524, 0.00281130159105442, 0.000...         0   \n",
       "1  TCGA-AC-A2FB  [0.0016083637394169912, 0.9956820159337193, 0....         1   \n",
       "2  TCGA-A7-A426  [0.5270273223601764, 0.001833717093735818, 0.4...         0   \n",
       "3  TCGA-A8-A093  [0.0008713799289258712, 0.9964010916515933, 0....         1   \n",
       "4  TCGA-A2-A04N  [0.997132319267581, 0.0003141789444394046, 0.0...         0   \n",
       "\n",
       "                                         probs_fused  pred_fused  \n",
       "0  [0.996105920569524, 0.00281130159105442, 0.000...           0  \n",
       "1  [0.0016083637394169912, 0.9956820159337193, 0....           1  \n",
       "2  [0.5270273223601764, 0.001833717093735818, 0.4...           0  \n",
       "3  [0.0008713799289258712, 0.9964010916515933, 0....           1  \n",
       "4  [0.997132319267581, 0.0003141789444394046, 0.0...           0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>probs_WSI</th>\n",
       "      <th>pred_WSI</th>\n",
       "      <th>probs_fused</th>\n",
       "      <th>pred_fused</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-A2-A3XZ</td>\n",
       "      <td>[0.996105920569524, 0.00281130159105442, 0.000...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.996105920569524, 0.00281130159105442, 0.000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-AC-A2FB</td>\n",
       "      <td>[0.0016083637394169912, 0.9956820159337193, 0....</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0016083637394169912, 0.9956820159337193, 0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-A7-A426</td>\n",
       "      <td>[0.5270273223601764, 0.001833717093735818, 0.4...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.5270273223601764, 0.001833717093735818, 0.4...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-A8-A093</td>\n",
       "      <td>[0.0008713799289258712, 0.9964010916515933, 0....</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0008713799289258712, 0.9964010916515933, 0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-A2-A04N</td>\n",
       "      <td>[0.997132319267581, 0.0003141789444394046, 0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.997132319267581, 0.0003141789444394046, 0.0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
