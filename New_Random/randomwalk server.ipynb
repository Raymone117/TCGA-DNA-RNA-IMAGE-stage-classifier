{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T06:11:10.922439Z",
     "start_time": "2025-10-21T06:11:10.800896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# ============================================================\n",
    "# Utility Functions\n",
    "# ============================================================\n",
    "\n",
    "def _to_numpy(x):\n",
    "    \"\"\"Convert to numpy array\"\"\"\n",
    "    return np.asarray(x, dtype=float)\n",
    "\n",
    "def encode_labels(y: List[Any]):\n",
    "    \"\"\"Encode string labels to integer IDs 0..C-1\"\"\"\n",
    "    uniq = sorted(list({str(v) for v in y}))\n",
    "    str2id = {s: i for i, s in enumerate(uniq)}\n",
    "    y_id = np.array([str2id[str(v)] for v in y], dtype=int)\n",
    "    id2str = {i: s for s, i in str2id.items()}\n",
    "    return y_id, str2id, id2str\n",
    "\n",
    "def fuse_softmax(prob_list: List[np.ndarray], weights: List[float] | None = None) -> np.ndarray:\n",
    "    \"\"\"Fuse multiple modality softmax probability vectors via weighted mean\"\"\"\n",
    "    if len(prob_list) == 1:\n",
    "        return prob_list[0]\n",
    "    P = np.vstack(prob_list)\n",
    "    if weights is None:\n",
    "        w = np.ones((P.shape[0], 1))\n",
    "    else:\n",
    "        w = _to_numpy(weights).reshape(-1, 1)\n",
    "    P = (P * w).sum(axis=0) / w.sum()\n",
    "    P = np.clip(P, 1e-9, 1.0)\n",
    "    P = P / P.sum()\n",
    "    return P\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Custom Federated Strategy: Prediction + Fusion Only\n",
    "# ============================================================\n",
    "\n",
    "class PredictAndFuseStrategy(fl.server.strategy.FedAvg):\n",
    "    \"\"\"\n",
    "    Custom federated strategy for prediction only.\n",
    "    Clients return softmax probabilities, and the server fuses them by patient_id.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patient_ids: List[str], label_ids: np.ndarray, id2label: Dict[int, str], fusion: str = \"mean\"):\n",
    "        super().__init__(\n",
    "            fraction_fit=0.0,          # Disable training\n",
    "            min_fit_clients=0,\n",
    "            fraction_evaluate=1.0,     # All clients perform evaluate (i.e., predict)\n",
    "            min_evaluate_clients=1,\n",
    "            min_available_clients=1,\n",
    "        )\n",
    "        self.patient_ids = patient_ids\n",
    "        self.labels = label_ids\n",
    "        self.id2label = id2label\n",
    "        self.fusion = fusion\n",
    "        self.buffer: Dict[str, Dict[str, np.ndarray]] = defaultdict(dict)\n",
    "\n",
    "    def evaluate(self, server_round: int, parameters):\n",
    "        \"\"\"No global model evaluation\"\"\"\n",
    "        return None\n",
    "\n",
    "    def configure_evaluate(self, server_round: int, parameters, client_manager):\n",
    "        \"\"\"Broadcast prediction task to all clients\"\"\"\n",
    "        config = {\"task\": \"predict\", \"round\": server_round}\n",
    "        evaluate_ins = fl.server.client_proxy.EvaluateIns(parameters, config)\n",
    "        clients = list(client_manager.all().values())\n",
    "        return [(client, evaluate_ins) for client in clients]\n",
    "\n",
    "    def aggregate_evaluate(self, server_round: int, results, failures):\n",
    "        \"\"\"Collect client predictions and perform fusion\"\"\"\n",
    "        for client_proxy, evaluate_res in results:\n",
    "            metrics = evaluate_res.metrics or {}\n",
    "            preds_blob = metrics.get(\"preds_json\", b\"\")\n",
    "            preds_json = preds_blob.decode(\"utf-8\") if isinstance(preds_blob, bytes) else preds_blob\n",
    "            if not preds_json:\n",
    "                continue\n",
    "            rows = json.loads(preds_json)\n",
    "\n",
    "            for r in rows:\n",
    "                pid = str(r[\"patient_id\"])\n",
    "                probs = _to_numpy(r[\"probs\"])\n",
    "                modality = str(r.get(\"modality\", \"unknown\"))\n",
    "                self.buffer[pid][modality] = probs\n",
    "\n",
    "        # ===== Evaluate partial results so far =====\n",
    "        y_true = self.labels\n",
    "        y_pred_partial = []\n",
    "        has_pred = []\n",
    "\n",
    "        for pid in self.patient_ids:\n",
    "            modal_dict = self.buffer.get(pid, {})\n",
    "            if not modal_dict:\n",
    "                has_pred.append(False)\n",
    "                y_pred_partial.append(-1)\n",
    "                continue\n",
    "            probs_list = list(modal_dict.values())\n",
    "            fused = fuse_softmax(probs_list)\n",
    "            y_pred_partial.append(int(np.argmax(fused)))\n",
    "            has_pred.append(True)\n",
    "\n",
    "        idx = [i for i, ok in enumerate(has_pred) if ok]\n",
    "        metrics = {}\n",
    "        if idx:\n",
    "            yt = y_true[idx]\n",
    "            yp = np.array(y_pred_partial)[idx]\n",
    "            acc = float(accuracy_score(yt, yp))\n",
    "            mf1 = float(f1_score(yt, yp, average=\"macro\"))\n",
    "            metrics = {\"acc_partial\": acc, \"macro_f1_partial\": mf1, \"n_pred\": len(idx)}\n",
    "            print(f\"[Round {server_round}] ✅ Fused {len(idx)}/{len(y_true)} samples, acc={acc:.4f}, macro_f1={mf1:.4f}\")\n",
    "        else:\n",
    "            print(f\"[Round {server_round}] ⚠ No client predictions received yet\")\n",
    "\n",
    "        return 0.0, metrics\n",
    "\n",
    "    def export_final(self, out_csv: str):\n",
    "        \"\"\"Export fused predictions for each patient\"\"\"\n",
    "        records = []\n",
    "        for pid in self.patient_ids:\n",
    "            modal_dict = self.buffer.get(pid, {})\n",
    "            row = {\"patient_id\": pid}\n",
    "            for m, p in modal_dict.items():\n",
    "                row[f\"probs_{m}\"] = json.dumps(p.tolist())\n",
    "                row[f\"pred_{m}\"] = int(np.argmax(p))\n",
    "            if modal_dict:\n",
    "                fused = fuse_softmax(list(modal_dict.values()))\n",
    "                row[\"probs_fused\"] = json.dumps(fused.tolist())\n",
    "                row[\"pred_fused\"] = int(np.argmax(fused))\n",
    "            records.append(row)\n",
    "        df = pd.DataFrame(records)\n",
    "        df.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "        print(f\"✅ Final fused prediction results saved to: {out_csv}\")\n",
    "        return df\n"
   ],
   "id": "eefb7a356e47aef1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T06:11:14.721012Z",
     "start_time": "2025-10-21T06:11:11.528247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# ============================================================\n",
    "# 启动服务器\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 你需要的测试元数据文件（包含 patient_id, label）\n",
    "    test_csv = r\"C:\\Users\\mxjli\\Desktop\\test_metadata_THENEWEST - 28.csv\"\n",
    "    n_classes = 4\n",
    "    fusion = \"mean\"\n",
    "    export_csv = \"predictions_fused.csv\"\n",
    "    rounds = 1\n",
    "\n",
    "    meta = pd.read_csv(test_csv)\n",
    "    assert \"patient_id\" in meta.columns and \"label\" in meta.columns\n",
    "\n",
    "    pids = meta[\"patient_id\"].astype(str).tolist()\n",
    "    y_raw = meta[\"label\"].tolist()\n",
    "    y_id, str2id, id2str = encode_labels(y_raw)\n",
    "\n",
    "    print(f\"[INFO] Loaded {len(pids)} test patients with labels.\")\n",
    "    strategy = PredictAndFuseStrategy(patient_ids=pids, label_ids=y_id, id2label=id2str, fusion=fusion)\n",
    "\n",
    "    # 启动 Flower 服务器\n",
    "    fl.server.start_server(\n",
    "        server_address=\"0.0.0.0:8090\",\n",
    "        config=fl.server.ServerConfig(num_rounds=rounds),\n",
    "        strategy=strategy,\n",
    "    )\n",
    "\n",
    "    # 导出最终结果\n",
    "    final_df = strategy.export_final(export_csv)\n",
    "    print(\"✅ Final predictions saved to:\", export_csv)\n",
    "    print(final_df.head())\n"
   ],
   "id": "b0a62bdd10c2d479",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[93mWARNING \u001B[0m:   DEPRECATED FEATURE: flwr.server.start_server() is deprecated.\n",
      "\tInstead, use the `flower-superlink` CLI command to start a SuperLink as shown below:\n",
      "\n",
      "\t\t$ flower-superlink --insecure\n",
      "\n",
      "\tTo view usage and all available options, run:\n",
      "\n",
      "\t\t$ flower-superlink --help\n",
      "\n",
      "\tUsing `start_server()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001B[92mINFO \u001B[0m:      Starting Flower server, config: num_rounds=1, no round_timeout\n",
      "\u001B[92mINFO \u001B[0m:      Flower ECE: gRPC server running (1 rounds), SSL is disabled\n",
      "\u001B[92mINFO \u001B[0m:      [INIT]\n",
      "\u001B[92mINFO \u001B[0m:      Requesting initial parameters from one random client\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded 28 test patients with labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      Received initial parameters from one random client\n",
      "\u001B[92mINFO \u001B[0m:      Starting evaluation of initial global parameters\n",
      "\u001B[92mINFO \u001B[0m:      Evaluation returned no results (`None`)\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [ROUND 1]\n",
      "\u001B[92mINFO \u001B[0m:      configure_fit: no clients selected, cancel\n",
      "\u001B[92mINFO \u001B[0m:      configure_evaluate: strategy sampled 1 clients (out of 1)\n",
      "\u001B[92mINFO \u001B[0m:      aggregate_evaluate: received 1 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [SUMMARY]\n",
      "\u001B[92mINFO \u001B[0m:      Run finished 1 round(s) in 0.08s\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (loss, distributed):\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 1: 0.0\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001B[92mINFO \u001B[0m:      \t{'acc_partial': [(1, 0.35714285714285715)],\n",
      "\u001B[92mINFO \u001B[0m:      \t 'macro_f1_partial': [(1, 0.29166666666666663)],\n",
      "\u001B[92mINFO \u001B[0m:      \t 'n_pred': [(1, 28)]}\n",
      "\u001B[92mINFO \u001B[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 1] ✅ Fused 28/28 samples, acc=0.3571, macro_f1=0.2917\n",
      "✅ Final fused prediction results saved to: predictions_fused.csv\n",
      "✅ Final predictions saved to: predictions_fused.csv\n",
      "     patient_id                                          probs_WSI  pred_WSI  \\\n",
      "0  TCGA-A2-A3XZ  [0.48621126371500306, 0.35949420481930233, 0.1...         0   \n",
      "1  TCGA-A7-A426  [0.16658036898221074, 0.6485370507533245, 0.13...         1   \n",
      "2  TCGA-A2-A04N  [0.36131723604752164, 0.2906667768920461, 0.16...         0   \n",
      "3  TCGA-A8-A09X  [0.08855836624591445, 0.11588980128127209, 0.2...         3   \n",
      "4  TCGA-PL-A8LX  [0.22262549905644102, 0.17420840362947843, 0.2...         3   \n",
      "\n",
      "                                         probs_fused  pred_fused  \n",
      "0  [0.48621126371500306, 0.35949420481930233, 0.1...           0  \n",
      "1  [0.16658036898221074, 0.6485370507533245, 0.13...           1  \n",
      "2  [0.36131723604752164, 0.2906667768920461, 0.16...           0  \n",
      "3  [0.08855836624591445, 0.11588980128127209, 0.2...           3  \n",
      "4  [0.22262549905644102, 0.17420840362947843, 0.2...           3  \n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ff50fbe828fb1fa1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
