{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-16T10:40:25.349667Z",
     "start_time": "2025-09-16T10:38:39.496629Z"
    }
   },
   "source": [
    "# wsi_stage_baseline.py\n",
    "import os, sys, math\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openslide\n",
    "from skimage import color, filters, morphology, measure, exposure\n",
    "from skimage.color import hed_from_rgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# ===== 配置：把它改成你的根目录（含 stage 1/2/3/4 train/test）=====\n",
    "ROOT = r\"C:\\Users\\mxjli\\Desktop\\image\"\n",
    "\n",
    "# ===== 工具函数 =====\n",
    "def read_best_level_thumbnail(slide_path, min_dim=3000):\n",
    "    \"\"\"用 OpenSlide 读取接近 min_dim 的缩略图（长边≈min_dim），避免读全分辨率。\"\"\"\n",
    "    slide = openslide.OpenSlide(slide_path)\n",
    "    w, h = slide.dimensions\n",
    "    scale = max(w, h) / float(min_dim)\n",
    "    new_w, new_h = int(w/scale), int(h/scale)\n",
    "    img = slide.get_thumbnail((new_w, new_h))  # PIL\n",
    "    slide.close()\n",
    "    return np.asarray(img)  # uint8 RGB\n",
    "\n",
    "def tissue_mask(rgb):\n",
    "    \"\"\"简单组织掩码：去白底。\"\"\"\n",
    "    hsv = color.rgb2hsv(rgb)\n",
    "    v = hsv[..., 2]\n",
    "    thr = filters.threshold_otsu(v)\n",
    "    mask = v < thr * 0.98            # 去亮白\n",
    "    mask = morphology.remove_small_holes(mask, 256)\n",
    "    mask = morphology.remove_small_objects(mask, 256)\n",
    "    return mask\n",
    "\n",
    "def he_nuclei_mask(rgb, tissue):\n",
    "    \"\"\"H&E分离，取H通道（核染色）并自动阈值。\"\"\"\n",
    "    # skimage 需要float并在[0,1]\n",
    "    rgbf = np.clip(rgb/255.0, 0, 1)\n",
    "    hed = color.separate_stains(rgbf, hed_from_rgb)\n",
    "    H = hed[..., 0]                  # Hematoxylin\n",
    "    H = exposure.rescale_intensity(H, in_range=(np.percentile(H[tissue], 2), np.percentile(H[tissue], 98)))\n",
    "    # H 值越大核越深，取Otsu\n",
    "    thr = filters.threshold_otsu(H[tissue])\n",
    "    nuc = np.zeros_like(H, dtype=bool)\n",
    "    nuc[tissue] = H[tissue] > thr\n",
    "    # 形态学清理\n",
    "    nuc = morphology.remove_small_objects(nuc, 64)\n",
    "    nuc = morphology.binary_opening(nuc, morphology.disk(2))\n",
    "    return nuc, H\n",
    "\n",
    "def wsi_features(svs_path):\n",
    "    rgb = read_best_level_thumbnail(svs_path)\n",
    "    mask = tissue_mask(rgb)\n",
    "    if mask.sum() < 5000:   # 太小视为无组织\n",
    "        return None\n",
    "    nuc, H = he_nuclei_mask(rgb, mask)\n",
    "\n",
    "    tissue_area = mask.sum()\n",
    "    tumor_area  = nuc.sum()\n",
    "    tumor_frac  = tumor_area / tissue_area\n",
    "\n",
    "    # 连通域\n",
    "    lab = measure.label(nuc)\n",
    "    props = measure.regionprops(lab)\n",
    "    if len(props) == 0:\n",
    "        largest = 0\n",
    "    else:\n",
    "        largest = max(p.area for p in props)\n",
    "    largest_cc_frac = largest / tissue_area\n",
    "    cc_count_per_mpx = len(props) / (rgb.shape[0]*rgb.shape[1]/1_000_000.0)\n",
    "\n",
    "    h_vals = H[mask]\n",
    "    h_mean, h_std = float(h_vals.mean()), float(h_vals.std())\n",
    "\n",
    "    return dict(\n",
    "        tumor_frac=tumor_frac,\n",
    "        largest_cc_frac=largest_cc_frac,\n",
    "        cc_count_per_mpx=cc_count_per_mpx,\n",
    "        h_mean=h_mean, h_std=h_std\n",
    "    )\n",
    "\n",
    "def scan_split(split_dir):\n",
    "    \"\"\"返回该 split（train/test）下所有 stage 的特征表\"\"\"\n",
    "    rows = []\n",
    "    for stage_name in [\"stage 1\", \"stage 2\", \"stage 3\", \"stage 4\"]:\n",
    "        d = Path(split_dir) / f\"{stage_name} train\" if \"train\" in split_dir.lower() else Path(split_dir) / f\"{stage_name} test\"\n",
    "        if not d.exists():  # 也兼容你截图里：stage 1 train 这样的直接在根目录\n",
    "            d = Path(split_dir) / f\"{stage_name} {'train' if 'train' in split_dir.lower() else 'test'}\"\n",
    "        if not d.exists():\n",
    "            d = Path(split_dir).parent / f\"{stage_name} {'train' if 'train' in split_dir.lower() else 'test'}\"\n",
    "        if not d.exists():\n",
    "            d = Path(split_dir).parent / f\"{stage_name} {'train' if 'train' in split_dir.lower() else 'test'}\"\n",
    "        if not d.exists():\n",
    "            continue\n",
    "\n",
    "        label = int(stage_name.split()[1]) - 1  # 0..3\n",
    "        for p in list(d.glob(\"*.svs\")) + list(d.glob(\"*.tif\")):\n",
    "            feats = wsi_features(str(p))\n",
    "            if feats is None:\n",
    "                continue\n",
    "            feats.update(dict(path=str(p), label=label, stage=stage_name))\n",
    "            rows.append(feats)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def load_dataset(root):\n",
    "    train_df = []\n",
    "    test_df  = []\n",
    "    # 你的结构是并列的 “stage 1 train / stage 1 test …”，我们直接各扫一遍\n",
    "    for name in os.listdir(root):\n",
    "        if name.lower().endswith(\"train\"):\n",
    "            train_df.append(scan_split(Path(root)))\n",
    "            break\n",
    "    # 上面已经把所有 train/test 都扫了（函数内部根据名字判断），这里再单独把 test 合并\n",
    "    return pd.concat(train_df, ignore_index=True)\n",
    "\n",
    "# ===== 主流程：提特征 -> 训练 -> 评估 =====\n",
    "if __name__ == \"__main__\":\n",
    "    df = []\n",
    "    # 扫描一次就会把四个stage的train/test都吃到\n",
    "    for stage in [1,2,3,4]:\n",
    "        for split in [\"train\", \"test\"]:\n",
    "            d = Path(ROOT) / f\"stage {stage} {split}\"\n",
    "            if d.exists():\n",
    "                for p in list(d.glob(\"*.svs\")) + list(d.glob(\"*.tif\")):\n",
    "                    feats = wsi_features(str(p))\n",
    "                    if feats is None:\n",
    "                        continue\n",
    "                    feats.update(dict(path=str(p), label=stage-1, split=split))\n",
    "                    df.append(feats)\n",
    "    df = pd.DataFrame(df)\n",
    "    print(\"Feature rows:\", df.shape)\n",
    "    df.to_csv(\"wsi_stage_features.csv\", index=False)\n",
    "\n",
    "    # 用 train 行训练，test 行评估（若没有 test，就做随机切分）\n",
    "    if \"test\" in df[\"split\"].unique():\n",
    "        train_df = df[df.split==\"train\"].copy()\n",
    "        test_df  = df[df.split==\"test\"].copy()\n",
    "    else:\n",
    "        train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"label\"])\n",
    "\n",
    "    Xtr = train_df[[\"tumor_frac\",\"largest_cc_frac\",\"cc_count_per_mpx\",\"h_mean\",\"h_std\"]].values\n",
    "    ytr = train_df[\"label\"].values\n",
    "    Xte = test_df[[\"tumor_frac\",\"largest_cc_frac\",\"cc_count_per_mpx\",\"h_mean\",\"h_std\"]].values\n",
    "    yte = test_df[\"label\"].values\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=300, max_depth=None, random_state=0, n_jobs=-1)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    ypr = clf.predict(Xte)\n",
    "\n",
    "    print(\"\\nConfusion matrix:\\n\", confusion_matrix(yte, ypr))\n",
    "    print(\"\\nReport:\\n\", classification_report(yte, ypr, digits=4))"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 127\u001B[39m\n\u001B[32m    125\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m d.exists():\n\u001B[32m    126\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(d.glob(\u001B[33m\"\u001B[39m\u001B[33m*.svs\u001B[39m\u001B[33m\"\u001B[39m)) + \u001B[38;5;28mlist\u001B[39m(d.glob(\u001B[33m\"\u001B[39m\u001B[33m*.tif\u001B[39m\u001B[33m\"\u001B[39m)):\n\u001B[32m--> \u001B[39m\u001B[32m127\u001B[39m         feats = \u001B[43mwsi_features\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mp\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    128\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m feats \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    129\u001B[39m             \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 55\u001B[39m, in \u001B[36mwsi_features\u001B[39m\u001B[34m(svs_path)\u001B[39m\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwsi_features\u001B[39m(svs_path):\n\u001B[32m     54\u001B[39m     rgb = read_best_level_thumbnail(svs_path)\n\u001B[32m---> \u001B[39m\u001B[32m55\u001B[39m     mask = \u001B[43mtissue_mask\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrgb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     56\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m mask.sum() < \u001B[32m5000\u001B[39m:   \u001B[38;5;66;03m# 太小视为无组织\u001B[39;00m\n\u001B[32m     57\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 29\u001B[39m, in \u001B[36mtissue_mask\u001B[39m\u001B[34m(rgb)\u001B[39m\n\u001B[32m     27\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mtissue_mask\u001B[39m(rgb):\n\u001B[32m     28\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"简单组织掩码：去白底。\"\"\"\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m29\u001B[39m     hsv = \u001B[43mcolor\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrgb2hsv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrgb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     30\u001B[39m     v = hsv[..., \u001B[32m2\u001B[39m]\n\u001B[32m     31\u001B[39m     thr = filters.threshold_otsu(v)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\skimage\\_shared\\utils.py:445\u001B[39m, in \u001B[36mchannel_as_last_axis.__call__.<locals>.fixed_func\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    442\u001B[39m channel_axis = kwargs.get(\u001B[33m'\u001B[39m\u001B[33mchannel_axis\u001B[39m\u001B[33m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    444\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m channel_axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m445\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    447\u001B[39m \u001B[38;5;66;03m# TODO: convert scalars to a tuple in anticipation of eventually\u001B[39;00m\n\u001B[32m    448\u001B[39m \u001B[38;5;66;03m#       supporting a tuple of channel axes. Right now, only an\u001B[39;00m\n\u001B[32m    449\u001B[39m \u001B[38;5;66;03m#       integer or a single-element tuple is supported, though.\u001B[39;00m\n\u001B[32m    450\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m np.isscalar(channel_axis):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\skimage\\color\\colorconv.py:313\u001B[39m, in \u001B[36mrgb2hsv\u001B[39m\u001B[34m(rgb, channel_axis)\u001B[39m\n\u001B[32m    310\u001B[39m out_v = arr.max(-\u001B[32m1\u001B[39m)\n\u001B[32m    312\u001B[39m \u001B[38;5;66;03m# -- S channel\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m313\u001B[39m delta = \u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mptp\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[43m-\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    314\u001B[39m \u001B[38;5;66;03m# Ignore warning for zero divided by zero\u001B[39;00m\n\u001B[32m    315\u001B[39m old_settings = np.seterr(invalid=\u001B[33m'\u001B[39m\u001B[33mignore\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3044\u001B[39m, in \u001B[36mptp\u001B[39m\u001B[34m(a, axis, out, keepdims)\u001B[39m\n\u001B[32m   3042\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m keepdims \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np._NoValue:\n\u001B[32m   3043\u001B[39m     kwargs[\u001B[33m'\u001B[39m\u001B[33mkeepdims\u001B[39m\u001B[33m'\u001B[39m] = keepdims\n\u001B[32m-> \u001B[39m\u001B[32m3044\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_methods\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_ptp\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:237\u001B[39m, in \u001B[36m_ptp\u001B[39m\u001B[34m(a, axis, out, keepdims)\u001B[39m\n\u001B[32m    235\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_ptp\u001B[39m(a, axis=\u001B[38;5;28;01mNone\u001B[39;00m, out=\u001B[38;5;28;01mNone\u001B[39;00m, keepdims=\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m    236\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m um.subtract(\n\u001B[32m--> \u001B[39m\u001B[32m237\u001B[39m         \u001B[43mumr_maximum\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeepdims\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[32m    238\u001B[39m         umr_minimum(a, axis, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m, keepdims),\n\u001B[32m    239\u001B[39m         out\n\u001B[32m    240\u001B[39m     )\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T11:27:52.171381Z",
     "start_time": "2025-09-16T11:18:20.098342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# wsi_stage_baseline_mpp.py\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openslide\n",
    "from skimage import color, filters, morphology, measure, exposure\n",
    "from skimage.color import hed_from_rgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ===== 路径：改成你的根目录（含 stage 1/2/3/4 train/test）=====\n",
    "ROOT = r\"C:\\Users\\mxjli\\Desktop\\image\"\n",
    "\n",
    "# 若为 True，没有 mpp 的切片就跳过；为 False 则退化为只用比例特征\n",
    "REQUIRE_MPP = True\n",
    "\n",
    "def read_thumbnail_and_geometry(svs_path, min_dim=3000):\n",
    "    \"\"\"读取缩略图 + 返回到 level-0 的比例 scale 以及 mpp 信息\"\"\"\n",
    "    slide = openslide.OpenSlide(svs_path)\n",
    "    W0, H0 = slide.dimensions\n",
    "    scale = max(W0, H0) / float(min_dim)  # thumb 像素 -> level0 像素的比例\n",
    "    new_w, new_h = int(W0/scale), int(H0/scale)\n",
    "    img = slide.get_thumbnail((new_w, new_h))\n",
    "    # mpp（微米/像素），有些厂商字段不同，这里只取 openslide 标准\n",
    "    mpp_x = slide.properties.get(\"openslide.mpp-x\", None)\n",
    "    mpp_y = slide.properties.get(\"openslide.mpp-y\", None)\n",
    "    slide.close()\n",
    "    mpp_x = float(mpp_x) if mpp_x not in (None, \"\") else None\n",
    "    mpp_y = float(mpp_y) if mpp_y not in (None, \"\") else None\n",
    "    return np.asarray(img), scale, mpp_x, mpp_y\n",
    "\n",
    "def tissue_mask(rgb):\n",
    "    hsv = color.rgb2hsv(rgb)\n",
    "    v = hsv[..., 2]\n",
    "    thr = filters.threshold_otsu(v)\n",
    "    mask = v < thr * 0.98\n",
    "    mask = morphology.remove_small_holes(mask, 256)\n",
    "    mask = morphology.remove_small_objects(mask, 256)\n",
    "    return mask\n",
    "\n",
    "def he_nuclei_mask(rgb, tissue):\n",
    "    rgbf = np.clip(rgb/255.0, 0, 1)\n",
    "    hed = color.separate_stains(rgbf, hed_from_rgb)\n",
    "    H = hed[..., 0]\n",
    "    H = exposure.rescale_intensity(\n",
    "        H,\n",
    "        in_range=(np.percentile(H[tissue], 2), np.percentile(H[tissue], 98))\n",
    "    )\n",
    "    thr = filters.threshold_otsu(H[tissue])\n",
    "    nuc = np.zeros_like(H, dtype=bool)\n",
    "    nuc[tissue] = H[tissue] > thr\n",
    "    nuc = morphology.remove_small_objects(nuc, 64)\n",
    "    nuc = morphology.binary_opening(nuc, morphology.disk(2))\n",
    "    return nuc, H\n",
    "\n",
    "def wsi_features(svs_path):\n",
    "    rgb, scale, mpp_x, mpp_y = read_thumbnail_and_geometry(svs_path)\n",
    "    # 缺 mpp 的处理\n",
    "    has_mpp = (mpp_x is not None) and (mpp_y is not None) and (mpp_x > 0) and (mpp_y > 0)\n",
    "    if REQUIRE_MPP and not has_mpp:\n",
    "        return None  # 直接跳过\n",
    "    mask = tissue_mask(rgb)\n",
    "    if mask.sum() < 5000:\n",
    "        return None\n",
    "    nuc, H = he_nuclei_mask(rgb, mask)\n",
    "\n",
    "    # --- 缩略图上的像素计数 ---\n",
    "    tissue_px_thumb = int(mask.sum())\n",
    "    tumor_px_thumb  = int(nuc.sum())\n",
    "    largest_cc_px_thumb = 0\n",
    "    lab = measure.label(nuc)\n",
    "    props = measure.regionprops(lab)\n",
    "    if len(props) > 0:\n",
    "        largest_cc_px_thumb = max(p.area for p in props)\n",
    "    cc_count = len(props)\n",
    "\n",
    "    # --- 比例特征（与分辨率无关） ---\n",
    "    tumor_frac = tumor_px_thumb / tissue_px_thumb\n",
    "    largest_cc_frac = largest_cc_px_thumb / tissue_px_thumb\n",
    "    h_vals = H[mask]\n",
    "    h_mean, h_std = float(h_vals.mean()), float(h_vals.std())\n",
    "\n",
    "    feats = dict(\n",
    "        tumor_frac=tumor_frac,\n",
    "        largest_cc_frac=largest_cc_frac,\n",
    "        h_mean=h_mean, h_std=h_std,\n",
    "        cc_count_thumb=cc_count  # 先存，下面若有 mpp 会转成每 cm²\n",
    "    )\n",
    "\n",
    "    # --- 物理面积（与分辨率有关，需要 mpp + scale） ---\n",
    "    if has_mpp:\n",
    "        # 每个 level-0 像素的面积（mm²）\n",
    "        # mpp 单位是微米/像素 → 每像素面积(um²) = mpp_x*mpp_y → 换算成 mm²: *1e-6\n",
    "        px_area_mm2 = (mpp_x * mpp_y) * 1e-6\n",
    "        # 缩略图像素需要乘回到 level-0：thumb_px * scale^2\n",
    "        s2 = scale * scale\n",
    "        tissue_area_mm2  = tissue_px_thumb  * s2 * px_area_mm2\n",
    "        tumor_area_mm2   = tumor_px_thumb   * s2 * px_area_mm2\n",
    "        largest_cc_mm2   = largest_cc_px_thumb * s2 * px_area_mm2\n",
    "        tissue_area_cm2  = tissue_area_mm2 / 100.0\n",
    "        tumor_area_cm2   = tumor_area_mm2  / 100.0\n",
    "        largest_cc_cm2   = largest_cc_mm2  / 100.0\n",
    "\n",
    "        # 物理尺度上的密度指标（每 cm² 的病灶个数）\n",
    "        cc_per_cm2 = cc_count / max(tissue_area_cm2, 1e-6)\n",
    "\n",
    "        feats.update(dict(\n",
    "            tissue_area_mm2=tissue_area_mm2,\n",
    "            tumor_area_mm2=tumor_area_mm2,\n",
    "            largest_cc_mm2=largest_cc_mm2,\n",
    "            tissue_area_cm2=tissue_area_cm2,\n",
    "            tumor_area_cm2=tumor_area_cm2,\n",
    "            largest_cc_cm2=largest_cc_cm2,\n",
    "            cc_per_cm2=cc_per_cm2,\n",
    "            has_mpp=1\n",
    "        ))\n",
    "    else:\n",
    "        feats.update(dict(\n",
    "            tissue_area_mm2=np.nan, tumor_area_mm2=np.nan, largest_cc_mm2=np.nan,\n",
    "            tissue_area_cm2=np.nan, tumor_area_cm2=np.nan, largest_cc_cm2=np.nan,\n",
    "            cc_per_cm2=np.nan, has_mpp=0\n",
    "        ))\n",
    "    return feats\n",
    "\n",
    "def collect_rows(root):\n",
    "    rows = []\n",
    "    for stage in [1,2,3,4]:\n",
    "        for split in [\"train\",\"test\"]:\n",
    "            d = Path(root) / f\"stage {stage} {split}\"\n",
    "            if not d.exists():\n",
    "                continue\n",
    "            label = stage - 1\n",
    "            for p in list(d.glob(\"*.svs\")) + list(d.glob(\"*.tif\")):\n",
    "                feats = wsi_features(str(p))\n",
    "                if feats is None:\n",
    "                    continue\n",
    "                feats.update(dict(path=str(p), label=label, split=split))\n",
    "                rows.append(feats)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = collect_rows(ROOT)\n",
    "    print(\"Feature rows:\", df.shape)\n",
    "    df.to_csv(\"wsi_stage_features_mpp.csv\", index=False)\n",
    "\n",
    "    # 训练：优先使用含物理特征的样本\n",
    "    have_mpp = df[df[\"has_mpp\"]==1]\n",
    "    if len(have_mpp) >= 8:   # 至少每类若干个更稳\n",
    "        train_df = have_mpp[have_mpp.split==\"train\"] if \"test\" in df.split.unique() else have_mpp\n",
    "        test_df  = have_mpp[have_mpp.split==\"test\"]  if \"test\" in df.split.unique() else None\n",
    "        feature_cols = [\"tumor_frac\",\"largest_cc_frac\",\"h_mean\",\"h_std\",\n",
    "                        \"tumor_area_mm2\",\"largest_cc_mm2\",\"tissue_area_mm2\",\"cc_per_cm2\"]\n",
    "    else:\n",
    "        # 回退：只用比例特征\n",
    "        train_df = df[df.split==\"train\"] if \"test\" in df.split.unique() else df\n",
    "        test_df  = df[df.split==\"test\"]  if \"test\" in df.split.unique() else None\n",
    "        feature_cols = [\"tumor_frac\",\"largest_cc_frac\",\"h_mean\",\"h_std\"]\n",
    "\n",
    "    if test_df is None:\n",
    "        train_df, test_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df[\"label\"])\n",
    "\n",
    "    Xtr = train_df[feature_cols].values\n",
    "    ytr = train_df[\"label\"].values\n",
    "    Xte = test_df[feature_cols].values\n",
    "    yte = test_df[\"label\"].values\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=400, random_state=0, n_jobs=-1)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    ypr = clf.predict(Xte)\n",
    "\n",
    "    print(\"Using features:\", feature_cols)\n",
    "    print(\"\\nConfusion matrix:\\n\", confusion_matrix(yte, ypr))\n",
    "    print(\"\\nReport:\\n\", classification_report(yte, ypr, digits=4))"
   ],
   "id": "b3ada90923993972",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature rows: (154, 16)\n",
      "Using features: ['tumor_frac', 'largest_cc_frac', 'h_mean', 'h_std', 'tumor_area_mm2', 'largest_cc_mm2', 'tissue_area_mm2', 'cc_per_cm2']\n",
      "\n",
      "Confusion matrix:\n",
      " [[2 1 1 0]\n",
      " [3 1 0 0]\n",
      " [0 2 0 0]\n",
      " [0 2 0 0]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4000    0.5000    0.4444         4\n",
      "           1     0.1667    0.2500    0.2000         4\n",
      "           2     0.0000    0.0000    0.0000         2\n",
      "           3     0.0000    0.0000    0.0000         2\n",
      "\n",
      "    accuracy                         0.2500        12\n",
      "   macro avg     0.1417    0.1875    0.1611        12\n",
      "weighted avg     0.1889    0.2500    0.2148        12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T15:44:52.812948Z",
     "start_time": "2025-09-16T15:36:37.221157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 改进后的 wsi_stage_baseline_mpp.py（增加CNN特征 + RGB直方图 + 平衡权重）\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openslide\n",
    "from PIL import Image\n",
    "from skimage import color, filters, morphology, measure, exposure\n",
    "from skimage.color import hed_from_rgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "\n",
    "# ===== 路径设置 =====\n",
    "ROOT = r\"C:\\Users\\mxjli\\Desktop\\image\"\n",
    "REQUIRE_MPP = True\n",
    "\n",
    "# ===== CNN 模型初始化 =====\n",
    "class ResNetFeatureExtractor:\n",
    "    def __init__(self):\n",
    "        model = resnet18(pretrained=True)\n",
    "        model.fc = nn.Identity()\n",
    "        self.model = model.eval()\n",
    "        self.transform = T.Compose([\n",
    "            T.Resize((224, 224)),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def extract(self, pil_img):\n",
    "        x = self.transform(pil_img).unsqueeze(0)  # Add batch dim\n",
    "        with torch.no_grad():\n",
    "            feat = self.model(x).squeeze(0).numpy()\n",
    "        return feat\n",
    "\n",
    "cnn_extractor = ResNetFeatureExtractor()\n",
    "\n",
    "# ===== 图像分析部分 =====\n",
    "def read_thumbnail_and_geometry(svs_path, min_dim=3000):\n",
    "    slide = openslide.OpenSlide(svs_path)\n",
    "    W0, H0 = slide.dimensions\n",
    "    scale = max(W0, H0) / float(min_dim)\n",
    "    new_w, new_h = int(W0 / scale), int(H0 / scale)\n",
    "    img = slide.get_thumbnail((new_w, new_h))\n",
    "    mpp_x = slide.properties.get(\"openslide.mpp-x\", None)\n",
    "    mpp_y = slide.properties.get(\"openslide.mpp-y\", None)\n",
    "    slide.close()\n",
    "    mpp_x = float(mpp_x) if mpp_x not in (None, \"\") else None\n",
    "    mpp_y = float(mpp_y) if mpp_y not in (None, \"\") else None\n",
    "    return img, np.asarray(img), scale, mpp_x, mpp_y\n",
    "\n",
    "def tissue_mask(rgb):\n",
    "    hsv = color.rgb2hsv(rgb)\n",
    "    v = hsv[..., 2]\n",
    "    thr = filters.threshold_otsu(v)\n",
    "    mask = v < thr * 0.98\n",
    "    mask = morphology.remove_small_holes(mask, 256)\n",
    "    mask = morphology.remove_small_objects(mask, 256)\n",
    "    return mask\n",
    "\n",
    "def he_nuclei_mask(rgb, tissue):\n",
    "    rgbf = np.clip(rgb / 255.0, 0, 1)\n",
    "    hed = color.separate_stains(rgbf, hed_from_rgb)\n",
    "    H = hed[..., 0]\n",
    "    H = exposure.rescale_intensity(\n",
    "        H, in_range=(np.percentile(H[tissue], 2), np.percentile(H[tissue], 98))\n",
    "    )\n",
    "    thr = filters.threshold_otsu(H[tissue])\n",
    "    nuc = np.zeros_like(H, dtype=bool)\n",
    "    nuc[tissue] = H[tissue] > thr\n",
    "    nuc = morphology.remove_small_objects(nuc, 64)\n",
    "    nuc = morphology.binary_opening(nuc, morphology.disk(2))\n",
    "    return nuc, H\n",
    "\n",
    "def rgb_hist_features(rgb):\n",
    "    feats = {}\n",
    "    for i, c in enumerate(['r', 'g', 'b']):\n",
    "        hist, _ = np.histogram(rgb[..., i], bins=32, range=(0, 255), density=True)\n",
    "        feats.update({f\"{c}_hist_{j}\": hist[j] for j in range(32)})\n",
    "    return feats\n",
    "\n",
    "def wsi_features(svs_path):\n",
    "    pil_img, rgb, scale, mpp_x, mpp_y = read_thumbnail_and_geometry(svs_path)\n",
    "    has_mpp = (mpp_x and mpp_y and mpp_x > 0 and mpp_y > 0)\n",
    "    if REQUIRE_MPP and not has_mpp:\n",
    "        return None\n",
    "    mask = tissue_mask(rgb)\n",
    "    if mask.sum() < 5000:\n",
    "        return None\n",
    "    nuc, H = he_nuclei_mask(rgb, mask)\n",
    "\n",
    "    tissue_px_thumb = int(mask.sum())\n",
    "    tumor_px_thumb = int(nuc.sum())\n",
    "    lab = measure.label(nuc)\n",
    "    props = measure.regionprops(lab)\n",
    "    largest_cc_px_thumb = max([p.area for p in props], default=0)\n",
    "    cc_count = len(props)\n",
    "\n",
    "    tumor_frac = tumor_px_thumb / tissue_px_thumb\n",
    "    largest_cc_frac = largest_cc_px_thumb / tissue_px_thumb\n",
    "    h_vals = H[mask]\n",
    "    h_mean, h_std = float(h_vals.mean()), float(h_vals.std())\n",
    "\n",
    "    feats = dict(\n",
    "        tumor_frac=tumor_frac, largest_cc_frac=largest_cc_frac,\n",
    "        h_mean=h_mean, h_std=h_std, cc_count_thumb=cc_count\n",
    "    )\n",
    "    feats.update(rgb_hist_features(rgb))\n",
    "\n",
    "    if has_mpp:\n",
    "        px_area_mm2 = (mpp_x * mpp_y) * 1e-6\n",
    "        s2 = scale * scale\n",
    "        tissue_area_mm2 = tissue_px_thumb * s2 * px_area_mm2\n",
    "        tumor_area_mm2 = tumor_px_thumb * s2 * px_area_mm2\n",
    "        largest_cc_mm2 = largest_cc_px_thumb * s2 * px_area_mm2\n",
    "        tissue_area_cm2 = tissue_area_mm2 / 100\n",
    "        tumor_area_cm2 = tumor_area_mm2 / 100\n",
    "        largest_cc_cm2 = largest_cc_mm2 / 100\n",
    "        cc_per_cm2 = cc_count / max(tissue_area_cm2, 1e-6)\n",
    "        feats.update(dict(\n",
    "            tissue_area_mm2=tissue_area_mm2, tumor_area_mm2=tumor_area_mm2,\n",
    "            largest_cc_mm2=largest_cc_mm2, tissue_area_cm2=tissue_area_cm2,\n",
    "            tumor_area_cm2=tumor_area_cm2, largest_cc_cm2=largest_cc_cm2,\n",
    "            cc_per_cm2=cc_per_cm2, has_mpp=1\n",
    "        ))\n",
    "    else:\n",
    "        feats.update(dict(\n",
    "            tissue_area_mm2=np.nan, tumor_area_mm2=np.nan, largest_cc_mm2=np.nan,\n",
    "            tissue_area_cm2=np.nan, tumor_area_cm2=np.nan, largest_cc_cm2=np.nan,\n",
    "            cc_per_cm2=np.nan, has_mpp=0\n",
    "        ))\n",
    "\n",
    "    # 添加CNN特征（512维）\n",
    "    feats.update({f\"cnn_{i}\": v for i, v in enumerate(cnn_extractor.extract(pil_img))})\n",
    "\n",
    "    return feats\n",
    "\n",
    "def collect_rows(root):\n",
    "    rows = []\n",
    "    for stage in [1, 2, 3, 4]:\n",
    "        for split in [\"train\", \"test\"]:\n",
    "            d = Path(root) / f\"stage {stage} {split}\"\n",
    "            if not d.exists(): continue\n",
    "            label = stage - 1\n",
    "            for p in list(d.glob(\"*.svs\")) + list(d.glob(\"*.tif\")):\n",
    "                feats = wsi_features(str(p))\n",
    "                if feats is None: continue\n",
    "                feats.update(dict(path=str(p), label=label, split=split))\n",
    "                rows.append(feats)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = collect_rows(ROOT)\n",
    "    df = df[df[\"tissue_area_cm2\"] > 0.1]  # 清洗组织面积太小的样本\n",
    "    print(\"Feature rows:\", df.shape)\n",
    "    df.to_csv(\"wsi_stage_features_enhanced.csv\", index=False)\n",
    "\n",
    "    have_mpp = df[df[\"has_mpp\"] == 1]\n",
    "    if len(have_mpp) >= 8:\n",
    "        train_df = have_mpp[have_mpp.split == \"train\"] if \"test\" in df.split.unique() else have_mpp\n",
    "        test_df = have_mpp[have_mpp.split == \"test\"] if \"test\" in df.split.unique() else None\n",
    "    else:\n",
    "        train_df = df[df.split == \"train\"] if \"test\" in df.split.unique() else df\n",
    "        test_df = df[df.split == \"test\"] if \"test\" in df.split.unique() else None\n",
    "\n",
    "    if test_df is None:\n",
    "        train_df, test_df = train_test_split(train_df, test_size=0.2, stratify=train_df[\"label\"], random_state=42)\n",
    "\n",
    "    feature_cols = [col for col in train_df.columns if col.startswith(\"tumor_\") or\n",
    "                    col.startswith(\"largest_cc\") or col.startswith(\"h_\") or\n",
    "                    col.startswith(\"tissue_area\") or col.startswith(\"cc_per\") or\n",
    "                    col.startswith(\"r_hist\") or col.startswith(\"g_hist\") or col.startswith(\"b_hist\") or\n",
    "                    col.startswith(\"cnn_\")]\n",
    "\n",
    "    Xtr = train_df[feature_cols].values\n",
    "    ytr = train_df[\"label\"].values\n",
    "    Xte = test_df[feature_cols].values\n",
    "    yte = test_df[\"label\"].values\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    Xtr = scaler.fit_transform(Xtr)\n",
    "    Xte = scaler.transform(Xte)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=400, class_weight=\"balanced\", random_state=0, n_jobs=-1)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    ypr = clf.predict(Xte)\n",
    "\n",
    "    print(\"\\nConfusion matrix:\\n\", confusion_matrix(yte, ypr))\n",
    "    print(\"\\nReport:\\n\", classification_report(yte, ypr, digits=4, zero_division=0))"
   ],
   "id": "7c252498c293d86d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature rows: (117, 624)\n",
      "\n",
      "Confusion matrix:\n",
      " [[2 4 1 0]\n",
      " [2 4 4 0]\n",
      " [0 5 0 0]\n",
      " [0 2 0 0]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.2857    0.3636         7\n",
      "           1     0.2667    0.4000    0.3200        10\n",
      "           2     0.0000    0.0000    0.0000         5\n",
      "           3     0.0000    0.0000    0.0000         2\n",
      "\n",
      "    accuracy                         0.2500        24\n",
      "   macro avg     0.1917    0.1714    0.1709        24\n",
      "weighted avg     0.2569    0.2500    0.2394        24\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:05:17.594514Z",
     "start_time": "2025-09-16T16:57:39.848943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openslide\n",
    "from skimage import color, filters, morphology, measure, exposure, transform\n",
    "from skimage.color import hed_from_rgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ===== 根目录 =====\n",
    "ROOT = r\"C:\\Users\\mxjli\\Desktop\\image\"\n",
    "REQUIRE_MPP = True\n",
    "\n",
    "# ===== CNN 特征提取器 =====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = nn.Identity()  # 去掉最后分类层\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n",
    "\n",
    "# 图像预处理\n",
    "transform_cnn = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((224,224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def extract_cnn_feature(rgb_crop):\n",
    "    \"\"\"输入RGB图像 -> 提取CNN特征\"\"\"\n",
    "    x = transform_cnn(rgb_crop).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        feat = resnet(x).cpu().numpy().flatten()\n",
    "    return feat\n",
    "\n",
    "# ===== 你的原始函数（保留不变）=====\n",
    "def read_thumbnail_and_geometry(svs_path, min_dim=3000):\n",
    "    slide = openslide.OpenSlide(svs_path)\n",
    "    W0, H0 = slide.dimensions\n",
    "    scale = max(W0, H0) / float(min_dim)\n",
    "    new_w, new_h = int(W0/scale), int(H0/scale)\n",
    "    img = slide.get_thumbnail((new_w, new_h))\n",
    "    mpp_x = slide.properties.get(\"openslide.mpp-x\", None)\n",
    "    mpp_y = slide.properties.get(\"openslide.mpp-y\", None)\n",
    "    slide.close()\n",
    "    mpp_x = float(mpp_x) if mpp_x not in (None, \"\") else None\n",
    "    mpp_y = float(mpp_y) if mpp_y not in (None, \"\") else None\n",
    "    return np.asarray(img), scale, mpp_x, mpp_y\n",
    "\n",
    "def tissue_mask(rgb):\n",
    "    hsv = color.rgb2hsv(rgb)\n",
    "    v = hsv[..., 2]\n",
    "    thr = filters.threshold_otsu(v)\n",
    "    mask = v < thr * 0.98\n",
    "    mask = morphology.remove_small_holes(mask, 256)\n",
    "    mask = morphology.remove_small_objects(mask, 256)\n",
    "    return mask\n",
    "\n",
    "def he_nuclei_mask(rgb, tissue):\n",
    "    rgbf = np.clip(rgb/255.0, 0, 1)\n",
    "    hed = color.separate_stains(rgbf, hed_from_rgb)\n",
    "    H = hed[..., 0]\n",
    "    H = exposure.rescale_intensity(\n",
    "        H,\n",
    "        in_range=(np.percentile(H[tissue], 2), np.percentile(H[tissue], 98))\n",
    "    )\n",
    "    thr = filters.threshold_otsu(H[tissue])\n",
    "    nuc = np.zeros_like(H, dtype=bool)\n",
    "    nuc[tissue] = H[tissue] > thr\n",
    "    nuc = morphology.remove_small_objects(nuc, 64)\n",
    "    nuc = morphology.binary_opening(nuc, morphology.disk(2))\n",
    "    return nuc, H\n",
    "\n",
    "# ===== 提取特征（手工 + CNN）=====\n",
    "def wsi_features(svs_path):\n",
    "    rgb, scale, mpp_x, mpp_y = read_thumbnail_and_geometry(svs_path)\n",
    "    has_mpp = (mpp_x is not None) and (mpp_y is not None) and (mpp_x > 0) and (mpp_y > 0)\n",
    "    if REQUIRE_MPP and not has_mpp:\n",
    "        return None\n",
    "\n",
    "    mask = tissue_mask(rgb)\n",
    "    if mask.sum() < 5000:\n",
    "        return None\n",
    "    nuc, H = he_nuclei_mask(rgb, mask)\n",
    "\n",
    "    # 手工特征\n",
    "    tissue_px_thumb = int(mask.sum())\n",
    "    tumor_px_thumb  = int(nuc.sum())\n",
    "    tumor_frac = tumor_px_thumb / tissue_px_thumb\n",
    "    h_vals = H[mask]\n",
    "    h_mean, h_std = float(h_vals.mean()), float(h_vals.std())\n",
    "\n",
    "    feats = dict(\n",
    "        tumor_frac=tumor_frac,\n",
    "        h_mean=h_mean, h_std=h_std\n",
    "    )\n",
    "\n",
    "    # ===== CNN 特征提取 =====\n",
    "    ys, xs = np.where(nuc)\n",
    "    if len(xs) > 0 and len(ys) > 0:\n",
    "        xmin, xmax = xs.min(), xs.max()\n",
    "        ymin, ymax = ys.min(), ys.max()\n",
    "        crop = rgb[ymin:ymax, xmin:xmax]\n",
    "        cnn_feat = extract_cnn_feature(crop)\n",
    "    else:\n",
    "        cnn_feat = np.zeros(512)  # 没检测到肿瘤 → 空特征\n",
    "\n",
    "    return feats, cnn_feat\n",
    "\n",
    "def collect_rows(root):\n",
    "    rows = []\n",
    "    for stage in [1,2,3,4]:\n",
    "        for split in [\"train\",\"test\"]:\n",
    "            d = Path(root) / f\"stage {stage} {split}\"\n",
    "            if not d.exists():\n",
    "                continue\n",
    "            label = stage - 1\n",
    "            for p in list(d.glob(\"*.svs\")) + list(d.glob(\"*.tif\")):\n",
    "                res = wsi_features(str(p))\n",
    "                if res is None:\n",
    "                    continue\n",
    "                feats, cnn_feat = res\n",
    "                row = dict(path=str(p), label=label, split=split)\n",
    "                row.update(feats)\n",
    "                # CNN 特征展开为单独列\n",
    "                for i,v in enumerate(cnn_feat):\n",
    "                    row[f\"cnn_{i}\"] = v\n",
    "                rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ===== 主程序 =====\n",
    "if __name__ == \"__main__\":\n",
    "    df = collect_rows(ROOT)\n",
    "    print(\"Feature rows:\", df.shape)\n",
    "    df.to_csv(\"wsi_stage_features_cnn.csv\", index=False)\n",
    "\n",
    "    train_df = df[df.split==\"train\"]\n",
    "    test_df  = df[df.split==\"test\"]\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c.startswith(\"cnn_\")] + [\"tumor_frac\",\"h_mean\",\"h_std\"]\n",
    "\n",
    "    Xtr, ytr = train_df[feature_cols].values, train_df[\"label\"].values\n",
    "    Xte, yte = test_df[feature_cols].values, test_df[\"label\"].values\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=400, random_state=0, n_jobs=-1, class_weight=\"balanced\")\n",
    "    clf.fit(Xtr, ytr)\n",
    "    ypr = clf.predict(Xte)\n",
    "\n",
    "    print(\"\\nConfusion matrix:\\n\", confusion_matrix(yte, ypr))\n",
    "    print(\"\\nReport:\\n\", classification_report(yte, ypr, digits=4))\n"
   ],
   "id": "b791f71eaab61e2d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature rows: (133, 518)\n",
      "\n",
      "Confusion matrix:\n",
      " [[1 6 0 0]\n",
      " [1 7 2 0]\n",
      " [0 6 1 0]\n",
      " [1 1 0 0]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3333    0.1429    0.2000         7\n",
      "           1     0.3500    0.7000    0.4667        10\n",
      "           2     0.3333    0.1429    0.2000         7\n",
      "           3     0.0000    0.0000    0.0000         2\n",
      "\n",
      "    accuracy                         0.3462        26\n",
      "   macro avg     0.2542    0.2464    0.2167        26\n",
      "weighted avg     0.3141    0.3462    0.2872        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T03:02:39.454165Z",
     "start_time": "2025-09-17T02:54:56.498293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openslide\n",
    "from skimage import color, filters, morphology, measure, exposure, transform\n",
    "from skimage.color import hed_from_rgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ===== 根目录 =====\n",
    "ROOT = r\"C:\\Users\\mxjli\\Desktop\\image\"\n",
    "REQUIRE_MPP = True\n",
    "\n",
    "# ===== CNN 特征提取器 =====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = nn.Identity()  # 去掉最后分类层\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n",
    "\n",
    "# 图像预处理\n",
    "transform_cnn = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((224,224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def extract_cnn_feature(rgb_crop):\n",
    "    \"\"\"输入RGB图像 -> 提取CNN特征\"\"\"\n",
    "    x = transform_cnn(rgb_crop).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        feat = resnet(x).cpu().numpy().flatten()\n",
    "    return feat\n",
    "\n",
    "# ===== 读取与分割 =====\n",
    "def read_thumbnail_and_geometry(svs_path, min_dim=3000):\n",
    "    slide = openslide.OpenSlide(svs_path)\n",
    "    W0, H0 = slide.dimensions\n",
    "    scale = max(W0, H0) / float(min_dim)\n",
    "    new_w, new_h = int(W0/scale), int(H0/scale)\n",
    "    img = slide.get_thumbnail((new_w, new_h))\n",
    "    mpp_x = slide.properties.get(\"openslide.mpp-x\", None)\n",
    "    mpp_y = slide.properties.get(\"openslide.mpp-y\", None)\n",
    "    slide.close()\n",
    "    mpp_x = float(mpp_x) if mpp_x not in (None, \"\") else None\n",
    "    mpp_y = float(mpp_y) if mpp_y not in (None, \"\") else None\n",
    "    return np.asarray(img), scale, mpp_x, mpp_y\n",
    "\n",
    "def tissue_mask(rgb):\n",
    "    hsv = color.rgb2hsv(rgb)\n",
    "    v = hsv[..., 2]\n",
    "    thr = filters.threshold_otsu(v)\n",
    "    mask = v < thr * 0.98\n",
    "    mask = morphology.remove_small_holes(mask, 256)\n",
    "    mask = morphology.remove_small_objects(mask, 256)\n",
    "    return mask\n",
    "\n",
    "def he_nuclei_mask(rgb, tissue):\n",
    "    rgbf = np.clip(rgb/255.0, 0, 1)\n",
    "    hed = color.separate_stains(rgbf, hed_from_rgb)\n",
    "    H = hed[..., 0]\n",
    "    H = exposure.rescale_intensity(\n",
    "        H,\n",
    "        in_range=(np.percentile(H[tissue], 2), np.percentile(H[tissue], 98))\n",
    "    )\n",
    "    thr = filters.threshold_otsu(H[tissue])\n",
    "    nuc = np.zeros_like(H, dtype=bool)\n",
    "    nuc[tissue] = H[tissue] > thr\n",
    "    nuc = morphology.remove_small_objects(nuc, 64)\n",
    "    nuc = morphology.binary_opening(nuc, morphology.disk(2))\n",
    "    return nuc, H\n",
    "\n",
    "# ===== 提取特征（手工 + CNN）=====\n",
    "def wsi_features(svs_path):\n",
    "    rgb, scale, mpp_x, mpp_y = read_thumbnail_and_geometry(svs_path)\n",
    "    has_mpp = (mpp_x is not None) and (mpp_y is not None) and (mpp_x > 0) and (mpp_y > 0)\n",
    "    if REQUIRE_MPP and not has_mpp:\n",
    "        return None\n",
    "\n",
    "    mask = tissue_mask(rgb)\n",
    "    if mask.sum() < 5000:\n",
    "        return None\n",
    "    nuc, H = he_nuclei_mask(rgb, mask)\n",
    "\n",
    "    # 手工特征\n",
    "    tissue_px_thumb = int(mask.sum())\n",
    "    tumor_px_thumb  = int(nuc.sum())\n",
    "    tumor_frac = tumor_px_thumb / tissue_px_thumb\n",
    "    h_vals = H[mask]\n",
    "    h_mean, h_std = float(h_vals.mean()), float(h_vals.std())\n",
    "\n",
    "    feats = dict(\n",
    "        tumor_frac=tumor_frac,\n",
    "        h_mean=h_mean, h_std=h_std\n",
    "    )\n",
    "\n",
    "    # CNN 特征（肿瘤外接框裁剪）\n",
    "    ys, xs = np.where(nuc)\n",
    "    if len(xs) > 0 and len(ys) > 0:\n",
    "        xmin, xmax = xs.min(), xs.max()\n",
    "        ymin, ymax = ys.min(), ys.max()\n",
    "        crop = rgb[ymin:ymax, xmin:xmax]\n",
    "        cnn_feat = extract_cnn_feature(crop)\n",
    "    else:\n",
    "        cnn_feat = np.zeros(512, dtype=np.float32)  # 兜底\n",
    "\n",
    "    return feats, cnn_feat\n",
    "\n",
    "def collect_rows(root):\n",
    "    rows = []\n",
    "    for stage in [1,2,3,4]:\n",
    "        for split in [\"train\",\"test\"]:\n",
    "            d = Path(root) / f\"stage {stage} {split}\"\n",
    "            if not d.exists():\n",
    "                continue\n",
    "\n",
    "            # === 三分类映射：1->0, 2/3->1, 4->2 ===\n",
    "            if stage == 1:\n",
    "                label = 0\n",
    "            elif stage in (2, 3):\n",
    "                label = 1\n",
    "            else:  # stage == 4\n",
    "                label = 2\n",
    "\n",
    "            for p in list(d.glob(\"*.svs\")) + list(d.glob(\"*.tif\")):\n",
    "                res = wsi_features(str(p))\n",
    "                if res is None:\n",
    "                    continue\n",
    "                feats, cnn_feat = res\n",
    "                row = dict(path=str(p), label=label, split=split)\n",
    "                row.update(feats)\n",
    "                for i, v in enumerate(cnn_feat):\n",
    "                    row[f\"cnn_{i}\"] = v\n",
    "                rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ===== 主程序 =====\n",
    "if __name__ == \"__main__\":\n",
    "    df = collect_rows(ROOT)\n",
    "    print(\"Feature rows:\", df.shape)\n",
    "    print(\"Class distribution (0=stage1, 1=stage2&3, 2=stage4):\\n\",\n",
    "          df[\"label\"].value_counts().sort_index())\n",
    "    df.to_csv(\"wsi_stage_features_cnn_3class.csv\", index=False)\n",
    "\n",
    "    train_df = df[df.split==\"train\"]\n",
    "    test_df  = df[df.split==\"test\"]\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c.startswith(\"cnn_\")] + [\"tumor_frac\",\"h_mean\",\"h_std\"]\n",
    "\n",
    "    Xtr, ytr = train_df[feature_cols].values, train_df[\"label\"].values\n",
    "    Xte, yte = test_df[feature_cols].values, test_df[\"label\"].values\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=400, random_state=0, n_jobs=-1, class_weight=\"balanced\"\n",
    "    )\n",
    "    clf.fit(Xtr, ytr)\n",
    "    ypr = clf.predict(Xte)\n",
    "\n",
    "    print(\"\\nConfusion matrix:\\n\", confusion_matrix(yte, ypr, labels=[0,1,2]))\n",
    "    print(\"\\nReport:\\n\", classification_report(\n",
    "        yte, ypr, labels=[0,1,2],\n",
    "        target_names=[\"stage1\",\"stage2&3\",\"stage4\"], digits=4))\n"
   ],
   "id": "954dd7b0d83f6a35",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature rows: (133, 518)\n",
      "Class distribution (0=stage1, 1=stage2&3, 2=stage4):\n",
      " label\n",
      "0    35\n",
      "1    89\n",
      "2     9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 0  7  0]\n",
      " [ 0 17  0]\n",
      " [ 0  2  0]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      stage1     0.0000    0.0000    0.0000         7\n",
      "    stage2&3     0.6538    1.0000    0.7907        17\n",
      "      stage4     0.0000    0.0000    0.0000         2\n",
      "\n",
      "    accuracy                         0.6538        26\n",
      "   macro avg     0.2179    0.3333    0.2636        26\n",
      "weighted avg     0.4275    0.6538    0.5170        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T03:30:20.429599Z",
     "start_time": "2025-09-17T03:22:43.990139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openslide\n",
    "from skimage import color, filters, morphology, measure, exposure\n",
    "from skimage.color import hed_from_rgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ===== 根目录 =====\n",
    "ROOT = r\"C:\\Users\\mxjli\\Desktop\\image\"\n",
    "REQUIRE_MPP = True\n",
    "\n",
    "# ===== CNN 特征提取器 =====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = nn.Identity()  # 去掉最后分类层\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n",
    "\n",
    "# 预处理（输入将是 PIL）\n",
    "transform_cnn = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def extract_cnn_feature(img):\n",
    "    \"\"\"img 可以是 PIL / numpy.ndarray / torch.Tensor；统一转 PIL→RGB 再变换\"\"\"\n",
    "    if isinstance(img, np.ndarray):\n",
    "        img = Image.fromarray(img)\n",
    "    elif isinstance(img, torch.Tensor):\n",
    "        img = T.ToPILImage()(img)\n",
    "    if getattr(img, \"mode\", None) != \"RGB\":\n",
    "        img = img.convert(\"RGB\")\n",
    "    x = transform_cnn(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        feat = resnet(x).cpu().numpy().flatten()\n",
    "    return feat\n",
    "\n",
    "def extract_tumor_region_with_padding(pil_img, tumor_mask, padding_ratio=0.12):\n",
    "    \"\"\"从 tumor_mask 中裁剪病灶区域，加 padding，返回 224x224 的 PIL\"\"\"\n",
    "    ys, xs = np.where(tumor_mask)\n",
    "    if len(xs) == 0 or len(ys) == 0:\n",
    "        return pil_img.resize((224, 224))\n",
    "    xmin, xmax = xs.min(), xs.max()\n",
    "    ymin, ymax = ys.min(), ys.max()\n",
    "    h, w = (ymax - ymin), (xmax - xmin)\n",
    "    pad_x = int(padding_ratio * w)\n",
    "    pad_y = int(padding_ratio * h)\n",
    "    xmin = max(xmin - pad_x, 0)\n",
    "    xmax = min(xmax + pad_x, pil_img.width)\n",
    "    ymin = max(ymin - pad_y, 0)\n",
    "    ymax = min(ymax + pad_y, pil_img.height)\n",
    "    return pil_img.crop((xmin, ymin, xmax, ymax)).resize((224, 224))\n",
    "\n",
    "# ===== 读取与分割 =====\n",
    "def read_thumbnail_and_geometry(svs_path, min_dim=3000):\n",
    "    slide = openslide.OpenSlide(svs_path)\n",
    "    W0, H0 = slide.dimensions\n",
    "    scale = max(W0, H0) / float(min_dim)\n",
    "    new_w, new_h = int(W0/scale), int(H0/scale)\n",
    "    img = slide.get_thumbnail((new_w, new_h))\n",
    "    mpp_x = slide.properties.get(\"openslide.mpp-x\", None)\n",
    "    mpp_y = slide.properties.get(\"openslide.mpp-y\", None)\n",
    "    slide.close()\n",
    "    mpp_x = float(mpp_x) if mpp_x not in (None, \"\") else None\n",
    "    mpp_y = float(mpp_y) if mpp_y not in (None, \"\") else None\n",
    "    return np.asarray(img), scale, mpp_x, mpp_y\n",
    "\n",
    "def tissue_mask(rgb):\n",
    "    hsv = color.rgb2hsv(rgb)\n",
    "    v = hsv[..., 2]\n",
    "    thr = filters.threshold_otsu(v)\n",
    "    mask = v < thr * 0.98\n",
    "    mask = morphology.remove_small_holes(mask, 256)\n",
    "    mask = morphology.remove_small_objects(mask, 256)\n",
    "    return mask\n",
    "\n",
    "def he_nuclei_mask(rgb, tissue):\n",
    "    rgbf = np.clip(rgb/255.0, 0, 1)\n",
    "    hed = color.separate_stains(rgbf, hed_from_rgb)\n",
    "    H = hed[..., 0]\n",
    "    H = exposure.rescale_intensity(\n",
    "        H, in_range=(np.percentile(H[tissue], 2), np.percentile(H[tissue], 98))\n",
    "    )\n",
    "    thr = filters.threshold_otsu(H[tissue])\n",
    "    nuc = np.zeros_like(H, dtype=bool)\n",
    "    nuc[tissue] = H[tissue] > thr\n",
    "    nuc = morphology.remove_small_objects(nuc, 64)\n",
    "    nuc = morphology.binary_opening(nuc, morphology.disk(2))\n",
    "    return nuc, H\n",
    "\n",
    "# ===== 提取特征（手工 + CNN）=====\n",
    "def wsi_features(svs_path):\n",
    "    rgb, scale, mpp_x, mpp_y = read_thumbnail_and_geometry(svs_path)\n",
    "    has_mpp = (mpp_x is not None) and (mpp_y is not None) and (mpp_x > 0) and (mpp_y > 0)\n",
    "    if REQUIRE_MPP and not has_mpp:\n",
    "        return None\n",
    "\n",
    "    mask = tissue_mask(rgb)\n",
    "    if mask.sum() < 5000:\n",
    "        return None\n",
    "    nuc, H = he_nuclei_mask(rgb, mask)\n",
    "\n",
    "    # 手工特征\n",
    "    tissue_px_thumb = int(mask.sum())\n",
    "    tumor_px_thumb  = int(nuc.sum())\n",
    "    tumor_frac = tumor_px_thumb / max(tissue_px_thumb, 1)\n",
    "    h_vals = H[mask]\n",
    "    h_mean, h_std = float(h_vals.mean()), float(h_vals.std())\n",
    "    feats = dict(tumor_frac=tumor_frac, h_mean=h_mean, h_std=h_std)\n",
    "\n",
    "    # CNN 特征：最小外接框 + padding 裁剪\n",
    "    pil_img = Image.fromarray(rgb)\n",
    "    tumor_crop = extract_tumor_region_with_padding(pil_img, tumor_mask=nuc, padding_ratio=0.12)\n",
    "    cnn_feat = extract_cnn_feature(tumor_crop)\n",
    "\n",
    "    return feats, cnn_feat\n",
    "\n",
    "def collect_rows(root):\n",
    "    rows = []\n",
    "    for stage in [1,2,3,4]:\n",
    "        for split in [\"train\",\"test\"]:\n",
    "            d = Path(root) / f\"stage {stage} {split}\"\n",
    "            if not d.exists():\n",
    "                continue\n",
    "            # 三分类映射：1->0, 2/3->1, 4->2\n",
    "            if stage == 1:\n",
    "                label = 0\n",
    "            elif stage in (2, 3):\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 2\n",
    "            for p in list(d.glob(\"*.svs\")) + list(d.glob(\"*.tif\")):\n",
    "                res = wsi_features(str(p))\n",
    "                if res is None:\n",
    "                    continue\n",
    "                feats, cnn_feat = res\n",
    "                row = dict(path=str(p), label=label, split=split)\n",
    "                row.update(feats)\n",
    "                for i, v in enumerate(cnn_feat):\n",
    "                    row[f\"cnn_{i}\"] = v\n",
    "                rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ===== 主程序 =====\n",
    "if __name__ == \"__main__\":\n",
    "    df = collect_rows(ROOT)\n",
    "    print(\"Feature rows:\", df.shape)\n",
    "    print(\"Class distribution (0=stage1, 1=stage2&3, 2=stage4):\\n\",\n",
    "          df[\"label\"].value_counts().sort_index())\n",
    "    df.to_csv(\"wsi_stage_features_cnn_3class_padding_fixed.csv\", index=False)\n",
    "\n",
    "    train_df = df[df.split==\"train\"]\n",
    "    test_df  = df[df.split==\"test\"]\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c.startswith(\"cnn_\")] + [\"tumor_frac\",\"h_mean\",\"h_std\"]\n",
    "    Xtr, ytr = train_df[feature_cols].values, train_df[\"label\"].values\n",
    "    Xte, yte = test_df[feature_cols].values, test_df[\"label\"].values\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=400, random_state=0, n_jobs=-1, class_weight=\"balanced\")\n",
    "    clf.fit(Xtr, ytr)\n",
    "    ypr = clf.predict(Xte)\n",
    "\n",
    "    print(\"\\nConfusion matrix:\\n\", confusion_matrix(yte, ypr, labels=[0,1,2]))\n",
    "    print(\"\\nReport:\\n\", classification_report(\n",
    "        yte, ypr, labels=[0,1,2],\n",
    "        target_names=[\"stage1\",\"stage2&3\",\"stage4\"], digits=4))\n"
   ],
   "id": "6a4b72cf264dca5c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature rows: (133, 518)\n",
      "Class distribution (0=stage1, 1=stage2&3, 2=stage4):\n",
      " label\n",
      "0    35\n",
      "1    89\n",
      "2     9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 1  6  0]\n",
      " [ 0 17  0]\n",
      " [ 0  2  0]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      stage1     1.0000    0.1429    0.2500         7\n",
      "    stage2&3     0.6800    1.0000    0.8095        17\n",
      "      stage4     0.0000    0.0000    0.0000         2\n",
      "\n",
      "    accuracy                         0.6923        26\n",
      "   macro avg     0.5600    0.3810    0.3532        26\n",
      "weighted avg     0.7138    0.6923    0.5966        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T04:55:54.839780Z",
     "start_time": "2025-09-17T04:54:44.459939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openslide\n",
    "from skimage import color, filters, morphology, measure, exposure\n",
    "from skimage.color import hed_from_rgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ===== 根目录 =====\n",
    "ROOT = r\"C:\\Users\\mxjli\\Desktop\\image\"\n",
    "REQUIRE_MPP = True\n",
    "\n",
    "# ===== CNN 特征提取器 =====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = nn.Identity()\n",
    "resnet = resnet.to(device).eval()\n",
    "\n",
    "# 预处理（输入将是 PIL）\n",
    "transform_cnn = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def extract_cnn_feature(img):\n",
    "    \"\"\"img: PIL / ndarray / Tensor -> 512d\"\"\"\n",
    "    if isinstance(img, np.ndarray):\n",
    "        img = Image.fromarray(img)\n",
    "    elif isinstance(img, torch.Tensor):\n",
    "        img = T.ToPILImage()(img)\n",
    "    if getattr(img, \"mode\", None) != \"RGB\":\n",
    "        img = img.convert(\"RGB\")\n",
    "    x = transform_cnn(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        feat = resnet(x).cpu().numpy().flatten()\n",
    "    return feat  # [512]\n",
    "\n",
    "# ---------- Top-K 病灶裁剪 + 池化 ----------\n",
    "def extract_topk_crops(pil_img, nuc_mask, k=3, pad_ratio=0.12, out_size=224):\n",
    "    lab = measure.label(nuc_mask)\n",
    "    props = sorted(measure.regionprops(lab), key=lambda p: p.area, reverse=True)\n",
    "    W, H = pil_img.width, pil_img.height\n",
    "    crops = []\n",
    "    for p in props[:k]:\n",
    "        ymin, xmin, ymax, xmax = p.bbox  # (min_row, min_col, max_row, max_col)\n",
    "        h, w = ymax - ymin, xmax - xmin\n",
    "        if h <= 0 or w <= 0:\n",
    "            continue\n",
    "        px = int(pad_ratio * w); py = int(pad_ratio * h)\n",
    "        xmin = max(xmin - px, 0); xmax = min(xmax + px, W)\n",
    "        ymin = max(ymin - py, 0); ymax = min(ymax + py, H)\n",
    "        crops.append(pil_img.crop((xmin, ymin, xmax, ymax)).resize((out_size, out_size)))\n",
    "    if not crops:  # 兜底：没有病灶就整图\n",
    "        crops = [pil_img.resize((out_size, out_size))]\n",
    "    return crops\n",
    "\n",
    "def cnn_features_pooled(crops):\n",
    "    \"\"\"多块裁剪 -> [1024] = mean(512) ⊕ max(512)\"\"\"\n",
    "    feats = [extract_cnn_feature(im) for im in crops]  # [k,512]\n",
    "    F = np.stack(feats, 0)\n",
    "    return np.concatenate([F.mean(0), F.max(0)], 0)  # [1024]\n",
    "# ------------------------------------------\n",
    "\n",
    "def read_thumbnail_and_geometry(svs_path, min_dim=3000):\n",
    "    slide = openslide.OpenSlide(svs_path)\n",
    "    W0, H0 = slide.dimensions\n",
    "    scale = max(W0, H0) / float(min_dim)\n",
    "    new_w, new_h = int(W0/scale), int(H0/scale)\n",
    "    img = slide.get_thumbnail((new_w, new_h))\n",
    "    mpp_x = slide.properties.get(\"openslide.mpp-x\", None)\n",
    "    mpp_y = slide.properties.get(\"openslide.mpp-y\", None)\n",
    "    slide.close()\n",
    "    mpp_x = float(mpp_x) if mpp_x not in (None, \"\") else None\n",
    "    mpp_y = float(mpp_y) if mpp_y not in (None, \"\") else None\n",
    "    return np.asarray(img), scale, mpp_x, mpp_y\n",
    "\n",
    "def tissue_mask(rgb):\n",
    "    hsv = color.rgb2hsv(rgb); v = hsv[..., 2]\n",
    "    thr = filters.threshold_otsu(v)\n",
    "    mask = v < thr * 0.98\n",
    "    mask = morphology.remove_small_holes(mask, 256)\n",
    "    mask = morphology.remove_small_objects(mask, 256)\n",
    "    return mask\n",
    "\n",
    "def he_nuclei_mask(rgb, tissue):\n",
    "    rgbf = np.clip(rgb/255.0, 0, 1)\n",
    "    hed = color.separate_stains(rgbf, hed_from_rgb)\n",
    "    H = hed[..., 0]\n",
    "    H = exposure.rescale_intensity(\n",
    "        H, in_range=(np.percentile(H[tissue], 2), np.percentile(H[tissue], 98)))\n",
    "    thr = filters.threshold_otsu(H[tissue])\n",
    "    nuc = np.zeros_like(H, dtype=bool)\n",
    "    nuc[tissue] = H[tissue] > thr\n",
    "    nuc = morphology.remove_small_objects(nuc, 64)\n",
    "    nuc = morphology.binary_opening(nuc, morphology.disk(2))\n",
    "    return nuc, H\n",
    "\n",
    "def wsi_features(svs_path):\n",
    "    rgb, scale, mpp_x, mpp_y = read_thumbnail_and_geometry(svs_path)\n",
    "    has_mpp = (mpp_x is not None) and (mpp_y is not None) and (mpp_x > 0) and (mpp_y > 0)\n",
    "    if REQUIRE_MPP and not has_mpp:\n",
    "        return None\n",
    "\n",
    "    mask = tissue_mask(rgb)\n",
    "    if mask.sum() < 5000:\n",
    "        return None\n",
    "    nuc, H = he_nuclei_mask(rgb, mask)\n",
    "\n",
    "    # —— 手工统计\n",
    "    tissue_px_thumb = int(mask.sum())\n",
    "    tumor_px_thumb  = int(nuc.sum())\n",
    "    lab = measure.label(nuc)\n",
    "    props = measure.regionprops(lab)\n",
    "    areas  = np.array([p.area for p in props], dtype=np.float32) if props else np.array([])\n",
    "    perims = np.array([p.perimeter for p in props], dtype=np.float32) if props else np.array([])\n",
    "    cc_count = len(props)\n",
    "    largest_cc_px = int(areas.max()) if cc_count else 0\n",
    "\n",
    "    tumor_frac = tumor_px_thumb / max(tissue_px_thumb, 1)\n",
    "    largest_cc_frac = largest_cc_px / max(tissue_px_thumb, 1)\n",
    "    small_thresh = 0.001 * tissue_px_thumb\n",
    "    cc_small = int((areas < small_thresh).sum()) if cc_count else 0\n",
    "    cc_small_frac = cc_small / max(cc_count, 1)\n",
    "    frag_ratio = float(perims.sum() / (areas.sum() + 1e-6)) if cc_count else 0.0\n",
    "\n",
    "    feats = dict(\n",
    "        tumor_frac=tumor_frac,\n",
    "        largest_cc_frac=largest_cc_frac,\n",
    "        cc_count=cc_count,\n",
    "        cc_small_frac=cc_small_frac,\n",
    "        frag_ratio=frag_ratio,\n",
    "    )\n",
    "\n",
    "    # —— CNN：Top-K 裁剪 + 池化（K=3）\n",
    "    pil_img = Image.fromarray(rgb)\n",
    "    crops = extract_topk_crops(pil_img, nuc_mask=nuc, k=3, pad_ratio=0.12)\n",
    "    cnn_feat = cnn_features_pooled(crops)  # [1024]\n",
    "\n",
    "    return feats, cnn_feat\n",
    "\n",
    "def collect_rows(root):\n",
    "    rows = []\n",
    "    for stage in [1,2,3,4]:\n",
    "        for split in [\"train\",\"test\"]:\n",
    "            d = Path(root) / f\"stage {stage} {split}\"\n",
    "            if not d.exists():\n",
    "                continue\n",
    "            # 三分类映射：1->0, 2/3->1, 4->2\n",
    "            if stage == 1: label = 0\n",
    "            elif stage in (2,3): label = 1\n",
    "            else: label = 2\n",
    "            for p in list(d.glob(\"*.svs\")) + list(d.glob(\"*.tif\")):\n",
    "                res = wsi_features(str(p))\n",
    "                if res is None: continue\n",
    "                feats, cnn_feat = res\n",
    "                row = dict(path=str(p), label=label, split=split); row.update(feats)\n",
    "                for i, v in enumerate(cnn_feat):\n",
    "                    row[f\"cnn_{i}\"] = v\n",
    "                rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ===== 主程序 =====\n",
    "if __name__ == \"__main__\":\n",
    "    df = collect_rows(ROOT)\n",
    "    print(\"Feature rows:\", df.shape)\n",
    "    print(\"Class distribution (0=stage1, 1=stage2&3, 2=stage4):\\n\",\n",
    "          df[\"label\"].value_counts().sort_index())\n",
    "    df.to_csv(\"wsi_stage_features_topk.csv\", index=False)\n",
    "\n",
    "    train_df = df[df.split==\"train\"].copy()\n",
    "    test_df  = df[df.split==\"test\"].copy()\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c.startswith(\"cnn_\")] + [\n",
    "        \"tumor_frac\",\"largest_cc_frac\",\"cc_count\",\"cc_small_frac\",\"frag_ratio\"\n",
    "    ]\n",
    "\n",
    "    Xtr = train_df[feature_cols].values\n",
    "    ytr = train_df[\"label\"].values\n",
    "    Xte = test_df[feature_cols].values\n",
    "    yte = test_df[\"label\"].values\n",
    "\n",
    "    # ===== 更强的不平衡处理：在 balanced 基础上额外放大 stage1/4 =====\n",
    "    cnt = Counter(ytr)\n",
    "    base_bal = {k: len(ytr) / (3.0 * cnt[k]) for k in cnt}  # balanced\n",
    "    boost = {0: 1.6, 1: 1.0, 2: 1.8}                        # 可调：stage1/4 更重\n",
    "    weights = np.array([base_bal[c] * boost.get(c,1.0) for c in ytr], dtype=np.float32)\n",
    "\n",
    "    # === 模型：HGB（更稳），也可换回 RF（把下面两行注释解除）\n",
    "    clf = HistGradientBoostingClassifier(\n",
    "        max_depth=6, learning_rate=0.06, max_iter=600,\n",
    "        l2_regularization=1.0, min_samples_leaf=20\n",
    "    )\n",
    "    clf.fit(Xtr, ytr, sample_weight=weights)\n",
    "\n",
    "    # rf = RandomForestClassifier(n_estimators=800, random_state=0, n_jobs=-1, class_weight={0:base_bal[0]*boost[0],1:base_bal[1],2:base_bal.get(2,1.0)*boost[2]})\n",
    "    # rf.fit(Xtr, ytr); clf = rf\n",
    "\n",
    "    # ===== 预测时小幅偏置：提高 stage1/4 的召回 =====\n",
    "    proba = clf.predict_proba(Xte)\n",
    "    proba[:, 0] *= 1.20   # stage1 boost  1.10~1.40 可调\n",
    "    proba[:, 2] *= 1.25   # stage4 boost  1.10~1.50 可调\n",
    "    ypr = proba.argmax(axis=1)\n",
    "\n",
    "    print(\"\\nConfusion matrix:\\n\", confusion_matrix(yte, ypr, labels=[0,1,2]))\n",
    "    print(\"\\nReport:\\n\", classification_report(\n",
    "        yte, ypr, labels=[0,1,2],\n",
    "        target_names=[\"stage1\",\"stage2&3\",\"stage4\"], digits=4))\n"
   ],
   "id": "dbc1fd0ef8eaf72e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 177\u001B[39m\n\u001B[32m    175\u001B[39m \u001B[38;5;66;03m# ===== 主程序 =====\u001B[39;00m\n\u001B[32m    176\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[34m__name__\u001B[39m == \u001B[33m\"\u001B[39m\u001B[33m__main__\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m177\u001B[39m     df = \u001B[43mcollect_rows\u001B[49m\u001B[43m(\u001B[49m\u001B[43mROOT\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    178\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mFeature rows:\u001B[39m\u001B[33m\"\u001B[39m, df.shape)\n\u001B[32m    179\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mClass distribution (0=stage1, 1=stage2&3, 2=stage4):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m,\n\u001B[32m    180\u001B[39m           df[\u001B[33m\"\u001B[39m\u001B[33mlabel\u001B[39m\u001B[33m\"\u001B[39m].value_counts().sort_index())\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 166\u001B[39m, in \u001B[36mcollect_rows\u001B[39m\u001B[34m(root)\u001B[39m\n\u001B[32m    164\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m: label = \u001B[32m2\u001B[39m\n\u001B[32m    165\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(d.glob(\u001B[33m\"\u001B[39m\u001B[33m*.svs\u001B[39m\u001B[33m\"\u001B[39m)) + \u001B[38;5;28mlist\u001B[39m(d.glob(\u001B[33m\"\u001B[39m\u001B[33m*.tif\u001B[39m\u001B[33m\"\u001B[39m)):\n\u001B[32m--> \u001B[39m\u001B[32m166\u001B[39m     res = \u001B[43mwsi_features\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mp\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    167\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m: \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[32m    168\u001B[39m     feats, cnn_feat = res\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 127\u001B[39m, in \u001B[36mwsi_features\u001B[39m\u001B[34m(svs_path)\u001B[39m\n\u001B[32m    125\u001B[39m lab = measure.label(nuc)\n\u001B[32m    126\u001B[39m props = measure.regionprops(lab)\n\u001B[32m--> \u001B[39m\u001B[32m127\u001B[39m areas  = np.array([\u001B[43mp\u001B[49m\u001B[43m.\u001B[49m\u001B[43marea\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m props], dtype=np.float32) \u001B[38;5;28;01mif\u001B[39;00m props \u001B[38;5;28;01melse\u001B[39;00m np.array([])\n\u001B[32m    128\u001B[39m perims = np.array([p.perimeter \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m props], dtype=np.float32) \u001B[38;5;28;01mif\u001B[39;00m props \u001B[38;5;28;01melse\u001B[39;00m np.array([])\n\u001B[32m    129\u001B[39m cc_count = \u001B[38;5;28mlen\u001B[39m(props)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\skimage\\measure\\_regionprops.py:243\u001B[39m, in \u001B[36m_cached.<locals>.wrapper\u001B[39m\u001B[34m(obj)\u001B[39m\n\u001B[32m    240\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m f(obj)\n\u001B[32m    242\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m prop \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m cache:\n\u001B[32m--> \u001B[39m\u001B[32m243\u001B[39m     cache[prop] = \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    245\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m cache[prop]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\skimage\\measure\\_regionprops.py:435\u001B[39m, in \u001B[36mRegionProperties.area\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    432\u001B[39m \u001B[38;5;129m@property\u001B[39m\n\u001B[32m    433\u001B[39m \u001B[38;5;129m@_cached\u001B[39m\n\u001B[32m    434\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34marea\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m435\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m * \u001B[38;5;28mself\u001B[39m._pixel_area\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:2333\u001B[39m, in \u001B[36m_sum_dispatcher\u001B[39m\u001B[34m(a, axis, dtype, out, keepdims, initial, where)\u001B[39m\n\u001B[32m   2327\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mPassing `min` or `max` keyword argument when \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2328\u001B[39m                          \u001B[33m\"\u001B[39m\u001B[33m`a_min` and `a_max` are provided is forbidden.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   2330\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m _wrapfunc(a, \u001B[33m'\u001B[39m\u001B[33mclip\u001B[39m\u001B[33m'\u001B[39m, a_min, a_max, out=out, **kwargs)\n\u001B[32m-> \u001B[39m\u001B[32m2333\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_sum_dispatcher\u001B[39m(a, axis=\u001B[38;5;28;01mNone\u001B[39;00m, dtype=\u001B[38;5;28;01mNone\u001B[39;00m, out=\u001B[38;5;28;01mNone\u001B[39;00m, keepdims=\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   2334\u001B[39m                     initial=\u001B[38;5;28;01mNone\u001B[39;00m, where=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m   2335\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m (a, out)\n\u001B[32m   2338\u001B[39m \u001B[38;5;129m@array_function_dispatch\u001B[39m(_sum_dispatcher)\n\u001B[32m   2339\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34msum\u001B[39m(a, axis=\u001B[38;5;28;01mNone\u001B[39;00m, dtype=\u001B[38;5;28;01mNone\u001B[39;00m, out=\u001B[38;5;28;01mNone\u001B[39;00m, keepdims=np._NoValue,\n\u001B[32m   2340\u001B[39m         initial=np._NoValue, where=np._NoValue):\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T05:06:06.846949Z",
     "start_time": "2025-09-17T04:58:08.583563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openslide\n",
    "from skimage import color, filters, morphology, measure, exposure\n",
    "from skimage.color import hed_from_rgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ===== 根目录 =====\n",
    "ROOT = r\"C:\\Users\\mxjli\\Desktop\\image\"\n",
    "REQUIRE_MPP = True\n",
    "\n",
    "# ===== CNN 特征提取器 =====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = nn.Identity()\n",
    "resnet = resnet.to(device).eval()\n",
    "\n",
    "transform_cnn = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def extract_cnn_feature(img):\n",
    "    if isinstance(img, np.ndarray):\n",
    "        img = Image.fromarray(img)\n",
    "    elif isinstance(img, torch.Tensor):\n",
    "        img = T.ToPILImage()(img)\n",
    "    if getattr(img, \"mode\", None) != \"RGB\":\n",
    "        img = img.convert(\"RGB\")\n",
    "    x = transform_cnn(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        feat = resnet(x).cpu().numpy().flatten()\n",
    "    return feat  # [512]\n",
    "\n",
    "# ---------- Top-K 病灶裁剪 + 池化 ----------\n",
    "def extract_topk_crops(pil_img, nuc_mask, k=3, pad_ratio=0.12, out_size=224):\n",
    "    lab = measure.label(nuc_mask)\n",
    "    props = sorted(measure.regionprops(lab), key=lambda p: p.area, reverse=True)\n",
    "    W, H = pil_img.width, pil_img.height\n",
    "    crops = []\n",
    "    for p in props[:k]:\n",
    "        ymin, xmin, ymax, xmax = p.bbox\n",
    "        h, w = ymax - ymin, xmax - xmin\n",
    "        if h <= 0 or w <= 0: continue\n",
    "        px = int(pad_ratio * w); py = int(pad_ratio * h)\n",
    "        xmin = max(xmin - px, 0); xmax = min(xmax + px, W)\n",
    "        ymin = max(ymin - py, 0); ymax = min(ymax + py, H)\n",
    "        crops.append(pil_img.crop((xmin, ymin, xmax, ymax)).resize((out_size, out_size)))\n",
    "    if not crops:\n",
    "        crops = [pil_img.resize((out_size, out_size))]\n",
    "    return crops\n",
    "\n",
    "def cnn_features_pooled(crops):\n",
    "    feats = [extract_cnn_feature(im) for im in crops]  # [k,512]\n",
    "    F = np.stack(feats, 0)\n",
    "    return np.concatenate([F.mean(0), F.max(0)], 0)  # [1024]\n",
    "# ------------------------------------------\n",
    "\n",
    "def read_thumbnail_and_geometry(svs_path, min_dim=3000):\n",
    "    slide = openslide.OpenSlide(svs_path)\n",
    "    W0, H0 = slide.dimensions\n",
    "    scale = max(W0, H0) / float(min_dim)\n",
    "    new_w, new_h = int(W0/scale), int(H0/scale)\n",
    "    img = slide.get_thumbnail((new_w, new_h))\n",
    "    mpp_x = slide.properties.get(\"openslide.mpp-x\", None)\n",
    "    mpp_y = slide.properties.get(\"openslide.mpp-y\", None)\n",
    "    slide.close()\n",
    "    mpp_x = float(mpp_x) if mpp_x not in (None, \"\") else None\n",
    "    mpp_y = float(mpp_y) if mpp_y not in (None, \"\") else None\n",
    "    return np.asarray(img), scale, mpp_x, mpp_y\n",
    "\n",
    "def tissue_mask(rgb):\n",
    "    hsv = color.rgb2hsv(rgb); v = hsv[..., 2]\n",
    "    thr = filters.threshold_otsu(v)\n",
    "    mask = v < thr * 0.98\n",
    "    mask = morphology.remove_small_holes(mask, 256)\n",
    "    mask = morphology.remove_small_objects(mask, 256)\n",
    "    return mask\n",
    "\n",
    "def he_nuclei_mask(rgb, tissue):\n",
    "    rgbf = np.clip(rgb/255.0, 0, 1)\n",
    "    hed = color.separate_stains(rgbf, hed_from_rgb)\n",
    "    H = hed[..., 0]\n",
    "    H = exposure.rescale_intensity(\n",
    "        H, in_range=(np.percentile(H[tissue], 2), np.percentile(H[tissue], 98)))\n",
    "    thr = filters.threshold_otsu(H[tissue])\n",
    "    nuc = np.zeros_like(H, dtype=bool)\n",
    "    nuc[tissue] = H[tissue] > thr\n",
    "    nuc = morphology.remove_small_objects(nuc, 64)\n",
    "    nuc = morphology.binary_opening(nuc, morphology.disk(2))\n",
    "    return nuc, H\n",
    "\n",
    "def wsi_features(svs_path):\n",
    "    rgb, scale, mpp_x, mpp_y = read_thumbnail_and_geometry(svs_path)\n",
    "    has_mpp = (mpp_x is not None) and (mpp_y is not None) and (mpp_x > 0) and (mpp_y > 0)\n",
    "    if REQUIRE_MPP and not has_mpp:\n",
    "        return None\n",
    "    mask = tissue_mask(rgb)\n",
    "    if mask.sum() < 5000:\n",
    "        return None\n",
    "    nuc, H = he_nuclei_mask(rgb, mask)\n",
    "\n",
    "    # —— 手工统计\n",
    "    tissue_px_thumb = int(mask.sum())\n",
    "    tumor_px_thumb  = int(nuc.sum())\n",
    "    lab = measure.label(nuc)\n",
    "    props = measure.regionprops(lab)\n",
    "    areas  = np.array([p.area for p in props], dtype=np.float32) if props else np.array([])\n",
    "    perims = np.array([p.perimeter for p in props], dtype=np.float32) if props else np.array([])\n",
    "    cc_count = len(props)\n",
    "    largest_cc_px = int(areas.max()) if cc_count else 0\n",
    "\n",
    "    tumor_frac = tumor_px_thumb / max(tissue_px_thumb, 1)\n",
    "    largest_cc_frac = largest_cc_px / max(tissue_px_thumb, 1)\n",
    "    small_thresh = 0.001 * tissue_px_thumb\n",
    "    cc_small = int((areas < small_thresh).sum()) if cc_count else 0\n",
    "    cc_small_frac = cc_small / max(cc_count, 1)\n",
    "    frag_ratio = float(perims.sum() / (areas.sum() + 1e-6)) if cc_count else 0.0\n",
    "\n",
    "    feats = dict(\n",
    "        tumor_frac=tumor_frac,\n",
    "        largest_cc_frac=largest_cc_frac,\n",
    "        cc_count=cc_count,\n",
    "        cc_small_frac=cc_small_frac,\n",
    "        frag_ratio=frag_ratio,\n",
    "    )\n",
    "\n",
    "    # —— CNN：Top-K 裁剪 + 池化（K=3）\n",
    "    pil_img = Image.fromarray(rgb)\n",
    "    crops = extract_topk_crops(pil_img, nuc_mask=nuc, k=3, pad_ratio=0.12)\n",
    "    cnn_feat = cnn_features_pooled(crops)  # [1024]\n",
    "\n",
    "    return feats, cnn_feat\n",
    "\n",
    "def collect_rows(root):\n",
    "    rows = []\n",
    "    for stage in [1,2,3,4]:\n",
    "        for split in [\"train\",\"test\"]:\n",
    "            d = Path(root) / f\"stage {stage} {split}\"\n",
    "            if not d.exists(): continue\n",
    "            label = stage - 1        # ★ 变更点：四分类直接用 1→0,2→1,3→2,4→3\n",
    "            for p in list(d.glob(\"*.svs\")) + list(d.glob(\"*.tif\")):\n",
    "                res = wsi_features(str(p))\n",
    "                if res is None: continue\n",
    "                feats, cnn_feat = res\n",
    "                row = dict(path=str(p), label=label, split=split); row.update(feats)\n",
    "                for i, v in enumerate(cnn_feat):\n",
    "                    row[f\"cnn_{i}\"] = v\n",
    "                rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ===== 主程序 =====\n",
    "if __name__ == \"__main__\":\n",
    "    df = collect_rows(ROOT)\n",
    "    print(\"Feature rows:\", df.shape)\n",
    "    print(\"Class distribution (0=stage1, 1=stage2, 2=stage3, 3=stage4):\\n\",   # ★ 变更点\n",
    "          df[\"label\"].value_counts().sort_index())\n",
    "    df.to_csv(\"wsi_stage_features_topk_4class.csv\", index=False)\n",
    "\n",
    "    train_df = df[df.split==\"train\"].copy()\n",
    "    test_df  = df[df.split==\"test\"].copy()\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c.startswith(\"cnn_\")] + [\n",
    "        \"tumor_frac\",\"largest_cc_frac\",\"cc_count\",\"cc_small_frac\",\"frag_ratio\"\n",
    "    ]\n",
    "\n",
    "    Xtr = train_df[feature_cols].values\n",
    "    ytr = train_df[\"label\"].values\n",
    "    Xte = test_df[feature_cols].values\n",
    "    yte = test_df[\"label\"].values\n",
    "\n",
    "    # ===== 类不平衡权重：按 4 类计算 =====\n",
    "    counts = train_df[\"label\"].value_counts()\n",
    "    n_classes = 4                                                          # ★ 变更点\n",
    "    class_weight_map = {c: len(train_df) / (n_classes * counts[c]) for c in counts.index}\n",
    "    # 可选：额外拉高极少类（例如 stage1/4）\n",
    "    for k, mult in {0:1.4, 3:1.5}.items():                                 # ★ 可调\n",
    "        if k in class_weight_map: class_weight_map[k] *= mult\n",
    "    weights = train_df[\"label\"].map(class_weight_map).values\n",
    "\n",
    "    clf = HistGradientBoostingClassifier(\n",
    "        max_depth=6, learning_rate=0.06, max_iter=600,\n",
    "        l2_regularization=1.0, min_samples_leaf=20, random_state=0\n",
    "    )\n",
    "    clf.fit(Xtr, ytr, sample_weight=weights)\n",
    "\n",
    "    # ===== 预测：按 4 类输出；可对两端类小幅 boost =====\n",
    "    proba = clf.predict_proba(Xte)                                        # [N,4]\n",
    "    proba[:, 0] *= 1.10   # stage1 boost（可按需要调整/去掉）\n",
    "    proba[:, 3] *= 1.15   # stage4 boost\n",
    "    proba = proba / np.clip(proba.sum(1, keepdims=True), 1e-12, None)\n",
    "    ypr = proba.argmax(axis=1)\n",
    "\n",
    "    print(\"\\nConfusion matrix:\\n\", confusion_matrix(yte, ypr, labels=[0,1,2,3]))   # ★ 变更点\n",
    "    print(\"\\nReport:\\n\", classification_report(\n",
    "        yte, ypr, labels=[0,1,2,3],                                                # ★ 变更点\n",
    "        target_names=[\"stage1\",\"stage2\",\"stage3\",\"stage4\"], digits=4))\n"
   ],
   "id": "12239d44745e4b0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature rows: (133, 1032)\n",
      "Class distribution (0=stage1, 1=stage2, 2=stage3, 3=stage4):\n",
      " label\n",
      "0    35\n",
      "1    51\n",
      "2    38\n",
      "3     9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Confusion matrix:\n",
      " [[1 4 0 0]\n",
      " [2 2 1 0]\n",
      " [0 2 3 0]\n",
      " [0 1 0 1]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      stage1     0.3333    0.2000    0.2500         5\n",
      "      stage2     0.2222    0.4000    0.2857         5\n",
      "      stage3     0.7500    0.6000    0.6667         5\n",
      "      stage4     1.0000    0.5000    0.6667         2\n",
      "\n",
      "    accuracy                         0.4118        17\n",
      "   macro avg     0.5764    0.4250    0.4673        17\n",
      "weighted avg     0.5016    0.4118    0.4321        17\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T14:21:17.091057Z",
     "start_time": "2025-09-17T14:13:14.931949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openslide\n",
    "from skimage import color, filters, morphology, measure, exposure\n",
    "from skimage.color import hed_from_rgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ===== 根目录 =====\n",
    "ROOT = r\"C:\\Users\\mxjli\\Desktop\\image\"\n",
    "REQUIRE_MPP = True\n",
    "\n",
    "# ===== CNN 特征提取器 =====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = nn.Identity()\n",
    "resnet = resnet.to(device).eval()\n",
    "\n",
    "transform_cnn = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def extract_cnn_feature(img):\n",
    "    if isinstance(img, np.ndarray):\n",
    "        img = Image.fromarray(img)\n",
    "    elif isinstance(img, torch.Tensor):\n",
    "        img = T.ToPILImage()(img)\n",
    "    if getattr(img, \"mode\", None) != \"RGB\":\n",
    "        img = img.convert(\"RGB\")\n",
    "    x = transform_cnn(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        feat = resnet(x).cpu().numpy().flatten()\n",
    "    return feat  # [512]\n",
    "\n",
    "# ---------- Top-K 病灶裁剪 + 池化 ----------\n",
    "def extract_topk_crops(pil_img, nuc_mask, k=3, pad_ratio=0.12, out_size=224):\n",
    "    lab = measure.label(nuc_mask)\n",
    "    props = sorted(measure.regionprops(lab), key=lambda p: p.area, reverse=True)\n",
    "    W, H = pil_img.width, pil_img.height\n",
    "    crops = []\n",
    "    for p in props[:k]:\n",
    "        ymin, xmin, ymax, xmax = p.bbox\n",
    "        h, w = ymax - ymin, xmax - xmin\n",
    "        if h <= 0 or w <= 0: continue\n",
    "        px = int(pad_ratio * w); py = int(pad_ratio * h)\n",
    "        xmin = max(xmin - px, 0); xmax = min(xmax + px, W)\n",
    "        ymin = max(ymin - py, 0); ymax = min(ymax + py, H)\n",
    "        crops.append(pil_img.crop((xmin, ymin, xmax, ymax)).resize((out_size, out_size)))\n",
    "    if not crops:\n",
    "        crops = [pil_img.resize((out_size, out_size))]\n",
    "    return crops\n",
    "\n",
    "def cnn_features_pooled(crops):\n",
    "    feats = [extract_cnn_feature(im) for im in crops]  # [k,512]\n",
    "    F = np.stack(feats, 0)\n",
    "    return np.concatenate([F.mean(0), F.max(0)], 0)  # [1024]\n",
    "# ------------------------------------------\n",
    "\n",
    "def read_thumbnail_and_geometry(svs_path, min_dim=3000):\n",
    "    slide = openslide.OpenSlide(svs_path)\n",
    "    W0, H0 = slide.dimensions\n",
    "    scale = max(W0, H0) / float(min_dim)\n",
    "    new_w, new_h = int(W0/scale), int(H0/scale)\n",
    "    img = slide.get_thumbnail((new_w, new_h))\n",
    "    mpp_x = slide.properties.get(\"openslide.mpp-x\", None)\n",
    "    mpp_y = slide.properties.get(\"openslide.mpp-y\", None)\n",
    "    slide.close()\n",
    "    mpp_x = float(mpp_x) if mpp_x not in (None, \"\") else None\n",
    "    mpp_y = float(mpp_y) if mpp_y not in (None, \"\") else None\n",
    "    return np.asarray(img), scale, mpp_x, mpp_y\n",
    "\n",
    "def tissue_mask(rgb):\n",
    "    hsv = color.rgb2hsv(rgb); v = hsv[..., 2]\n",
    "    thr = filters.threshold_otsu(v)\n",
    "    mask = v < thr * 0.98\n",
    "    mask = morphology.remove_small_holes(mask, 256)\n",
    "    mask = morphology.remove_small_objects(mask, 256)\n",
    "    return mask\n",
    "\n",
    "def he_nuclei_mask(rgb, tissue):\n",
    "    rgbf = np.clip(rgb/255.0, 0, 1)\n",
    "    hed = color.separate_stains(rgbf, hed_from_rgb)\n",
    "    H = hed[..., 0]\n",
    "    H = exposure.rescale_intensity(\n",
    "        H, in_range=(np.percentile(H[tissue], 2), np.percentile(H[tissue], 98)))\n",
    "    thr = filters.threshold_otsu(H[tissue])\n",
    "    nuc = np.zeros_like(H, dtype=bool)\n",
    "    nuc[tissue] = H[tissue] > thr\n",
    "    nuc = morphology.remove_small_objects(nuc, 64)\n",
    "    nuc = morphology.binary_opening(nuc, morphology.disk(2))\n",
    "    return nuc, H\n",
    "\n",
    "def wsi_features(svs_path):\n",
    "    rgb, scale, mpp_x, mpp_y = read_thumbnail_and_geometry(svs_path)\n",
    "    has_mpp = (mpp_x is not None) and (mpp_y is not None) and (mpp_x > 0) and (mpp_y > 0)\n",
    "    if REQUIRE_MPP and not has_mpp:\n",
    "        return None\n",
    "    mask = tissue_mask(rgb)\n",
    "    if mask.sum() < 5000:\n",
    "        return None\n",
    "    nuc, H = he_nuclei_mask(rgb, mask)\n",
    "\n",
    "    # —— 手工统计\n",
    "    tissue_px_thumb = int(mask.sum())\n",
    "    tumor_px_thumb  = int(nuc.sum())\n",
    "    lab = measure.label(nuc)\n",
    "    props = measure.regionprops(lab)\n",
    "    areas  = np.array([p.area for p in props], dtype=np.float32) if props else np.array([])\n",
    "    perims = np.array([p.perimeter for p in props], dtype=np.float32) if props else np.array([])\n",
    "    cc_count = len(props)\n",
    "    largest_cc_px = int(areas.max()) if cc_count else 0\n",
    "\n",
    "    tumor_frac = tumor_px_thumb / max(tissue_px_thumb, 1)\n",
    "    largest_cc_frac = largest_cc_px / max(tissue_px_thumb, 1)\n",
    "    small_thresh = 0.001 * tissue_px_thumb\n",
    "    cc_small = int((areas < small_thresh).sum()) if cc_count else 0\n",
    "    cc_small_frac = cc_small / max(cc_count, 1)\n",
    "    frag_ratio = float(perims.sum() / (areas.sum() + 1e-6)) if cc_count else 0.0\n",
    "\n",
    "    feats = dict(\n",
    "        tumor_frac=tumor_frac,\n",
    "        largest_cc_frac=largest_cc_frac,\n",
    "        cc_count=cc_count,\n",
    "        cc_small_frac=cc_small_frac,\n",
    "        frag_ratio=frag_ratio,\n",
    "    )\n",
    "\n",
    "    # —— CNN：Top-K 裁剪 + 池化（K=3）\n",
    "    pil_img = Image.fromarray(rgb)\n",
    "    crops = extract_topk_crops(pil_img, nuc_mask=nuc, k=3, pad_ratio=0.12)\n",
    "    cnn_feat = cnn_features_pooled(crops)  # [1024]\n",
    "\n",
    "    return feats, cnn_feat\n",
    "\n",
    "def collect_rows(root):\n",
    "    rows = []\n",
    "    for stage in [1,2,3,4]:\n",
    "        for split in [\"train\",\"test\"]:\n",
    "            d = Path(root) / f\"stage {stage} {split}\"\n",
    "            if not d.exists(): continue\n",
    "            label = stage - 1        # ★ 变更点：四分类直接用 1→0,2→1,3→2,4→3\n",
    "            for p in list(d.glob(\"*.svs\")) + list(d.glob(\"*.tif\")):\n",
    "                res = wsi_features(str(p))\n",
    "                if res is None: continue\n",
    "                feats, cnn_feat = res\n",
    "                row = dict(path=str(p), label=label, split=split); row.update(feats)\n",
    "                for i, v in enumerate(cnn_feat):\n",
    "                    row[f\"cnn_{i}\"] = v\n",
    "                rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ===== 主程序 =====\n",
    "if __name__ == \"__main__\":\n",
    "    df = collect_rows(ROOT)\n",
    "    print(\"Feature rows:\", df.shape)\n",
    "    print(\"Class distribution (0=stage1, 1=stage2, 2=stage3, 3=stage4):\\n\",   # ★ 变更点\n",
    "          df[\"label\"].value_counts().sort_index())\n",
    "    df.to_csv(\"wsi_stage_features_topk_4class.csv\", index=False)\n",
    "\n",
    "    train_df = df[df.split==\"train\"].copy()\n",
    "    test_df  = df[df.split==\"test\"].copy()\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c.startswith(\"cnn_\")] + [\n",
    "        \"tumor_frac\",\"largest_cc_frac\",\"cc_count\",\"cc_small_frac\",\"frag_ratio\"\n",
    "    ]\n",
    "\n",
    "    Xtr = train_df[feature_cols].values\n",
    "    ytr = train_df[\"label\"].values\n",
    "    Xte = test_df[feature_cols].values\n",
    "    yte = test_df[\"label\"].values\n",
    "\n",
    "    # ===== 类不平衡权重：按 4 类计算 =====\n",
    "    counts = train_df[\"label\"].value_counts()\n",
    "    n_classes = 4                                                          # ★ 变更点\n",
    "    class_weight_map = {c: len(train_df) / (n_classes * counts[c]) for c in counts.index}\n",
    "    # 可选：额外拉高极少类（例如 stage1/4）\n",
    "    for k, mult in {0:1.4, 3:1.5}.items():                                 # ★ 可调\n",
    "        if k in class_weight_map: class_weight_map[k] *= mult\n",
    "    weights = train_df[\"label\"].map(class_weight_map).values\n",
    "\n",
    "    clf = HistGradientBoostingClassifier(\n",
    "        max_depth=6, learning_rate=0.06, max_iter=600,\n",
    "        l2_regularization=1.0, min_samples_leaf=20, random_state=0\n",
    "    )\n",
    "    clf.fit(Xtr, ytr, sample_weight=weights)\n",
    "\n",
    "    # ===== 预测：按 4 类输出；可对两端类小幅 boost =====\n",
    "    proba = clf.predict_proba(Xte)                                        # [N,4]\n",
    "    proba[:, 0] *= 1.10   # stage1 boost（可按需要调整/去掉）\n",
    "    proba[:, 3] *= 1.15   # stage4 boost\n",
    "    proba = proba / np.clip(proba.sum(1, keepdims=True), 1e-12, None)\n",
    "    ypr = proba.argmax(axis=1)\n",
    "\n",
    "    print(\"\\nConfusion matrix:\\n\", confusion_matrix(yte, ypr, labels=[0,1,2,3]))   # ★ 变更点\n",
    "    print(\"\\nReport:\\n\", classification_report(\n",
    "        yte, ypr, labels=[0,1,2,3],                                                # ★ 变更点\n",
    "        target_names=[\"stage1\",\"stage2\",\"stage3\",\"stage4\"], digits=4))\n"
   ],
   "id": "dc0e4727b110dfe3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature rows: (133, 1032)\n",
      "Class distribution (0=stage1, 1=stage2, 2=stage3, 3=stage4):\n",
      " label\n",
      "0    35\n",
      "1    51\n",
      "2    38\n",
      "3     9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Confusion matrix:\n",
      " [[2 3 1 2]\n",
      " [3 4 1 0]\n",
      " [2 3 2 1]\n",
      " [0 1 0 1]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      stage1     0.2857    0.2500    0.2667         8\n",
      "      stage2     0.3636    0.5000    0.4211         8\n",
      "      stage3     0.5000    0.2500    0.3333         8\n",
      "      stage4     0.2500    0.5000    0.3333         2\n",
      "\n",
      "    accuracy                         0.3462        26\n",
      "   macro avg     0.3498    0.3750    0.3386        26\n",
      "weighted avg     0.3729    0.3462    0.3398        26\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T14:51:14.288594Z",
     "start_time": "2025-09-17T14:43:18.335300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openslide\n",
    "from skimage import color, filters, morphology, measure, exposure\n",
    "from skimage.color import hed_from_rgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# =================== 基础设置 ===================\n",
    "ROOT = r\"C:\\Users\\mxjli\\Desktop\\image\"\n",
    "REQUIRE_MPP = True    # 需要 mpp 才计算物理面积\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = nn.Identity()\n",
    "resnet = resnet.to(device).eval()\n",
    "\n",
    "transform_cnn = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def extract_cnn_feature(img):\n",
    "    if isinstance(img, np.ndarray):\n",
    "        img = Image.fromarray(img)\n",
    "    elif isinstance(img, torch.Tensor):\n",
    "        img = T.ToPILImage()(img)\n",
    "    if getattr(img, \"mode\", None) != \"RGB\":\n",
    "        img = img.convert(\"RGB\")\n",
    "    x = transform_cnn(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        feat = resnet(x).cpu().numpy().flatten()\n",
    "    return feat  # 512d\n",
    "\n",
    "# ----------- Top-K 病灶裁剪 + 池化（更稳） -----------\n",
    "def extract_topk_crops(pil_img, nuc_mask, k=5, pad_ratio=0.18, out_size=224):\n",
    "    lab = measure.label(nuc_mask)\n",
    "    props = sorted(measure.regionprops(lab), key=lambda p: p.area, reverse=True)\n",
    "    W, H = pil_img.width, pil_img.height\n",
    "    crops = []\n",
    "    for p in props[:k]:\n",
    "        ymin, xmin, ymax, xmax = p.bbox\n",
    "        h, w = ymax - ymin, xmax - xmin\n",
    "        if h <= 0 or w <= 0:\n",
    "            continue\n",
    "        px = int(pad_ratio * w); py = int(pad_ratio * h)\n",
    "        xmin = max(xmin - px, 0); xmax = min(xmax + px, W)\n",
    "        ymin = max(ymin - py, 0); ymax = min(ymax + py, H)\n",
    "        crops.append(pil_img.crop((xmin, ymin, xmax, ymax)).resize((out_size, out_size)))\n",
    "    if not crops:  # 兜底\n",
    "        crops = [pil_img.resize((out_size, out_size))]\n",
    "    return crops\n",
    "\n",
    "def cnn_features_pooled(crops):\n",
    "    feats = [extract_cnn_feature(im) for im in crops]  # [k,512]\n",
    "    F = np.stack(feats, 0)\n",
    "    return np.concatenate([F.mean(0), F.max(0)], 0)    # 1024d\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def read_thumbnail_and_geometry(svs_path, min_dim=3000):\n",
    "    slide = openslide.OpenSlide(svs_path)\n",
    "    W0, H0 = slide.dimensions\n",
    "    scale = max(W0, H0) / float(min_dim)\n",
    "    new_w, new_h = int(W0/scale), int(H0/scale)\n",
    "    img = slide.get_thumbnail((new_w, new_h))\n",
    "    mpp_x = slide.properties.get(\"openslide.mpp-x\", None)\n",
    "    mpp_y = slide.properties.get(\"openslide.mpp-y\", None)\n",
    "    slide.close()\n",
    "    mpp_x = float(mpp_x) if mpp_x not in (None, \"\") else None\n",
    "    mpp_y = float(mpp_y) if mpp_y not in (None, \"\") else None\n",
    "    return np.asarray(img), scale, mpp_x, mpp_y\n",
    "\n",
    "def tissue_mask(rgb):\n",
    "    hsv = color.rgb2hsv(rgb); v = hsv[..., 2]\n",
    "    thr = filters.threshold_otsu(v)\n",
    "    mask = v < thr * 0.98\n",
    "    mask = morphology.remove_small_holes(mask, 256)\n",
    "    mask = morphology.remove_small_objects(mask, 256)\n",
    "    return mask\n",
    "\n",
    "def he_nuclei_mask(rgb, tissue):\n",
    "    rgbf = np.clip(rgb/255.0, 0, 1)\n",
    "    hed = color.separate_stains(rgbf, hed_from_rgb)\n",
    "    H = hed[..., 0]\n",
    "    H = exposure.rescale_intensity(\n",
    "        H, in_range=(np.percentile(H[tissue], 2), np.percentile(H[tissue], 98)))\n",
    "    thr = filters.threshold_otsu(H[tissue])\n",
    "    nuc = np.zeros_like(H, dtype=bool)\n",
    "    nuc[tissue] = H[tissue] > thr\n",
    "    nuc = morphology.remove_small_objects(nuc, 64)\n",
    "    nuc = morphology.binary_opening(nuc, morphology.disk(2))\n",
    "    return nuc, H\n",
    "\n",
    "def wsi_features(svs_path):\n",
    "    rgb, scale, mpp_x, mpp_y = read_thumbnail_and_geometry(svs_path)\n",
    "    has_mpp = (mpp_x is not None) and (mpp_y is not None) and (mpp_x > 0) and (mpp_y > 0)\n",
    "    if REQUIRE_MPP and not has_mpp:\n",
    "        return None\n",
    "\n",
    "    mask = tissue_mask(rgb)\n",
    "    if mask.sum() < 5000:\n",
    "        return None\n",
    "    nuc, H = he_nuclei_mask(rgb, mask)\n",
    "\n",
    "    # ------ 缩略图像素域统计 ------\n",
    "    tissue_px_thumb = int(mask.sum())\n",
    "    tumor_px_thumb  = int(nuc.sum())\n",
    "    lab = measure.label(nuc)\n",
    "    props = measure.regionprops(lab)\n",
    "    areas  = np.array([p.area for p in props], dtype=np.float32) if props else np.array([])\n",
    "    perims = np.array([p.perimeter for p in props], dtype=np.float32) if props else np.array([])\n",
    "    cc_count = len(props)\n",
    "    largest_cc_px = int(areas.max()) if cc_count else 0\n",
    "\n",
    "    tumor_frac = tumor_px_thumb / max(tissue_px_thumb, 1)\n",
    "    largest_cc_frac = largest_cc_px / max(tissue_px_thumb, 1)\n",
    "    small_thresh = 0.001 * tissue_px_thumb\n",
    "    cc_small = int((areas < small_thresh).sum()) if cc_count else 0\n",
    "    cc_small_frac = cc_small / max(cc_count, 1)\n",
    "    frag_ratio = float(perims.sum() / (areas.sum() + 1e-6)) if cc_count else 0.0\n",
    "\n",
    "    feats = dict(\n",
    "        tumor_frac=tumor_frac,\n",
    "        largest_cc_frac=largest_cc_frac,\n",
    "        cc_count=cc_count,\n",
    "        cc_small_frac=cc_small_frac,\n",
    "        frag_ratio=frag_ratio,\n",
    "    )\n",
    "\n",
    "    # ------ 物理尺度（mm²/cm²），直连 “T 大小” ------\n",
    "    if has_mpp:\n",
    "        px_area_mm2 = (mpp_x * mpp_y) * 1e-6\n",
    "        s2 = scale * scale\n",
    "        tissue_area_mm2  = tissue_px_thumb  * s2 * px_area_mm2\n",
    "        tumor_area_mm2   = tumor_px_thumb   * s2 * px_area_mm2\n",
    "        largest_cc_mm2   = largest_cc_px    * s2 * px_area_mm2\n",
    "        tissue_area_cm2  = tissue_area_mm2 / 100.0\n",
    "        tumor_area_cm2   = tumor_area_mm2  / 100.0\n",
    "        largest_cc_cm2   = largest_cc_mm2  / 100.0\n",
    "        cc_per_cm2       = cc_count / max(tissue_area_cm2, 1e-6)\n",
    "        feats.update(dict(\n",
    "            tissue_area_mm2=tissue_area_mm2,\n",
    "            tumor_area_mm2=tumor_area_mm2,\n",
    "            largest_cc_mm2=largest_cc_mm2,\n",
    "            tissue_area_cm2=tissue_area_cm2,\n",
    "            tumor_area_cm2=tumor_area_cm2,\n",
    "            largest_cc_cm2=largest_cc_cm2,\n",
    "            cc_per_cm2=cc_per_cm2,\n",
    "            has_mpp=1\n",
    "        ))\n",
    "    else:\n",
    "        feats.update(dict(\n",
    "            tissue_area_mm2=np.nan, tumor_area_mm2=np.nan, largest_cc_mm2=np.nan,\n",
    "            tissue_area_cm2=np.nan,  tumor_area_cm2=np.nan,  largest_cc_cm2=np.nan,\n",
    "            cc_per_cm2=np.nan, has_mpp=0\n",
    "        ))\n",
    "\n",
    "    # ------ CNN：Top-K 裁剪 + 池化 ------\n",
    "    pil_img = Image.fromarray(rgb)\n",
    "    crops = extract_topk_crops(pil_img, nuc_mask=nuc, k=5, pad_ratio=0.18)\n",
    "    cnn_feat = cnn_features_pooled(crops)  # 1024d\n",
    "\n",
    "    return feats, cnn_feat\n",
    "\n",
    "def collect_rows(root):\n",
    "    rows = []\n",
    "    for stage in [1,2,3,4]:\n",
    "        for split in [\"train\",\"test\"]:\n",
    "            d = Path(root) / f\"stage {stage} {split}\"\n",
    "            if not d.exists():\n",
    "                continue\n",
    "            label = stage - 1\n",
    "            for p in list(d.glob(\"*.svs\")) + list(d.glob(\"*.tif\")):\n",
    "                res = wsi_features(str(p))\n",
    "                if res is None:\n",
    "                    continue\n",
    "                feats, cnn_feat = res\n",
    "                row = dict(path=str(p), label=label, split=split); row.update(feats)\n",
    "                for i, v in enumerate(cnn_feat):\n",
    "                    row[f\"cnn_{i}\"] = v\n",
    "                rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# =================== 训练与评估 ===================\n",
    "if __name__ == \"__main__\":\n",
    "    df = collect_rows(ROOT)\n",
    "    print(\"Feature rows:\", df.shape)\n",
    "    print(\"Class distribution (0=stage1, 1=stage2, 2=stage3, 3=stage4):\\n\",\n",
    "          df[\"label\"].value_counts().sort_index())\n",
    "    df.to_csv(\"wsi_stage_features_topk_4class_phys.csv\", index=False)\n",
    "\n",
    "    train_df = df[df.split==\"train\"].copy()\n",
    "    test_df  = df[df.split==\"test\"].copy()\n",
    "\n",
    "    # 特征列：CNN + 像素比例 + 物理面积（若无 mpp 自动是 NaN，HGB 能处理）\n",
    "    feature_cols = [c for c in df.columns if c.startswith(\"cnn_\")] + [\n",
    "        \"tumor_frac\",\"largest_cc_frac\",\"cc_count\",\"cc_small_frac\",\"frag_ratio\",\n",
    "        \"tumor_area_mm2\",\"largest_cc_mm2\",\"tissue_area_mm2\",\"cc_per_cm2\",\n",
    "        \"tumor_area_cm2\",\"largest_cc_cm2\",\"tissue_area_cm2\"\n",
    "    ]\n",
    "\n",
    "    Xtr = train_df[feature_cols].values\n",
    "    ytr = train_df[\"label\"].values\n",
    "    Xte = test_df[feature_cols].values\n",
    "    yte = test_df[\"label\"].values\n",
    "\n",
    "    # ===== 类不平衡：先按频次反比，再对 1/4 额外放大 =====\n",
    "    counts = train_df[\"label\"].value_counts()\n",
    "    n_classes = 4\n",
    "    class_weight_map = {c: len(train_df) / (n_classes * counts[c]) for c in counts.index}\n",
    "    EXTRA_BOOST = {0: 2.0, 3: 3.0}  # 更激进：stage1×2，stage4×3\n",
    "    for k, mult in EXTRA_BOOST.items():\n",
    "        if k in class_weight_map:\n",
    "            class_weight_map[k] *= mult\n",
    "    weights = train_df[\"label\"].map(class_weight_map).values\n",
    "\n",
    "    # ===== HGB 参数（可微调）=====\n",
    "    clf = HistGradientBoostingClassifier(\n",
    "        max_depth=7,           # 6~8\n",
    "        max_iter=800,          # 600~1200\n",
    "        learning_rate=0.06,    # 0.05~0.1\n",
    "        min_samples_leaf=16,   # 10~40\n",
    "        l2_regularization=0.5, # 0.0~1.0\n",
    "        random_state=0\n",
    "    )\n",
    "    clf.fit(Xtr, ytr, sample_weight=weights)\n",
    "\n",
    "    # ===== 预测后 class bias（让 1/4 再“响亮一点”）=====\n",
    "    proba = clf.predict_proba(Xte)  # (N,4)\n",
    "    BIAS = np.array([1.25, 1.00, 1.00, 1.40], dtype=np.float32)\n",
    "    proba = proba * BIAS[None, :]\n",
    "    proba = proba / np.clip(proba.sum(1, keepdims=True), 1e-12, None)\n",
    "    ypr = proba.argmax(1)\n",
    "\n",
    "    print(\"\\nConfusion matrix:\\n\", confusion_matrix(yte, ypr, labels=[0,1,2,3]))\n",
    "    print(\"\\nReport:\\n\", classification_report(\n",
    "        yte, ypr, labels=[0,1,2,3],\n",
    "        target_names=[\"stage1\",\"stage2\",\"stage3\",\"stage4\"], digits=4))\n"
   ],
   "id": "29007eb69d4b2e82",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature rows: (133, 1040)\n",
      "Class distribution (0=stage1, 1=stage2, 2=stage3, 3=stage4):\n",
      " label\n",
      "0    35\n",
      "1    51\n",
      "2    38\n",
      "3     9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Confusion matrix:\n",
      " [[4 4 0 0]\n",
      " [3 3 2 0]\n",
      " [2 4 2 0]\n",
      " [0 1 0 1]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      stage1     0.4444    0.5000    0.4706         8\n",
      "      stage2     0.2500    0.3750    0.3000         8\n",
      "      stage3     0.5000    0.2500    0.3333         8\n",
      "      stage4     1.0000    0.5000    0.6667         2\n",
      "\n",
      "    accuracy                         0.3846        26\n",
      "   macro avg     0.5486    0.4062    0.4426        26\n",
      "weighted avg     0.4444    0.3846    0.3910        26\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
