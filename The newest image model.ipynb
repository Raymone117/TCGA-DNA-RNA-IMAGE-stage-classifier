{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T03:02:39.454165Z",
     "start_time": "2025-09-17T02:54:56.498293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openslide\n",
    "from skimage import color, filters, morphology, measure, exposure, transform\n",
    "from skimage.color import hed_from_rgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ===== 根目录 =====\n",
    "ROOT = r\"C:\\Users\\mxjli\\Desktop\\image\"\n",
    "REQUIRE_MPP = True\n",
    "\n",
    "# ===== CNN 特征提取器 =====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = nn.Identity()  # 去掉最后分类层\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n",
    "\n",
    "# 图像预处理\n",
    "transform_cnn = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((224,224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def extract_cnn_feature(rgb_crop):\n",
    "    \"\"\"输入RGB图像 -> 提取CNN特征\"\"\"\n",
    "    x = transform_cnn(rgb_crop).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        feat = resnet(x).cpu().numpy().flatten()\n",
    "    return feat\n",
    "\n",
    "# ===== 读取与分割 =====\n",
    "def read_thumbnail_and_geometry(svs_path, min_dim=3000):\n",
    "    slide = openslide.OpenSlide(svs_path)\n",
    "    W0, H0 = slide.dimensions\n",
    "    scale = max(W0, H0) / float(min_dim)\n",
    "    new_w, new_h = int(W0/scale), int(H0/scale)\n",
    "    img = slide.get_thumbnail((new_w, new_h))\n",
    "    mpp_x = slide.properties.get(\"openslide.mpp-x\", None)\n",
    "    mpp_y = slide.properties.get(\"openslide.mpp-y\", None)\n",
    "    slide.close()\n",
    "    mpp_x = float(mpp_x) if mpp_x not in (None, \"\") else None\n",
    "    mpp_y = float(mpp_y) if mpp_y not in (None, \"\") else None\n",
    "    return np.asarray(img), scale, mpp_x, mpp_y\n",
    "\n",
    "def tissue_mask(rgb):\n",
    "    hsv = color.rgb2hsv(rgb)\n",
    "    v = hsv[..., 2]\n",
    "    thr = filters.threshold_otsu(v)\n",
    "    mask = v < thr * 0.98\n",
    "    mask = morphology.remove_small_holes(mask, 256)\n",
    "    mask = morphology.remove_small_objects(mask, 256)\n",
    "    return mask\n",
    "\n",
    "def he_nuclei_mask(rgb, tissue):\n",
    "    rgbf = np.clip(rgb/255.0, 0, 1)\n",
    "    hed = color.separate_stains(rgbf, hed_from_rgb)\n",
    "    H = hed[..., 0]\n",
    "    H = exposure.rescale_intensity(\n",
    "        H,\n",
    "        in_range=(np.percentile(H[tissue], 2), np.percentile(H[tissue], 98))\n",
    "    )\n",
    "    thr = filters.threshold_otsu(H[tissue])\n",
    "    nuc = np.zeros_like(H, dtype=bool)\n",
    "    nuc[tissue] = H[tissue] > thr\n",
    "    nuc = morphology.remove_small_objects(nuc, 64)\n",
    "    nuc = morphology.binary_opening(nuc, morphology.disk(2))\n",
    "    return nuc, H\n",
    "\n",
    "# ===== 提取特征（手工 + CNN）=====\n",
    "def wsi_features(svs_path):\n",
    "    rgb, scale, mpp_x, mpp_y = read_thumbnail_and_geometry(svs_path)\n",
    "    has_mpp = (mpp_x is not None) and (mpp_y is not None) and (mpp_x > 0) and (mpp_y > 0)\n",
    "    if REQUIRE_MPP and not has_mpp:\n",
    "        return None\n",
    "\n",
    "    mask = tissue_mask(rgb)\n",
    "    if mask.sum() < 5000:\n",
    "        return None\n",
    "    nuc, H = he_nuclei_mask(rgb, mask)\n",
    "\n",
    "    # 手工特征\n",
    "    tissue_px_thumb = int(mask.sum())\n",
    "    tumor_px_thumb  = int(nuc.sum())\n",
    "    tumor_frac = tumor_px_thumb / tissue_px_thumb\n",
    "    h_vals = H[mask]\n",
    "    h_mean, h_std = float(h_vals.mean()), float(h_vals.std())\n",
    "\n",
    "    feats = dict(\n",
    "        tumor_frac=tumor_frac,\n",
    "        h_mean=h_mean, h_std=h_std\n",
    "    )\n",
    "\n",
    "    # CNN 特征（肿瘤外接框裁剪）\n",
    "    ys, xs = np.where(nuc)\n",
    "    if len(xs) > 0 and len(ys) > 0:\n",
    "        xmin, xmax = xs.min(), xs.max()\n",
    "        ymin, ymax = ys.min(), ys.max()\n",
    "        crop = rgb[ymin:ymax, xmin:xmax]\n",
    "        cnn_feat = extract_cnn_feature(crop)\n",
    "    else:\n",
    "        cnn_feat = np.zeros(512, dtype=np.float32)  # 兜底\n",
    "\n",
    "    return feats, cnn_feat\n",
    "\n",
    "def collect_rows(root):\n",
    "    rows = []\n",
    "    for stage in [1,2,3,4]:\n",
    "        for split in [\"train\",\"test\"]:\n",
    "            d = Path(root) / f\"stage {stage} {split}\"\n",
    "            if not d.exists():\n",
    "                continue\n",
    "\n",
    "            # === 三分类映射：1->0, 2/3->1, 4->2 ===\n",
    "            if stage == 1:\n",
    "                label = 0\n",
    "            elif stage in (2, 3):\n",
    "                label = 1\n",
    "            else:  # stage == 4\n",
    "                label = 2\n",
    "\n",
    "            for p in list(d.glob(\"*.svs\")) + list(d.glob(\"*.tif\")):\n",
    "                res = wsi_features(str(p))\n",
    "                if res is None:\n",
    "                    continue\n",
    "                feats, cnn_feat = res\n",
    "                row = dict(path=str(p), label=label, split=split)\n",
    "                row.update(feats)\n",
    "                for i, v in enumerate(cnn_feat):\n",
    "                    row[f\"cnn_{i}\"] = v\n",
    "                rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ===== 主程序 =====\n",
    "if __name__ == \"__main__\":\n",
    "    df = collect_rows(ROOT)\n",
    "    print(\"Feature rows:\", df.shape)\n",
    "    print(\"Class distribution (0=stage1, 1=stage2&3, 2=stage4):\\n\",\n",
    "          df[\"label\"].value_counts().sort_index())\n",
    "    df.to_csv(\"wsi_stage_features_cnn_3class.csv\", index=False)\n",
    "\n",
    "    train_df = df[df.split==\"train\"]\n",
    "    test_df  = df[df.split==\"test\"]\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c.startswith(\"cnn_\")] + [\"tumor_frac\",\"h_mean\",\"h_std\"]\n",
    "\n",
    "    Xtr, ytr = train_df[feature_cols].values, train_df[\"label\"].values\n",
    "    Xte, yte = test_df[feature_cols].values, test_df[\"label\"].values\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=400, random_state=0, n_jobs=-1, class_weight=\"balanced\"\n",
    "    )\n",
    "    clf.fit(Xtr, ytr)\n",
    "    ypr = clf.predict(Xte)\n",
    "\n",
    "    print(\"\\nConfusion matrix:\\n\", confusion_matrix(yte, ypr, labels=[0,1,2]))\n",
    "    print(\"\\nReport:\\n\", classification_report(\n",
    "        yte, ypr, labels=[0,1,2],\n",
    "        target_names=[\"stage1\",\"stage2&3\",\"stage4\"], digits=4))\n"
   ],
   "id": "954dd7b0d83f6a35",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature rows: (133, 518)\n",
      "Class distribution (0=stage1, 1=stage2&3, 2=stage4):\n",
      " label\n",
      "0    35\n",
      "1    89\n",
      "2     9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 0  7  0]\n",
      " [ 0 17  0]\n",
      " [ 0  2  0]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      stage1     0.0000    0.0000    0.0000         7\n",
      "    stage2&3     0.6538    1.0000    0.7907        17\n",
      "      stage4     0.0000    0.0000    0.0000         2\n",
      "\n",
      "    accuracy                         0.6538        26\n",
      "   macro avg     0.2179    0.3333    0.2636        26\n",
      "weighted avg     0.4275    0.6538    0.5170        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T03:30:20.429599Z",
     "start_time": "2025-09-17T03:22:43.990139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openslide\n",
    "from skimage import color, filters, morphology, measure, exposure\n",
    "from skimage.color import hed_from_rgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ===== 根目录 =====\n",
    "ROOT = r\"C:\\Users\\mxjli\\Desktop\\image\"\n",
    "REQUIRE_MPP = True\n",
    "\n",
    "# ===== CNN 特征提取器 =====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = nn.Identity()  # 去掉最后分类层\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n",
    "\n",
    "# 预处理（输入将是 PIL）\n",
    "transform_cnn = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def extract_cnn_feature(img):\n",
    "    \"\"\"img 可以是 PIL / numpy.ndarray / torch.Tensor；统一转 PIL→RGB 再变换\"\"\"\n",
    "    if isinstance(img, np.ndarray):\n",
    "        img = Image.fromarray(img)\n",
    "    elif isinstance(img, torch.Tensor):\n",
    "        img = T.ToPILImage()(img)\n",
    "    if getattr(img, \"mode\", None) != \"RGB\":\n",
    "        img = img.convert(\"RGB\")\n",
    "    x = transform_cnn(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        feat = resnet(x).cpu().numpy().flatten()\n",
    "    return feat\n",
    "\n",
    "def extract_tumor_region_with_padding(pil_img, tumor_mask, padding_ratio=0.12):\n",
    "    \"\"\"从 tumor_mask 中裁剪病灶区域，加 padding，返回 224x224 的 PIL\"\"\"\n",
    "    ys, xs = np.where(tumor_mask)\n",
    "    if len(xs) == 0 or len(ys) == 0:\n",
    "        return pil_img.resize((224, 224))\n",
    "    xmin, xmax = xs.min(), xs.max()\n",
    "    ymin, ymax = ys.min(), ys.max()\n",
    "    h, w = (ymax - ymin), (xmax - xmin)\n",
    "    pad_x = int(padding_ratio * w)\n",
    "    pad_y = int(padding_ratio * h)\n",
    "    xmin = max(xmin - pad_x, 0)\n",
    "    xmax = min(xmax + pad_x, pil_img.width)\n",
    "    ymin = max(ymin - pad_y, 0)\n",
    "    ymax = min(ymax + pad_y, pil_img.height)\n",
    "    return pil_img.crop((xmin, ymin, xmax, ymax)).resize((224, 224))\n",
    "\n",
    "# ===== 读取与分割 =====\n",
    "def read_thumbnail_and_geometry(svs_path, min_dim=3000):\n",
    "    slide = openslide.OpenSlide(svs_path)\n",
    "    W0, H0 = slide.dimensions\n",
    "    scale = max(W0, H0) / float(min_dim)\n",
    "    new_w, new_h = int(W0/scale), int(H0/scale)\n",
    "    img = slide.get_thumbnail((new_w, new_h))\n",
    "    mpp_x = slide.properties.get(\"openslide.mpp-x\", None)\n",
    "    mpp_y = slide.properties.get(\"openslide.mpp-y\", None)\n",
    "    slide.close()\n",
    "    mpp_x = float(mpp_x) if mpp_x not in (None, \"\") else None\n",
    "    mpp_y = float(mpp_y) if mpp_y not in (None, \"\") else None\n",
    "    return np.asarray(img), scale, mpp_x, mpp_y\n",
    "\n",
    "def tissue_mask(rgb):\n",
    "    hsv = color.rgb2hsv(rgb)\n",
    "    v = hsv[..., 2]\n",
    "    thr = filters.threshold_otsu(v)\n",
    "    mask = v < thr * 0.98\n",
    "    mask = morphology.remove_small_holes(mask, 256)\n",
    "    mask = morphology.remove_small_objects(mask, 256)\n",
    "    return mask\n",
    "\n",
    "def he_nuclei_mask(rgb, tissue):\n",
    "    rgbf = np.clip(rgb/255.0, 0, 1)\n",
    "    hed = color.separate_stains(rgbf, hed_from_rgb)\n",
    "    H = hed[..., 0]\n",
    "    H = exposure.rescale_intensity(\n",
    "        H, in_range=(np.percentile(H[tissue], 2), np.percentile(H[tissue], 98))\n",
    "    )\n",
    "    thr = filters.threshold_otsu(H[tissue])\n",
    "    nuc = np.zeros_like(H, dtype=bool)\n",
    "    nuc[tissue] = H[tissue] > thr\n",
    "    nuc = morphology.remove_small_objects(nuc, 64)\n",
    "    nuc = morphology.binary_opening(nuc, morphology.disk(2))\n",
    "    return nuc, H\n",
    "\n",
    "# ===== 提取特征（手工 + CNN）=====\n",
    "def wsi_features(svs_path):\n",
    "    rgb, scale, mpp_x, mpp_y = read_thumbnail_and_geometry(svs_path)\n",
    "    has_mpp = (mpp_x is not None) and (mpp_y is not None) and (mpp_x > 0) and (mpp_y > 0)\n",
    "    if REQUIRE_MPP and not has_mpp:\n",
    "        return None\n",
    "\n",
    "    mask = tissue_mask(rgb)\n",
    "    if mask.sum() < 5000:\n",
    "        return None\n",
    "    nuc, H = he_nuclei_mask(rgb, mask)\n",
    "\n",
    "    # 手工特征\n",
    "    tissue_px_thumb = int(mask.sum())\n",
    "    tumor_px_thumb  = int(nuc.sum())\n",
    "    tumor_frac = tumor_px_thumb / max(tissue_px_thumb, 1)\n",
    "    h_vals = H[mask]\n",
    "    h_mean, h_std = float(h_vals.mean()), float(h_vals.std())\n",
    "    feats = dict(tumor_frac=tumor_frac, h_mean=h_mean, h_std=h_std)\n",
    "\n",
    "    # CNN 特征：最小外接框 + padding 裁剪\n",
    "    pil_img = Image.fromarray(rgb)\n",
    "    tumor_crop = extract_tumor_region_with_padding(pil_img, tumor_mask=nuc, padding_ratio=0.12)\n",
    "    cnn_feat = extract_cnn_feature(tumor_crop)\n",
    "\n",
    "    return feats, cnn_feat\n",
    "\n",
    "def collect_rows(root):\n",
    "    rows = []\n",
    "    for stage in [1,2,3,4]:\n",
    "        for split in [\"train\",\"test\"]:\n",
    "            d = Path(root) / f\"stage {stage} {split}\"\n",
    "            if not d.exists():\n",
    "                continue\n",
    "            # 三分类映射：1->0, 2/3->1, 4->2\n",
    "            if stage == 1:\n",
    "                label = 0\n",
    "            elif stage in (2, 3):\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 2\n",
    "            for p in list(d.glob(\"*.svs\")) + list(d.glob(\"*.tif\")):\n",
    "                res = wsi_features(str(p))\n",
    "                if res is None:\n",
    "                    continue\n",
    "                feats, cnn_feat = res\n",
    "                row = dict(path=str(p), label=label, split=split)\n",
    "                row.update(feats)\n",
    "                for i, v in enumerate(cnn_feat):\n",
    "                    row[f\"cnn_{i}\"] = v\n",
    "                rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ===== 主程序 =====\n",
    "if __name__ == \"__main__\":\n",
    "    df = collect_rows(ROOT)\n",
    "    print(\"Feature rows:\", df.shape)\n",
    "    print(\"Class distribution (0=stage1, 1=stage2&3, 2=stage4):\\n\",\n",
    "          df[\"label\"].value_counts().sort_index())\n",
    "    df.to_csv(\"wsi_stage_features_cnn_3class_padding_fixed.csv\", index=False)\n",
    "\n",
    "    train_df = df[df.split==\"train\"]\n",
    "    test_df  = df[df.split==\"test\"]\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c.startswith(\"cnn_\")] + [\"tumor_frac\",\"h_mean\",\"h_std\"]\n",
    "    Xtr, ytr = train_df[feature_cols].values, train_df[\"label\"].values\n",
    "    Xte, yte = test_df[feature_cols].values, test_df[\"label\"].values\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=400, random_state=0, n_jobs=-1, class_weight=\"balanced\")\n",
    "    clf.fit(Xtr, ytr)\n",
    "    ypr = clf.predict(Xte)\n",
    "\n",
    "    print(\"\\nConfusion matrix:\\n\", confusion_matrix(yte, ypr, labels=[0,1,2]))\n",
    "    print(\"\\nReport:\\n\", classification_report(\n",
    "        yte, ypr, labels=[0,1,2],\n",
    "        target_names=[\"stage1\",\"stage2&3\",\"stage4\"], digits=4))\n"
   ],
   "id": "6a4b72cf264dca5c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature rows: (133, 518)\n",
      "Class distribution (0=stage1, 1=stage2&3, 2=stage4):\n",
      " label\n",
      "0    35\n",
      "1    89\n",
      "2     9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 1  6  0]\n",
      " [ 0 17  0]\n",
      " [ 0  2  0]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      stage1     1.0000    0.1429    0.2500         7\n",
      "    stage2&3     0.6800    1.0000    0.8095        17\n",
      "      stage4     0.0000    0.0000    0.0000         2\n",
      "\n",
      "    accuracy                         0.6923        26\n",
      "   macro avg     0.5600    0.3810    0.3532        26\n",
      "weighted avg     0.7138    0.6923    0.5966        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\mxjli\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T05:06:06.846949Z",
     "start_time": "2025-09-17T04:58:08.583563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openslide\n",
    "from skimage import color, filters, morphology, measure, exposure\n",
    "from skimage.color import hed_from_rgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ===== 根目录 =====\n",
    "ROOT = r\"C:\\Users\\mxjli\\Desktop\\image\"\n",
    "REQUIRE_MPP = True\n",
    "\n",
    "# ===== CNN 特征提取器 =====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = nn.Identity()\n",
    "resnet = resnet.to(device).eval()\n",
    "\n",
    "transform_cnn = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def extract_cnn_feature(img):\n",
    "    if isinstance(img, np.ndarray):\n",
    "        img = Image.fromarray(img)\n",
    "    elif isinstance(img, torch.Tensor):\n",
    "        img = T.ToPILImage()(img)\n",
    "    if getattr(img, \"mode\", None) != \"RGB\":\n",
    "        img = img.convert(\"RGB\")\n",
    "    x = transform_cnn(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        feat = resnet(x).cpu().numpy().flatten()\n",
    "    return feat  # [512]\n",
    "\n",
    "# ---------- Top-K 病灶裁剪 + 池化 ----------\n",
    "def extract_topk_crops(pil_img, nuc_mask, k=3, pad_ratio=0.12, out_size=224):\n",
    "    lab = measure.label(nuc_mask)\n",
    "    props = sorted(measure.regionprops(lab), key=lambda p: p.area, reverse=True)\n",
    "    W, H = pil_img.width, pil_img.height\n",
    "    crops = []\n",
    "    for p in props[:k]:\n",
    "        ymin, xmin, ymax, xmax = p.bbox\n",
    "        h, w = ymax - ymin, xmax - xmin\n",
    "        if h <= 0 or w <= 0: continue\n",
    "        px = int(pad_ratio * w); py = int(pad_ratio * h)\n",
    "        xmin = max(xmin - px, 0); xmax = min(xmax + px, W)\n",
    "        ymin = max(ymin - py, 0); ymax = min(ymax + py, H)\n",
    "        crops.append(pil_img.crop((xmin, ymin, xmax, ymax)).resize((out_size, out_size)))\n",
    "    if not crops:\n",
    "        crops = [pil_img.resize((out_size, out_size))]\n",
    "    return crops\n",
    "\n",
    "def cnn_features_pooled(crops):\n",
    "    feats = [extract_cnn_feature(im) for im in crops]  # [k,512]\n",
    "    F = np.stack(feats, 0)\n",
    "    return np.concatenate([F.mean(0), F.max(0)], 0)  # [1024]\n",
    "# ------------------------------------------\n",
    "\n",
    "def read_thumbnail_and_geometry(svs_path, min_dim=3000):\n",
    "    slide = openslide.OpenSlide(svs_path)\n",
    "    W0, H0 = slide.dimensions\n",
    "    scale = max(W0, H0) / float(min_dim)\n",
    "    new_w, new_h = int(W0/scale), int(H0/scale)\n",
    "    img = slide.get_thumbnail((new_w, new_h))\n",
    "    mpp_x = slide.properties.get(\"openslide.mpp-x\", None)\n",
    "    mpp_y = slide.properties.get(\"openslide.mpp-y\", None)\n",
    "    slide.close()\n",
    "    mpp_x = float(mpp_x) if mpp_x not in (None, \"\") else None\n",
    "    mpp_y = float(mpp_y) if mpp_y not in (None, \"\") else None\n",
    "    return np.asarray(img), scale, mpp_x, mpp_y\n",
    "\n",
    "def tissue_mask(rgb):\n",
    "    hsv = color.rgb2hsv(rgb); v = hsv[..., 2]\n",
    "    thr = filters.threshold_otsu(v)\n",
    "    mask = v < thr * 0.98\n",
    "    mask = morphology.remove_small_holes(mask, 256)\n",
    "    mask = morphology.remove_small_objects(mask, 256)\n",
    "    return mask\n",
    "\n",
    "def he_nuclei_mask(rgb, tissue):\n",
    "    rgbf = np.clip(rgb/255.0, 0, 1)\n",
    "    hed = color.separate_stains(rgbf, hed_from_rgb)\n",
    "    H = hed[..., 0]\n",
    "    H = exposure.rescale_intensity(\n",
    "        H, in_range=(np.percentile(H[tissue], 2), np.percentile(H[tissue], 98)))\n",
    "    thr = filters.threshold_otsu(H[tissue])\n",
    "    nuc = np.zeros_like(H, dtype=bool)\n",
    "    nuc[tissue] = H[tissue] > thr\n",
    "    nuc = morphology.remove_small_objects(nuc, 64)\n",
    "    nuc = morphology.binary_opening(nuc, morphology.disk(2))\n",
    "    return nuc, H\n",
    "\n",
    "def wsi_features(svs_path):\n",
    "    rgb, scale, mpp_x, mpp_y = read_thumbnail_and_geometry(svs_path)\n",
    "    has_mpp = (mpp_x is not None) and (mpp_y is not None) and (mpp_x > 0) and (mpp_y > 0)\n",
    "    if REQUIRE_MPP and not has_mpp:\n",
    "        return None\n",
    "    mask = tissue_mask(rgb)\n",
    "    if mask.sum() < 5000:\n",
    "        return None\n",
    "    nuc, H = he_nuclei_mask(rgb, mask)\n",
    "\n",
    "    # —— 手工统计\n",
    "    tissue_px_thumb = int(mask.sum())\n",
    "    tumor_px_thumb  = int(nuc.sum())\n",
    "    lab = measure.label(nuc)\n",
    "    props = measure.regionprops(lab)\n",
    "    areas  = np.array([p.area for p in props], dtype=np.float32) if props else np.array([])\n",
    "    perims = np.array([p.perimeter for p in props], dtype=np.float32) if props else np.array([])\n",
    "    cc_count = len(props)\n",
    "    largest_cc_px = int(areas.max()) if cc_count else 0\n",
    "\n",
    "    tumor_frac = tumor_px_thumb / max(tissue_px_thumb, 1)\n",
    "    largest_cc_frac = largest_cc_px / max(tissue_px_thumb, 1)\n",
    "    small_thresh = 0.001 * tissue_px_thumb\n",
    "    cc_small = int((areas < small_thresh).sum()) if cc_count else 0\n",
    "    cc_small_frac = cc_small / max(cc_count, 1)\n",
    "    frag_ratio = float(perims.sum() / (areas.sum() + 1e-6)) if cc_count else 0.0\n",
    "\n",
    "    feats = dict(\n",
    "        tumor_frac=tumor_frac,\n",
    "        largest_cc_frac=largest_cc_frac,\n",
    "        cc_count=cc_count,\n",
    "        cc_small_frac=cc_small_frac,\n",
    "        frag_ratio=frag_ratio,\n",
    "    )\n",
    "\n",
    "    # —— CNN：Top-K 裁剪 + 池化（K=3）\n",
    "    pil_img = Image.fromarray(rgb)\n",
    "    crops = extract_topk_crops(pil_img, nuc_mask=nuc, k=3, pad_ratio=0.12)\n",
    "    cnn_feat = cnn_features_pooled(crops)  # [1024]\n",
    "\n",
    "    return feats, cnn_feat\n",
    "\n",
    "def collect_rows(root):\n",
    "    rows = []\n",
    "    for stage in [1,2,3,4]:\n",
    "        for split in [\"train\",\"test\"]:\n",
    "            d = Path(root) / f\"stage {stage} {split}\"\n",
    "            if not d.exists(): continue\n",
    "            label = stage - 1        # ★ 变更点：四分类直接用 1→0,2→1,3→2,4→3\n",
    "            for p in list(d.glob(\"*.svs\")) + list(d.glob(\"*.tif\")):\n",
    "                res = wsi_features(str(p))\n",
    "                if res is None: continue\n",
    "                feats, cnn_feat = res\n",
    "                row = dict(path=str(p), label=label, split=split); row.update(feats)\n",
    "                for i, v in enumerate(cnn_feat):\n",
    "                    row[f\"cnn_{i}\"] = v\n",
    "                rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ===== 主程序 =====\n",
    "if __name__ == \"__main__\":\n",
    "    df = collect_rows(ROOT)\n",
    "    print(\"Feature rows:\", df.shape)\n",
    "    print(\"Class distribution (0=stage1, 1=stage2, 2=stage3, 3=stage4):\\n\",   # ★ 变更点\n",
    "          df[\"label\"].value_counts().sort_index())\n",
    "    df.to_csv(\"wsi_stage_features_topk_4class.csv\", index=False)\n",
    "\n",
    "    train_df = df[df.split==\"train\"].copy()\n",
    "    test_df  = df[df.split==\"test\"].copy()\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c.startswith(\"cnn_\")] + [\n",
    "        \"tumor_frac\",\"largest_cc_frac\",\"cc_count\",\"cc_small_frac\",\"frag_ratio\"\n",
    "    ]\n",
    "\n",
    "    Xtr = train_df[feature_cols].values\n",
    "    ytr = train_df[\"label\"].values\n",
    "    Xte = test_df[feature_cols].values\n",
    "    yte = test_df[\"label\"].values\n",
    "\n",
    "    # ===== 类不平衡权重：按 4 类计算 =====\n",
    "    counts = train_df[\"label\"].value_counts()\n",
    "    n_classes = 4                                                          # ★ 变更点\n",
    "    class_weight_map = {c: len(train_df) / (n_classes * counts[c]) for c in counts.index}\n",
    "    # 可选：额外拉高极少类（例如 stage1/4）\n",
    "    for k, mult in {0:1.4, 3:1.5}.items():                                 # ★ 可调\n",
    "        if k in class_weight_map: class_weight_map[k] *= mult\n",
    "    weights = train_df[\"label\"].map(class_weight_map).values\n",
    "\n",
    "    clf = HistGradientBoostingClassifier(\n",
    "        max_depth=6, learning_rate=0.06, max_iter=600,\n",
    "        l2_regularization=1.0, min_samples_leaf=20, random_state=0\n",
    "    )\n",
    "    clf.fit(Xtr, ytr, sample_weight=weights)\n",
    "\n",
    "    # ===== 预测：按 4 类输出；可对两端类小幅 boost =====\n",
    "    proba = clf.predict_proba(Xte)                                        # [N,4]\n",
    "    proba[:, 0] *= 1.10   # stage1 boost（可按需要调整/去掉）\n",
    "    proba[:, 3] *= 1.15   # stage4 boost\n",
    "    proba = proba / np.clip(proba.sum(1, keepdims=True), 1e-12, None)\n",
    "    ypr = proba.argmax(axis=1)\n",
    "\n",
    "    print(\"\\nConfusion matrix:\\n\", confusion_matrix(yte, ypr, labels=[0,1,2,3]))   # ★ 变更点\n",
    "    print(\"\\nReport:\\n\", classification_report(\n",
    "        yte, ypr, labels=[0,1,2,3],                                                # ★ 变更点\n",
    "        target_names=[\"stage1\",\"stage2\",\"stage3\",\"stage4\"], digits=4))\n"
   ],
   "id": "12239d44745e4b0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature rows: (133, 1032)\n",
      "Class distribution (0=stage1, 1=stage2, 2=stage3, 3=stage4):\n",
      " label\n",
      "0    35\n",
      "1    51\n",
      "2    38\n",
      "3     9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Confusion matrix:\n",
      " [[1 4 0 0]\n",
      " [2 2 1 0]\n",
      " [0 2 3 0]\n",
      " [0 1 0 1]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      stage1     0.3333    0.2000    0.2500         5\n",
      "      stage2     0.2222    0.4000    0.2857         5\n",
      "      stage3     0.7500    0.6000    0.6667         5\n",
      "      stage4     1.0000    0.5000    0.6667         2\n",
      "\n",
      "    accuracy                         0.4118        17\n",
      "   macro avg     0.5764    0.4250    0.4673        17\n",
      "weighted avg     0.5016    0.4118    0.4321        17\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
